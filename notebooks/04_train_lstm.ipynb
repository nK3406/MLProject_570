{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2eb68ec",
   "metadata": {},
   "source": [
    "# 04 LSTM EÄŸitimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ba55e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.config import PROJECT_ROOT\n",
    "from src.utils.dataset import TrafficDataset\n",
    "from src.utils.model import TrafficPredictor\n",
    "from torch.utils.data import DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d4111eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(PROJECT_ROOT.joinpath('data/interim/sample.parquet'))\n",
    "df = df.fillna(0)\n",
    "X_STEP, Y_STEP = 2, 1\n",
    "\n",
    "data_array = df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c36d6e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PCA_COMPONENTS = 5\n",
    "dataset = TrafficDataset(\n",
    "    data_array,\n",
    "    X_STEP,\n",
    "    Y_STEP,\n",
    "    pca_components=PCA_COMPONENTS\n",
    ")\n",
    "train_len = int(len(dataset) * 0.8)\n",
    "val_len = len(dataset) - train_len\n",
    "train_ds, val_ds = random_split(dataset, [train_len, val_len])\n",
    "train_loader = DataLoader(train_ds,batch_size=10, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1b04741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "sensors = dataset.sensors\n",
    "print(sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "441df48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm.pt (val_loss improved)\n",
      "Epoch 1/500  Train Loss: 1215516.6250  Val Loss: 409020.6875  Val MSE: 237.8027  Val R2: 0.9553\n",
      "Epoch 2/500  Train Loss: 1215465.7500  Val Loss: 409029.2812  Val MSE: 237.8077  Val R2: 0.9553\n",
      "Epoch 3/500  Train Loss: 1215426.2500  Val Loss: 409037.8438  Val MSE: 237.8127  Val R2: 0.9553\n",
      "Epoch 4/500  Train Loss: 1215392.1250  Val Loss: 409046.5312  Val MSE: 237.8177  Val R2: 0.9553\n",
      "Epoch 5/500  Train Loss: 1215358.2500  Val Loss: 409055.3125  Val MSE: 237.8229  Val R2: 0.9553\n",
      "Epoch 6/500  Train Loss: 1215323.7500  Val Loss: 409064.3125  Val MSE: 237.8281  Val R2: 0.9553\n",
      "Epoch 7/500  Train Loss: 1215287.8750  Val Loss: 409073.5625  Val MSE: 237.8335  Val R2: 0.9553\n",
      "Epoch 8/500  Train Loss: 1215248.3750  Val Loss: 409083.0625  Val MSE: 237.8390  Val R2: 0.9553\n",
      "Epoch 9/500  Train Loss: 1215205.0000  Val Loss: 409092.9375  Val MSE: 237.8447  Val R2: 0.9553\n",
      "Epoch 10/500  Train Loss: 1215160.0000  Val Loss: 409103.2500  Val MSE: 237.8507  Val R2: 0.9553\n",
      "Epoch 11/500  Train Loss: 1215114.3750  Val Loss: 409113.9062  Val MSE: 237.8569  Val R2: 0.9553\n",
      "Epoch 12/500  Train Loss: 1215067.0000  Val Loss: 409125.0000  Val MSE: 237.8634  Val R2: 0.9553\n",
      "Epoch 13/500  Train Loss: 1215019.5000  Val Loss: 409136.6562  Val MSE: 237.8701  Val R2: 0.9553\n",
      "Epoch 14/500  Train Loss: 1214972.0000  Val Loss: 409148.9062  Val MSE: 237.8773  Val R2: 0.9553\n",
      "Epoch 15/500  Train Loss: 1214922.8750  Val Loss: 409161.8125  Val MSE: 237.8848  Val R2: 0.9553\n",
      "Epoch 16/500  Train Loss: 1214871.2500  Val Loss: 409175.8125  Val MSE: 237.8929  Val R2: 0.9552\n",
      "Epoch 17/500  Train Loss: 1214817.0000  Val Loss: 409192.0625  Val MSE: 237.9024  Val R2: 0.9552\n",
      "Epoch 18/500  Train Loss: 1214758.8750  Val Loss: 409212.9375  Val MSE: 237.9145  Val R2: 0.9552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/500  Train Loss: 1214695.6250  Val Loss: 409234.1875  Val MSE: 237.9269  Val R2: 0.9552\n",
      "Epoch 20/500  Train Loss: 1214626.1250  Val Loss: 409252.9688  Val MSE: 237.9378  Val R2: 0.9552\n",
      "Epoch 21/500  Train Loss: 1214548.7500  Val Loss: 409272.3438  Val MSE: 237.9490  Val R2: 0.9552\n",
      "Epoch 22/500  Train Loss: 1214465.6250  Val Loss: 409292.9375  Val MSE: 237.9610  Val R2: 0.9552\n",
      "Epoch 23/500  Train Loss: 1214384.5000  Val Loss: 409314.8125  Val MSE: 237.9737  Val R2: 0.9552\n",
      "Epoch 24/500  Train Loss: 1214303.1250  Val Loss: 409338.1875  Val MSE: 237.9873  Val R2: 0.9552\n",
      "Epoch 25/500  Train Loss: 1214218.0000  Val Loss: 409363.1562  Val MSE: 238.0018  Val R2: 0.9552\n",
      "Epoch 26/500  Train Loss: 1214128.0000  Val Loss: 409389.7188  Val MSE: 238.0173  Val R2: 0.9552\n",
      "Epoch 27/500  Train Loss: 1214034.5000  Val Loss: 409418.1250  Val MSE: 238.0338  Val R2: 0.9552\n",
      "Epoch 28/500  Train Loss: 1213937.3750  Val Loss: 409448.3125  Val MSE: 238.0513  Val R2: 0.9552\n",
      "Epoch 29/500  Train Loss: 1213836.3750  Val Loss: 409480.4375  Val MSE: 238.0700  Val R2: 0.9552\n",
      "Epoch 30/500  Train Loss: 1213730.8750  Val Loss: 409514.6562  Val MSE: 238.0899  Val R2: 0.9552\n",
      "Epoch 31/500  Train Loss: 1213620.7500  Val Loss: 409550.9688  Val MSE: 238.1110  Val R2: 0.9552\n",
      "Epoch 32/500  Train Loss: 1213504.0000  Val Loss: 409589.5000  Val MSE: 238.1335  Val R2: 0.9552\n",
      "Epoch 33/500  Train Loss: 1213379.0000  Val Loss: 409630.4062  Val MSE: 238.1572  Val R2: 0.9552\n",
      "Epoch 34/500  Train Loss: 1213245.8750  Val Loss: 409673.6875  Val MSE: 238.1824  Val R2: 0.9552\n",
      "Epoch 35/500  Train Loss: 1213111.2500  Val Loss: 409719.5312  Val MSE: 238.2090  Val R2: 0.9552\n",
      "Epoch 36/500  Train Loss: 1212979.2500  Val Loss: 409768.0000  Val MSE: 238.2372  Val R2: 0.9552\n",
      "Epoch 37/500  Train Loss: 1212845.6250  Val Loss: 409819.0938  Val MSE: 238.2669  Val R2: 0.9552\n",
      "Epoch 38/500  Train Loss: 1212708.8750  Val Loss: 409872.9375  Val MSE: 238.2982  Val R2: 0.9552\n",
      "Epoch 39/500  Train Loss: 1212569.5000  Val Loss: 409929.5312  Val MSE: 238.3311  Val R2: 0.9552\n",
      "Epoch 40/500  Train Loss: 1212427.3750  Val Loss: 409988.8750  Val MSE: 238.3656  Val R2: 0.9552\n",
      "Epoch 41/500  Train Loss: 1212283.0000  Val Loss: 410051.0625  Val MSE: 238.4018  Val R2: 0.9552\n",
      "Epoch 42/500  Train Loss: 1212136.7500  Val Loss: 410116.1875  Val MSE: 238.4396  Val R2: 0.9551\n",
      "Epoch 43/500  Train Loss: 1211988.8750  Val Loss: 410184.0625  Val MSE: 238.4791  Val R2: 0.9551\n",
      "Epoch 44/500  Train Loss: 1211839.3750  Val Loss: 410254.7500  Val MSE: 238.5202  Val R2: 0.9551\n",
      "Epoch 45/500  Train Loss: 1211689.1250  Val Loss: 410328.2188  Val MSE: 238.5629  Val R2: 0.9551\n",
      "Epoch 46/500  Train Loss: 1211537.8750  Val Loss: 410404.5625  Val MSE: 238.6073  Val R2: 0.9551\n",
      "Epoch 47/500  Train Loss: 1211386.2500  Val Loss: 410483.4375  Val MSE: 238.6532  Val R2: 0.9551\n",
      "Epoch 48/500  Train Loss: 1211234.2500  Val Loss: 410564.9688  Val MSE: 238.7006  Val R2: 0.9551\n",
      "Epoch 49/500  Train Loss: 1211082.3750  Val Loss: 410649.1250  Val MSE: 238.7495  Val R2: 0.9551\n",
      "Epoch 50/500  Train Loss: 1210929.7500  Val Loss: 410735.7188  Val MSE: 238.7998  Val R2: 0.9551\n",
      "Epoch 51/500  Train Loss: 1210777.0000  Val Loss: 410824.6875  Val MSE: 238.8515  Val R2: 0.9551\n",
      "Epoch 52/500  Train Loss: 1210625.7500  Val Loss: 410915.8438  Val MSE: 238.9046  Val R2: 0.9551\n",
      "Epoch 53/500  Train Loss: 1210476.2500  Val Loss: 411009.1875  Val MSE: 238.9588  Val R2: 0.9550\n",
      "Epoch 54/500  Train Loss: 1210327.8750  Val Loss: 411104.4688  Val MSE: 239.0143  Val R2: 0.9550\n",
      "Epoch 55/500  Train Loss: 1210180.5000  Val Loss: 411201.7500  Val MSE: 239.0708  Val R2: 0.9550\n",
      "Epoch 56/500  Train Loss: 1210034.7500  Val Loss: 411300.6875  Val MSE: 239.1283  Val R2: 0.9550\n",
      "Epoch 57/500  Train Loss: 1209890.7500  Val Loss: 411401.2188  Val MSE: 239.1867  Val R2: 0.9550\n",
      "Epoch 58/500  Train Loss: 1209748.1250  Val Loss: 411503.2500  Val MSE: 239.2460  Val R2: 0.9550\n",
      "Epoch 59/500  Train Loss: 1209607.5000  Val Loss: 411606.5000  Val MSE: 239.3061  Val R2: 0.9550\n",
      "Epoch 60/500  Train Loss: 1209468.3750  Val Loss: 411710.9688  Val MSE: 239.3669  Val R2: 0.9550\n",
      "Epoch 61/500  Train Loss: 1209331.3750  Val Loss: 411816.5000  Val MSE: 239.4282  Val R2: 0.9550\n",
      "Epoch 62/500  Train Loss: 1209196.1250  Val Loss: 411922.9375  Val MSE: 239.4901  Val R2: 0.9549\n",
      "Epoch 63/500  Train Loss: 1209062.7500  Val Loss: 412030.0625  Val MSE: 239.5523  Val R2: 0.9549\n",
      "Epoch 64/500  Train Loss: 1208931.5000  Val Loss: 412137.8125  Val MSE: 239.6150  Val R2: 0.9549\n",
      "Epoch 65/500  Train Loss: 1208801.8750  Val Loss: 412246.0625  Val MSE: 239.6779  Val R2: 0.9549\n",
      "Epoch 66/500  Train Loss: 1208674.2500  Val Loss: 412354.6875  Val MSE: 239.7411  Val R2: 0.9549\n",
      "Epoch 67/500  Train Loss: 1208548.6250  Val Loss: 412463.5938  Val MSE: 239.8044  Val R2: 0.9549\n",
      "Epoch 68/500  Train Loss: 1208424.5000  Val Loss: 412572.6875  Val MSE: 239.8678  Val R2: 0.9549\n",
      "Epoch 69/500  Train Loss: 1208302.3750  Val Loss: 412681.8125  Val MSE: 239.9313  Val R2: 0.9549\n",
      "Epoch 70/500  Train Loss: 1208181.8750  Val Loss: 412790.8750  Val MSE: 239.9947  Val R2: 0.9549\n",
      "Epoch 71/500  Train Loss: 1208063.2500  Val Loss: 412899.8125  Val MSE: 240.0581  Val R2: 0.9548\n",
      "Epoch 72/500  Train Loss: 1207946.1250  Val Loss: 413008.6562  Val MSE: 240.1213  Val R2: 0.9548\n",
      "Epoch 73/500  Train Loss: 1207830.7500  Val Loss: 413117.1250  Val MSE: 240.1844  Val R2: 0.9548\n",
      "Epoch 74/500  Train Loss: 1207716.6250  Val Loss: 413225.4062  Val MSE: 240.2473  Val R2: 0.9548\n",
      "Epoch 75/500  Train Loss: 1207604.2500  Val Loss: 413333.1875  Val MSE: 240.3100  Val R2: 0.9548\n",
      "Epoch 76/500  Train Loss: 1207492.8750  Val Loss: 413440.6875  Val MSE: 240.3725  Val R2: 0.9548\n",
      "Epoch 77/500  Train Loss: 1207383.2500  Val Loss: 413547.6562  Val MSE: 240.4347  Val R2: 0.9548\n",
      "Epoch 78/500  Train Loss: 1207274.7500  Val Loss: 413654.1250  Val MSE: 240.4966  Val R2: 0.9548\n",
      "Epoch 79/500  Train Loss: 1207167.6250  Val Loss: 413760.1250  Val MSE: 240.5582  Val R2: 0.9547\n",
      "Epoch 80/500  Train Loss: 1207061.6250  Val Loss: 413865.5625  Val MSE: 240.6195  Val R2: 0.9547\n",
      "Epoch 81/500  Train Loss: 1206956.7500  Val Loss: 413970.4375  Val MSE: 240.6805  Val R2: 0.9547\n",
      "Epoch 82/500  Train Loss: 1206853.1250  Val Loss: 414074.7500  Val MSE: 240.7411  Val R2: 0.9547\n",
      "Epoch 83/500  Train Loss: 1206750.5000  Val Loss: 414178.5625  Val MSE: 240.8015  Val R2: 0.9547\n",
      "Epoch 84/500  Train Loss: 1206648.7500  Val Loss: 414281.6875  Val MSE: 240.8614  Val R2: 0.9547\n",
      "Epoch 85/500  Train Loss: 1206548.2500  Val Loss: 414384.2188  Val MSE: 240.9211  Val R2: 0.9547\n",
      "Epoch 86/500  Train Loss: 1206448.6250  Val Loss: 414486.1875  Val MSE: 240.9803  Val R2: 0.9547\n",
      "Epoch 87/500  Train Loss: 1206349.5000  Val Loss: 414587.5000  Val MSE: 241.0392  Val R2: 0.9547\n",
      "Epoch 88/500  Train Loss: 1206251.3750  Val Loss: 414688.1875  Val MSE: 241.0978  Val R2: 0.9546\n",
      "Epoch 89/500  Train Loss: 1206154.3750  Val Loss: 414788.3125  Val MSE: 241.1560  Val R2: 0.9546\n",
      "Epoch 90/500  Train Loss: 1206057.8750  Val Loss: 414887.8125  Val MSE: 241.2138  Val R2: 0.9546\n",
      "Epoch 91/500  Train Loss: 1205962.2500  Val Loss: 414986.7188  Val MSE: 241.2713  Val R2: 0.9546\n",
      "Epoch 92/500  Train Loss: 1205867.2500  Val Loss: 415084.8750  Val MSE: 241.3284  Val R2: 0.9546\n",
      "Epoch 93/500  Train Loss: 1205772.8750  Val Loss: 415182.4688  Val MSE: 241.3852  Val R2: 0.9546\n",
      "Epoch 94/500  Train Loss: 1205679.6250  Val Loss: 415279.4688  Val MSE: 241.4415  Val R2: 0.9546\n",
      "Epoch 95/500  Train Loss: 1205586.2500  Val Loss: 415375.8125  Val MSE: 241.4976  Val R2: 0.9546\n",
      "Epoch 96/500  Train Loss: 1205494.0000  Val Loss: 415471.4688  Val MSE: 241.5532  Val R2: 0.9546\n",
      "Epoch 97/500  Train Loss: 1205402.2500  Val Loss: 415566.5625  Val MSE: 241.6085  Val R2: 0.9546\n",
      "Epoch 98/500  Train Loss: 1205311.1250  Val Loss: 415660.9688  Val MSE: 241.6634  Val R2: 0.9545\n",
      "Epoch 99/500  Train Loss: 1205220.3750  Val Loss: 415754.8125  Val MSE: 241.7179  Val R2: 0.9545\n",
      "Epoch 100/500  Train Loss: 1205130.1250  Val Loss: 415848.0312  Val MSE: 241.7721  Val R2: 0.9545\n",
      "Epoch 101/500  Train Loss: 1205040.5000  Val Loss: 415940.6250  Val MSE: 241.8260  Val R2: 0.9545\n",
      "Epoch 102/500  Train Loss: 1204951.2500  Val Loss: 416032.6562  Val MSE: 241.8795  Val R2: 0.9545\n",
      "Epoch 103/500  Train Loss: 1204862.7500  Val Loss: 416124.0625  Val MSE: 241.9326  Val R2: 0.9545\n",
      "Epoch 104/500  Train Loss: 1204774.7500  Val Loss: 416214.9375  Val MSE: 241.9854  Val R2: 0.9545\n",
      "Epoch 105/500  Train Loss: 1204686.7500  Val Loss: 416305.2500  Val MSE: 242.0379  Val R2: 0.9545\n",
      "Epoch 106/500  Train Loss: 1204599.6250  Val Loss: 416394.9688  Val MSE: 242.0901  Val R2: 0.9545\n",
      "Epoch 107/500  Train Loss: 1204512.7500  Val Loss: 416484.1250  Val MSE: 242.1419  Val R2: 0.9545\n",
      "Epoch 108/500  Train Loss: 1204426.2500  Val Loss: 416572.7812  Val MSE: 242.1935  Val R2: 0.9544\n",
      "Epoch 109/500  Train Loss: 1204340.2500  Val Loss: 416660.9688  Val MSE: 242.2447  Val R2: 0.9544\n",
      "Epoch 110/500  Train Loss: 1204254.3750  Val Loss: 416748.5938  Val MSE: 242.2957  Val R2: 0.9544\n",
      "Epoch 111/500  Train Loss: 1204169.1250  Val Loss: 416835.7188  Val MSE: 242.3464  Val R2: 0.9544\n",
      "Epoch 112/500  Train Loss: 1204084.0000  Val Loss: 416922.3750  Val MSE: 242.3968  Val R2: 0.9544\n",
      "Epoch 113/500  Train Loss: 1203999.3750  Val Loss: 417008.6562  Val MSE: 242.4469  Val R2: 0.9544\n",
      "Epoch 114/500  Train Loss: 1203915.2500  Val Loss: 417094.4688  Val MSE: 242.4967  Val R2: 0.9544\n",
      "Epoch 115/500  Train Loss: 1203831.2500  Val Loss: 417179.7500  Val MSE: 242.5464  Val R2: 0.9544\n",
      "Epoch 116/500  Train Loss: 1203747.5000  Val Loss: 417264.6562  Val MSE: 242.5957  Val R2: 0.9544\n",
      "Epoch 117/500  Train Loss: 1203664.3750  Val Loss: 417349.1250  Val MSE: 242.6448  Val R2: 0.9544\n",
      "Epoch 118/500  Train Loss: 1203581.3750  Val Loss: 417433.1875  Val MSE: 242.6937  Val R2: 0.9543\n",
      "Epoch 119/500  Train Loss: 1203498.6250  Val Loss: 417516.9062  Val MSE: 242.7424  Val R2: 0.9543\n",
      "Epoch 120/500  Train Loss: 1203416.3750  Val Loss: 417600.1875  Val MSE: 242.7908  Val R2: 0.9543\n",
      "Epoch 121/500  Train Loss: 1203334.2500  Val Loss: 417683.1562  Val MSE: 242.8390  Val R2: 0.9543\n",
      "Epoch 122/500  Train Loss: 1203252.3750  Val Loss: 417765.7188  Val MSE: 242.8870  Val R2: 0.9543\n",
      "Epoch 123/500  Train Loss: 1203170.7500  Val Loss: 417847.8750  Val MSE: 242.9348  Val R2: 0.9543\n",
      "Epoch 124/500  Train Loss: 1203089.5000  Val Loss: 417929.7500  Val MSE: 242.9824  Val R2: 0.9543\n",
      "Epoch 125/500  Train Loss: 1203008.6250  Val Loss: 418011.3125  Val MSE: 243.0298  Val R2: 0.9543\n",
      "Epoch 126/500  Train Loss: 1202927.7500  Val Loss: 418092.4688  Val MSE: 243.0770  Val R2: 0.9543\n",
      "Epoch 127/500  Train Loss: 1202847.2500  Val Loss: 418173.3750  Val MSE: 243.1241  Val R2: 0.9543\n",
      "Epoch 128/500  Train Loss: 1202766.8750  Val Loss: 418253.9688  Val MSE: 243.1709  Val R2: 0.9543\n",
      "Epoch 129/500  Train Loss: 1202686.8750  Val Loss: 418334.1875  Val MSE: 243.2176  Val R2: 0.9542\n",
      "Epoch 130/500  Train Loss: 1202607.2500  Val Loss: 418414.1875  Val MSE: 243.2641  Val R2: 0.9542\n",
      "Epoch 131/500  Train Loss: 1202527.5000  Val Loss: 418493.8750  Val MSE: 243.3104  Val R2: 0.9542\n",
      "Epoch 132/500  Train Loss: 1202448.2500  Val Loss: 418573.3125  Val MSE: 243.3566  Val R2: 0.9542\n",
      "Epoch 133/500  Train Loss: 1202369.1250  Val Loss: 418652.3750  Val MSE: 243.4025  Val R2: 0.9542\n",
      "Epoch 134/500  Train Loss: 1202290.2500  Val Loss: 418731.2500  Val MSE: 243.4484  Val R2: 0.9542\n",
      "Epoch 135/500  Train Loss: 1202211.5000  Val Loss: 418809.8125  Val MSE: 243.4941  Val R2: 0.9542\n",
      "Epoch 136/500  Train Loss: 1202133.1250  Val Loss: 418888.1250  Val MSE: 243.5396  Val R2: 0.9542\n",
      "Epoch 137/500  Train Loss: 1202054.7500  Val Loss: 418966.1875  Val MSE: 243.5850  Val R2: 0.9542\n",
      "Epoch 138/500  Train Loss: 1201976.5000  Val Loss: 419044.0000  Val MSE: 243.6302  Val R2: 0.9542\n",
      "Epoch 139/500  Train Loss: 1201898.6250  Val Loss: 419121.6250  Val MSE: 243.6753  Val R2: 0.9542\n",
      "Epoch 140/500  Train Loss: 1201821.1250  Val Loss: 419198.9375  Val MSE: 243.7203  Val R2: 0.9542\n",
      "Epoch 141/500  Train Loss: 1201743.5000  Val Loss: 419276.0625  Val MSE: 243.7651  Val R2: 0.9541\n",
      "Epoch 142/500  Train Loss: 1201666.1250  Val Loss: 419352.9062  Val MSE: 243.8098  Val R2: 0.9541\n",
      "Epoch 143/500  Train Loss: 1201588.7500  Val Loss: 419429.6562  Val MSE: 243.8544  Val R2: 0.9541\n",
      "Epoch 144/500  Train Loss: 1201511.7500  Val Loss: 419506.0625  Val MSE: 243.8989  Val R2: 0.9541\n",
      "Epoch 145/500  Train Loss: 1201435.0000  Val Loss: 419582.3125  Val MSE: 243.9432  Val R2: 0.9541\n",
      "Epoch 146/500  Train Loss: 1201358.3750  Val Loss: 419658.3125  Val MSE: 243.9874  Val R2: 0.9541\n",
      "Epoch 147/500  Train Loss: 1201281.7500  Val Loss: 419734.1562  Val MSE: 244.0315  Val R2: 0.9541\n",
      "Epoch 148/500  Train Loss: 1201205.5000  Val Loss: 419809.8125  Val MSE: 244.0755  Val R2: 0.9541\n",
      "Epoch 149/500  Train Loss: 1201129.2500  Val Loss: 419885.2500  Val MSE: 244.1193  Val R2: 0.9541\n",
      "Epoch 150/500  Train Loss: 1201053.1250  Val Loss: 419960.5000  Val MSE: 244.1631  Val R2: 0.9541\n",
      "Epoch 151/500  Train Loss: 1200977.2500  Val Loss: 420035.5000  Val MSE: 244.2067  Val R2: 0.9541\n",
      "Epoch 152/500  Train Loss: 1200901.3750  Val Loss: 420110.4062  Val MSE: 244.2503  Val R2: 0.9541\n",
      "Epoch 153/500  Train Loss: 1200825.8750  Val Loss: 420185.1562  Val MSE: 244.2937  Val R2: 0.9540\n",
      "Epoch 154/500  Train Loss: 1200750.7500  Val Loss: 420259.6562  Val MSE: 244.3370  Val R2: 0.9540\n",
      "Epoch 155/500  Train Loss: 1200675.2500  Val Loss: 420334.0625  Val MSE: 244.3802  Val R2: 0.9540\n",
      "Epoch 156/500  Train Loss: 1200600.0000  Val Loss: 420408.1875  Val MSE: 244.4234  Val R2: 0.9540\n",
      "Epoch 157/500  Train Loss: 1200525.1250  Val Loss: 420482.2500  Val MSE: 244.4664  Val R2: 0.9540\n",
      "Epoch 158/500  Train Loss: 1200450.1250  Val Loss: 420556.1562  Val MSE: 244.5094  Val R2: 0.9540\n",
      "Epoch 159/500  Train Loss: 1200375.3750  Val Loss: 420629.8125  Val MSE: 244.5522  Val R2: 0.9540\n",
      "Epoch 160/500  Train Loss: 1200300.7500  Val Loss: 420703.3438  Val MSE: 244.5950  Val R2: 0.9540\n",
      "Epoch 161/500  Train Loss: 1200226.2500  Val Loss: 420776.6875  Val MSE: 244.6376  Val R2: 0.9540\n",
      "Epoch 162/500  Train Loss: 1200151.8750  Val Loss: 420849.9375  Val MSE: 244.6802  Val R2: 0.9540\n",
      "Epoch 163/500  Train Loss: 1200077.7500  Val Loss: 420923.0000  Val MSE: 244.7227  Val R2: 0.9540\n",
      "Epoch 164/500  Train Loss: 1200003.6250  Val Loss: 420995.9375  Val MSE: 244.7651  Val R2: 0.9540\n",
      "Epoch 165/500  Train Loss: 1199929.6250  Val Loss: 421068.6875  Val MSE: 244.8074  Val R2: 0.9539\n",
      "Epoch 166/500  Train Loss: 1199855.7500  Val Loss: 421141.4062  Val MSE: 244.8496  Val R2: 0.9539\n",
      "Epoch 167/500  Train Loss: 1199782.0000  Val Loss: 421213.9062  Val MSE: 244.8918  Val R2: 0.9539\n",
      "Epoch 168/500  Train Loss: 1199708.3750  Val Loss: 421286.3125  Val MSE: 244.9339  Val R2: 0.9539\n",
      "Epoch 169/500  Train Loss: 1199634.7500  Val Loss: 421358.5625  Val MSE: 244.9759  Val R2: 0.9539\n",
      "Epoch 170/500  Train Loss: 1199561.3750  Val Loss: 421430.5938  Val MSE: 245.0178  Val R2: 0.9539\n",
      "Epoch 171/500  Train Loss: 1199488.2500  Val Loss: 421502.5625  Val MSE: 245.0596  Val R2: 0.9539\n",
      "Epoch 172/500  Train Loss: 1199414.8750  Val Loss: 421574.3438  Val MSE: 245.1014  Val R2: 0.9539\n",
      "Epoch 173/500  Train Loss: 1199341.8750  Val Loss: 421646.0938  Val MSE: 245.1431  Val R2: 0.9539\n",
      "Epoch 174/500  Train Loss: 1199269.0000  Val Loss: 421717.6875  Val MSE: 245.1847  Val R2: 0.9539\n",
      "Epoch 175/500  Train Loss: 1199196.0000  Val Loss: 421789.0938  Val MSE: 245.2262  Val R2: 0.9539\n",
      "Epoch 176/500  Train Loss: 1199123.2500  Val Loss: 421860.4375  Val MSE: 245.2677  Val R2: 0.9539\n",
      "Epoch 177/500  Train Loss: 1199050.7500  Val Loss: 421931.6562  Val MSE: 245.3091  Val R2: 0.9539\n",
      "Epoch 178/500  Train Loss: 1198978.1250  Val Loss: 422002.8125  Val MSE: 245.3504  Val R2: 0.9538\n",
      "Epoch 179/500  Train Loss: 1198905.7500  Val Loss: 422073.6875  Val MSE: 245.3917  Val R2: 0.9538\n",
      "Epoch 180/500  Train Loss: 1198833.2500  Val Loss: 422144.5938  Val MSE: 245.4329  Val R2: 0.9538\n",
      "Epoch 181/500  Train Loss: 1198761.1250  Val Loss: 422215.4062  Val MSE: 245.4740  Val R2: 0.9538\n",
      "Epoch 182/500  Train Loss: 1198688.8750  Val Loss: 422286.0000  Val MSE: 245.5151  Val R2: 0.9538\n",
      "Epoch 183/500  Train Loss: 1198616.7500  Val Loss: 422356.5625  Val MSE: 245.5561  Val R2: 0.9538\n",
      "Epoch 184/500  Train Loss: 1198544.6250  Val Loss: 422427.0000  Val MSE: 245.5971  Val R2: 0.9538\n",
      "Epoch 185/500  Train Loss: 1198472.7500  Val Loss: 422497.2500  Val MSE: 245.6379  Val R2: 0.9538\n",
      "Epoch 186/500  Train Loss: 1198401.2500  Val Loss: 422567.5000  Val MSE: 245.6788  Val R2: 0.9538\n",
      "Epoch 187/500  Train Loss: 1198329.5000  Val Loss: 422637.5938  Val MSE: 245.7195  Val R2: 0.9538\n",
      "Epoch 188/500  Train Loss: 1198257.7500  Val Loss: 422707.5938  Val MSE: 245.7602  Val R2: 0.9538\n",
      "Epoch 189/500  Train Loss: 1198186.2500  Val Loss: 422777.5000  Val MSE: 245.8009  Val R2: 0.9538\n",
      "Epoch 190/500  Train Loss: 1198114.7500  Val Loss: 422847.3125  Val MSE: 245.8414  Val R2: 0.9538\n",
      "Epoch 191/500  Train Loss: 1198043.6250  Val Loss: 422916.9375  Val MSE: 245.8820  Val R2: 0.9537\n",
      "Epoch 192/500  Train Loss: 1197972.2500  Val Loss: 422986.5938  Val MSE: 245.9224  Val R2: 0.9537\n",
      "Epoch 193/500  Train Loss: 1197901.1250  Val Loss: 423056.0625  Val MSE: 245.9628  Val R2: 0.9537\n",
      "Epoch 194/500  Train Loss: 1197829.7500  Val Loss: 423125.5000  Val MSE: 246.0032  Val R2: 0.9537\n",
      "Epoch 195/500  Train Loss: 1197758.8750  Val Loss: 423194.8125  Val MSE: 246.0435  Val R2: 0.9537\n",
      "Epoch 196/500  Train Loss: 1197687.8750  Val Loss: 423264.0625  Val MSE: 246.0838  Val R2: 0.9537\n",
      "Epoch 197/500  Train Loss: 1197617.1250  Val Loss: 423333.1875  Val MSE: 246.1240  Val R2: 0.9537\n",
      "Epoch 198/500  Train Loss: 1197546.3750  Val Loss: 423402.1875  Val MSE: 246.1641  Val R2: 0.9537\n",
      "Epoch 199/500  Train Loss: 1197475.7500  Val Loss: 423471.1875  Val MSE: 246.2042  Val R2: 0.9537\n",
      "Epoch 200/500  Train Loss: 1197405.1250  Val Loss: 423540.0625  Val MSE: 246.2442  Val R2: 0.9537\n",
      "Epoch 201/500  Train Loss: 1197334.5000  Val Loss: 423608.8438  Val MSE: 246.2842  Val R2: 0.9537\n",
      "Epoch 202/500  Train Loss: 1197264.2500  Val Loss: 423677.5625  Val MSE: 246.3242  Val R2: 0.9537\n",
      "Epoch 203/500  Train Loss: 1197193.7500  Val Loss: 423746.1562  Val MSE: 246.3640  Val R2: 0.9537\n",
      "Epoch 204/500  Train Loss: 1197123.2500  Val Loss: 423814.6562  Val MSE: 246.4039  Val R2: 0.9536\n",
      "Epoch 205/500  Train Loss: 1197053.2500  Val Loss: 423883.0938  Val MSE: 246.4437  Val R2: 0.9536\n",
      "Epoch 206/500  Train Loss: 1196983.0000  Val Loss: 423951.5000  Val MSE: 246.4834  Val R2: 0.9536\n",
      "Epoch 207/500  Train Loss: 1196912.7500  Val Loss: 424019.7500  Val MSE: 246.5231  Val R2: 0.9536\n",
      "Epoch 208/500  Train Loss: 1196843.0000  Val Loss: 424087.9375  Val MSE: 246.5628  Val R2: 0.9536\n",
      "Epoch 209/500  Train Loss: 1196772.8750  Val Loss: 424156.0938  Val MSE: 246.6024  Val R2: 0.9536\n",
      "Epoch 210/500  Train Loss: 1196703.0000  Val Loss: 424224.1562  Val MSE: 246.6419  Val R2: 0.9536\n",
      "Epoch 211/500  Train Loss: 1196633.2500  Val Loss: 424292.0938  Val MSE: 246.6814  Val R2: 0.9536\n",
      "Epoch 212/500  Train Loss: 1196563.5000  Val Loss: 424359.9375  Val MSE: 246.7209  Val R2: 0.9536\n",
      "Epoch 213/500  Train Loss: 1196493.7500  Val Loss: 424427.7500  Val MSE: 246.7603  Val R2: 0.9536\n",
      "Epoch 214/500  Train Loss: 1196424.2500  Val Loss: 424495.5625  Val MSE: 246.7997  Val R2: 0.9536\n",
      "Epoch 215/500  Train Loss: 1196354.6250  Val Loss: 424563.1875  Val MSE: 246.8391  Val R2: 0.9536\n",
      "Epoch 216/500  Train Loss: 1196285.2500  Val Loss: 424630.7500  Val MSE: 246.8783  Val R2: 0.9536\n",
      "Epoch 217/500  Train Loss: 1196215.8750  Val Loss: 424698.3125  Val MSE: 246.9176  Val R2: 0.9536\n",
      "Epoch 218/500  Train Loss: 1196146.7500  Val Loss: 424765.7500  Val MSE: 246.9568  Val R2: 0.9535\n",
      "Epoch 219/500  Train Loss: 1196077.2500  Val Loss: 424833.1562  Val MSE: 246.9960  Val R2: 0.9535\n",
      "Epoch 220/500  Train Loss: 1196008.0000  Val Loss: 424900.3438  Val MSE: 247.0351  Val R2: 0.9535\n",
      "Epoch 221/500  Train Loss: 1195938.7500  Val Loss: 424967.5938  Val MSE: 247.0742  Val R2: 0.9535\n",
      "Epoch 222/500  Train Loss: 1195869.6250  Val Loss: 425034.7500  Val MSE: 247.1132  Val R2: 0.9535\n",
      "Epoch 223/500  Train Loss: 1195800.7500  Val Loss: 425101.8438  Val MSE: 247.1523  Val R2: 0.9535\n",
      "Epoch 224/500  Train Loss: 1195731.7500  Val Loss: 425168.9062  Val MSE: 247.1912  Val R2: 0.9535\n",
      "Epoch 225/500  Train Loss: 1195662.6250  Val Loss: 425235.8438  Val MSE: 247.2302  Val R2: 0.9535\n",
      "Epoch 226/500  Train Loss: 1195594.0000  Val Loss: 425302.7500  Val MSE: 247.2690  Val R2: 0.9535\n",
      "Epoch 227/500  Train Loss: 1195525.0000  Val Loss: 425369.5938  Val MSE: 247.3079  Val R2: 0.9535\n",
      "Epoch 228/500  Train Loss: 1195456.5000  Val Loss: 425436.3125  Val MSE: 247.3467  Val R2: 0.9535\n",
      "Epoch 229/500  Train Loss: 1195387.7500  Val Loss: 425503.0625  Val MSE: 247.3855  Val R2: 0.9535\n",
      "Epoch 230/500  Train Loss: 1195319.2500  Val Loss: 425569.6875  Val MSE: 247.4242  Val R2: 0.9535\n",
      "Epoch 231/500  Train Loss: 1195250.5000  Val Loss: 425636.3125  Val MSE: 247.4629  Val R2: 0.9534\n",
      "Epoch 232/500  Train Loss: 1195182.1250  Val Loss: 425702.7500  Val MSE: 247.5016  Val R2: 0.9534\n",
      "Epoch 233/500  Train Loss: 1195113.6250  Val Loss: 425769.1875  Val MSE: 247.5402  Val R2: 0.9534\n",
      "Epoch 234/500  Train Loss: 1195045.2500  Val Loss: 425835.5938  Val MSE: 247.5788  Val R2: 0.9534\n",
      "Epoch 235/500  Train Loss: 1194976.8750  Val Loss: 425901.9062  Val MSE: 247.6174  Val R2: 0.9534\n",
      "Epoch 236/500  Train Loss: 1194908.7500  Val Loss: 425968.1562  Val MSE: 247.6559  Val R2: 0.9534\n",
      "Epoch 237/500  Train Loss: 1194840.3750  Val Loss: 426034.3438  Val MSE: 247.6944  Val R2: 0.9534\n",
      "Epoch 238/500  Train Loss: 1194772.2500  Val Loss: 426100.5000  Val MSE: 247.7329  Val R2: 0.9534\n",
      "Epoch 239/500  Train Loss: 1194704.1250  Val Loss: 426166.5938  Val MSE: 247.7713  Val R2: 0.9534\n",
      "Epoch 240/500  Train Loss: 1194636.2500  Val Loss: 426232.6875  Val MSE: 247.8097  Val R2: 0.9534\n",
      "Epoch 241/500  Train Loss: 1194568.2500  Val Loss: 426298.5938  Val MSE: 247.8480  Val R2: 0.9534\n",
      "Epoch 242/500  Train Loss: 1194500.2500  Val Loss: 426364.5000  Val MSE: 247.8863  Val R2: 0.9534\n",
      "Epoch 243/500  Train Loss: 1194432.2500  Val Loss: 426430.4062  Val MSE: 247.9246  Val R2: 0.9534\n",
      "Epoch 244/500  Train Loss: 1194364.3750  Val Loss: 426496.1875  Val MSE: 247.9629  Val R2: 0.9534\n",
      "Epoch 245/500  Train Loss: 1194296.7500  Val Loss: 426561.9062  Val MSE: 248.0011  Val R2: 0.9533\n",
      "Epoch 246/500  Train Loss: 1194228.7500  Val Loss: 426627.5625  Val MSE: 248.0393  Val R2: 0.9533\n",
      "Epoch 247/500  Train Loss: 1194161.2500  Val Loss: 426693.1875  Val MSE: 248.0775  Val R2: 0.9533\n",
      "Epoch 248/500  Train Loss: 1194093.5000  Val Loss: 426758.8438  Val MSE: 248.1156  Val R2: 0.9533\n",
      "Epoch 249/500  Train Loss: 1194025.8750  Val Loss: 426824.3438  Val MSE: 248.1537  Val R2: 0.9533\n",
      "Epoch 250/500  Train Loss: 1193958.3750  Val Loss: 426889.8125  Val MSE: 248.1917  Val R2: 0.9533\n",
      "Epoch 251/500  Train Loss: 1193890.8750  Val Loss: 426955.1562  Val MSE: 248.2298  Val R2: 0.9533\n",
      "Epoch 252/500  Train Loss: 1193823.3750  Val Loss: 427020.5625  Val MSE: 248.2678  Val R2: 0.9533\n",
      "Epoch 253/500  Train Loss: 1193756.2500  Val Loss: 427085.8438  Val MSE: 248.3058  Val R2: 0.9533\n",
      "Epoch 254/500  Train Loss: 1193688.7500  Val Loss: 427151.1562  Val MSE: 248.3437  Val R2: 0.9533\n",
      "Epoch 255/500  Train Loss: 1193621.5000  Val Loss: 427216.4062  Val MSE: 248.3816  Val R2: 0.9533\n",
      "Epoch 256/500  Train Loss: 1193553.8750  Val Loss: 427281.5000  Val MSE: 248.4195  Val R2: 0.9533\n",
      "Epoch 257/500  Train Loss: 1193487.0000  Val Loss: 427346.6562  Val MSE: 248.4574  Val R2: 0.9533\n",
      "Epoch 258/500  Train Loss: 1193419.6250  Val Loss: 427411.6875  Val MSE: 248.4952  Val R2: 0.9533\n",
      "Epoch 259/500  Train Loss: 1193352.5000  Val Loss: 427476.7500  Val MSE: 248.5330  Val R2: 0.9532\n",
      "Epoch 260/500  Train Loss: 1193285.5000  Val Loss: 427541.6875  Val MSE: 248.5707  Val R2: 0.9532\n",
      "Epoch 261/500  Train Loss: 1193218.3750  Val Loss: 427606.5625  Val MSE: 248.6085  Val R2: 0.9532\n",
      "Epoch 262/500  Train Loss: 1193151.5000  Val Loss: 427671.5000  Val MSE: 248.6462  Val R2: 0.9532\n",
      "Epoch 263/500  Train Loss: 1193084.3750  Val Loss: 427736.3125  Val MSE: 248.6839  Val R2: 0.9532\n",
      "Epoch 264/500  Train Loss: 1193017.7500  Val Loss: 427801.0000  Val MSE: 248.7215  Val R2: 0.9532\n",
      "Epoch 265/500  Train Loss: 1192950.7500  Val Loss: 427865.7500  Val MSE: 248.7592  Val R2: 0.9532\n",
      "Epoch 266/500  Train Loss: 1192884.0000  Val Loss: 427930.4062  Val MSE: 248.7968  Val R2: 0.9532\n",
      "Epoch 267/500  Train Loss: 1192817.2500  Val Loss: 427995.0625  Val MSE: 248.8343  Val R2: 0.9532\n",
      "Epoch 268/500  Train Loss: 1192750.2500  Val Loss: 428059.5938  Val MSE: 248.8719  Val R2: 0.9532\n",
      "Epoch 269/500  Train Loss: 1192683.7500  Val Loss: 428124.1875  Val MSE: 248.9094  Val R2: 0.9532\n",
      "Epoch 270/500  Train Loss: 1192617.2500  Val Loss: 428188.6562  Val MSE: 248.9469  Val R2: 0.9532\n",
      "Epoch 271/500  Train Loss: 1192550.6250  Val Loss: 428253.0938  Val MSE: 248.9843  Val R2: 0.9532\n",
      "Epoch 272/500  Train Loss: 1192484.1250  Val Loss: 428317.4375  Val MSE: 249.0218  Val R2: 0.9532\n",
      "Epoch 273/500  Train Loss: 1192417.5000  Val Loss: 428381.8125  Val MSE: 249.0592  Val R2: 0.9531\n",
      "Epoch 274/500  Train Loss: 1192350.8750  Val Loss: 428446.1562  Val MSE: 249.0966  Val R2: 0.9531\n",
      "Epoch 275/500  Train Loss: 1192284.6250  Val Loss: 428510.4062  Val MSE: 249.1339  Val R2: 0.9531\n",
      "Epoch 276/500  Train Loss: 1192218.1250  Val Loss: 428574.5938  Val MSE: 249.1713  Val R2: 0.9531\n",
      "Epoch 277/500  Train Loss: 1192151.8750  Val Loss: 428638.8125  Val MSE: 249.2086  Val R2: 0.9531\n",
      "Epoch 278/500  Train Loss: 1192085.5000  Val Loss: 428702.9062  Val MSE: 249.2459  Val R2: 0.9531\n",
      "Epoch 279/500  Train Loss: 1192019.2500  Val Loss: 428767.0625  Val MSE: 249.2831  Val R2: 0.9531\n",
      "Epoch 280/500  Train Loss: 1191952.7500  Val Loss: 428831.0625  Val MSE: 249.3204  Val R2: 0.9531\n",
      "Epoch 281/500  Train Loss: 1191886.7500  Val Loss: 428895.0000  Val MSE: 249.3576  Val R2: 0.9531\n",
      "Epoch 282/500  Train Loss: 1191820.6250  Val Loss: 428959.0000  Val MSE: 249.3948  Val R2: 0.9531\n",
      "Epoch 283/500  Train Loss: 1191754.5000  Val Loss: 429022.9375  Val MSE: 249.4319  Val R2: 0.9531\n",
      "Epoch 284/500  Train Loss: 1191688.5000  Val Loss: 429086.8125  Val MSE: 249.4691  Val R2: 0.9531\n",
      "Epoch 285/500  Train Loss: 1191622.3750  Val Loss: 429150.6562  Val MSE: 249.5062  Val R2: 0.9531\n",
      "Epoch 286/500  Train Loss: 1191556.3750  Val Loss: 429214.4062  Val MSE: 249.5433  Val R2: 0.9531\n",
      "Epoch 287/500  Train Loss: 1191490.3750  Val Loss: 429278.1875  Val MSE: 249.5803  Val R2: 0.9531\n",
      "Epoch 288/500  Train Loss: 1191424.5000  Val Loss: 429341.9062  Val MSE: 249.6174  Val R2: 0.9530\n",
      "Epoch 289/500  Train Loss: 1191358.7500  Val Loss: 429405.5625  Val MSE: 249.6544  Val R2: 0.9530\n",
      "Epoch 290/500  Train Loss: 1191292.8750  Val Loss: 429469.1875  Val MSE: 249.6914  Val R2: 0.9530\n",
      "Epoch 291/500  Train Loss: 1191227.1250  Val Loss: 429532.6875  Val MSE: 249.7283  Val R2: 0.9530\n",
      "Epoch 292/500  Train Loss: 1191161.2500  Val Loss: 429596.3125  Val MSE: 249.7653  Val R2: 0.9530\n",
      "Epoch 293/500  Train Loss: 1191095.3750  Val Loss: 429659.8125  Val MSE: 249.8022  Val R2: 0.9530\n",
      "Epoch 294/500  Train Loss: 1191029.8750  Val Loss: 429723.3125  Val MSE: 249.8391  Val R2: 0.9530\n",
      "Epoch 295/500  Train Loss: 1190964.2500  Val Loss: 429786.6875  Val MSE: 249.8760  Val R2: 0.9530\n",
      "Epoch 296/500  Train Loss: 1190898.6250  Val Loss: 429850.1562  Val MSE: 249.9129  Val R2: 0.9530\n",
      "Epoch 297/500  Train Loss: 1190833.0000  Val Loss: 429913.4375  Val MSE: 249.9497  Val R2: 0.9530\n",
      "Epoch 298/500  Train Loss: 1190767.2500  Val Loss: 429976.8125  Val MSE: 249.9865  Val R2: 0.9530\n",
      "Epoch 299/500  Train Loss: 1190701.7500  Val Loss: 430040.0625  Val MSE: 250.0233  Val R2: 0.9530\n",
      "Epoch 300/500  Train Loss: 1190636.2500  Val Loss: 430103.3125  Val MSE: 250.0601  Val R2: 0.9530\n",
      "Epoch 301/500  Train Loss: 1190571.0000  Val Loss: 430166.5625  Val MSE: 250.0968  Val R2: 0.9530\n",
      "Epoch 302/500  Train Loss: 1190505.2500  Val Loss: 430229.6562  Val MSE: 250.1335  Val R2: 0.9529\n",
      "Epoch 303/500  Train Loss: 1190440.0000  Val Loss: 430292.8125  Val MSE: 250.1702  Val R2: 0.9529\n",
      "Epoch 304/500  Train Loss: 1190374.7500  Val Loss: 430355.9062  Val MSE: 250.2069  Val R2: 0.9529\n",
      "Epoch 305/500  Train Loss: 1190309.3750  Val Loss: 430418.9062  Val MSE: 250.2436  Val R2: 0.9529\n",
      "Epoch 306/500  Train Loss: 1190243.8750  Val Loss: 430481.9375  Val MSE: 250.2802  Val R2: 0.9529\n",
      "Epoch 307/500  Train Loss: 1190178.7500  Val Loss: 430544.9375  Val MSE: 250.3168  Val R2: 0.9529\n",
      "Epoch 308/500  Train Loss: 1190113.5000  Val Loss: 430607.8438  Val MSE: 250.3534  Val R2: 0.9529\n",
      "Epoch 309/500  Train Loss: 1190048.3750  Val Loss: 430670.7500  Val MSE: 250.3900  Val R2: 0.9529\n",
      "Epoch 310/500  Train Loss: 1189983.2500  Val Loss: 430733.6562  Val MSE: 250.4265  Val R2: 0.9529\n",
      "Epoch 311/500  Train Loss: 1189918.2500  Val Loss: 430796.5000  Val MSE: 250.4631  Val R2: 0.9529\n",
      "Epoch 312/500  Train Loss: 1189853.1250  Val Loss: 430859.3125  Val MSE: 250.4996  Val R2: 0.9529\n",
      "Epoch 313/500  Train Loss: 1189788.0000  Val Loss: 430922.0625  Val MSE: 250.5361  Val R2: 0.9529\n",
      "Epoch 314/500  Train Loss: 1189723.1250  Val Loss: 430984.7500  Val MSE: 250.5726  Val R2: 0.9529\n",
      "Epoch 315/500  Train Loss: 1189658.1250  Val Loss: 431047.5000  Val MSE: 250.6090  Val R2: 0.9529\n",
      "Epoch 316/500  Train Loss: 1189592.8750  Val Loss: 431110.1562  Val MSE: 250.6454  Val R2: 0.9529\n",
      "Epoch 317/500  Train Loss: 1189528.2500  Val Loss: 431172.7500  Val MSE: 250.6818  Val R2: 0.9528\n",
      "Epoch 318/500  Train Loss: 1189463.2500  Val Loss: 431235.3438  Val MSE: 250.7182  Val R2: 0.9528\n",
      "Epoch 319/500  Train Loss: 1189398.2500  Val Loss: 431297.9062  Val MSE: 250.7546  Val R2: 0.9528\n",
      "Epoch 320/500  Train Loss: 1189333.3750  Val Loss: 431360.4062  Val MSE: 250.7910  Val R2: 0.9528\n",
      "Epoch 321/500  Train Loss: 1189268.7500  Val Loss: 431422.9375  Val MSE: 250.8273  Val R2: 0.9528\n",
      "Epoch 322/500  Train Loss: 1189203.7500  Val Loss: 431485.4062  Val MSE: 250.8636  Val R2: 0.9528\n",
      "Epoch 323/500  Train Loss: 1189139.2500  Val Loss: 431547.8438  Val MSE: 250.8999  Val R2: 0.9528\n",
      "Epoch 324/500  Train Loss: 1189074.6250  Val Loss: 431610.1875  Val MSE: 250.9362  Val R2: 0.9528\n",
      "Epoch 325/500  Train Loss: 1189009.8750  Val Loss: 431672.5625  Val MSE: 250.9724  Val R2: 0.9528\n",
      "Epoch 326/500  Train Loss: 1188945.2500  Val Loss: 431734.9062  Val MSE: 251.0087  Val R2: 0.9528\n",
      "Epoch 327/500  Train Loss: 1188880.6250  Val Loss: 431797.1875  Val MSE: 251.0449  Val R2: 0.9528\n",
      "Epoch 328/500  Train Loss: 1188816.0000  Val Loss: 431859.5000  Val MSE: 251.0811  Val R2: 0.9528\n",
      "Epoch 329/500  Train Loss: 1188751.5000  Val Loss: 431921.6562  Val MSE: 251.1172  Val R2: 0.9528\n",
      "Epoch 330/500  Train Loss: 1188686.8750  Val Loss: 431983.8438  Val MSE: 251.1534  Val R2: 0.9528\n",
      "Epoch 331/500  Train Loss: 1188622.3750  Val Loss: 432046.0000  Val MSE: 251.1895  Val R2: 0.9527\n",
      "Epoch 332/500  Train Loss: 1188558.0000  Val Loss: 432108.1562  Val MSE: 251.2257  Val R2: 0.9527\n",
      "Epoch 333/500  Train Loss: 1188493.6250  Val Loss: 432170.2500  Val MSE: 251.2618  Val R2: 0.9527\n",
      "Epoch 334/500  Train Loss: 1188429.2500  Val Loss: 432232.3438  Val MSE: 251.2979  Val R2: 0.9527\n",
      "Epoch 335/500  Train Loss: 1188364.7500  Val Loss: 432294.3438  Val MSE: 251.3339  Val R2: 0.9527\n",
      "Epoch 336/500  Train Loss: 1188300.2500  Val Loss: 432356.3438  Val MSE: 251.3700  Val R2: 0.9527\n",
      "Epoch 337/500  Train Loss: 1188236.0000  Val Loss: 432418.3125  Val MSE: 251.4060  Val R2: 0.9527\n",
      "Epoch 338/500  Train Loss: 1188171.7500  Val Loss: 432480.2500  Val MSE: 251.4420  Val R2: 0.9527\n",
      "Epoch 339/500  Train Loss: 1188107.6250  Val Loss: 432542.0938  Val MSE: 251.4780  Val R2: 0.9527\n",
      "Epoch 340/500  Train Loss: 1188043.2500  Val Loss: 432604.0625  Val MSE: 251.5140  Val R2: 0.9527\n",
      "Epoch 341/500  Train Loss: 1187979.1250  Val Loss: 432665.9375  Val MSE: 251.5499  Val R2: 0.9527\n",
      "Epoch 342/500  Train Loss: 1187914.8750  Val Loss: 432727.6875  Val MSE: 251.5859  Val R2: 0.9527\n",
      "Epoch 343/500  Train Loss: 1187850.7500  Val Loss: 432789.5000  Val MSE: 251.6218  Val R2: 0.9527\n",
      "Epoch 344/500  Train Loss: 1187786.6250  Val Loss: 432851.1875  Val MSE: 251.6577  Val R2: 0.9527\n",
      "Epoch 345/500  Train Loss: 1187722.2500  Val Loss: 432912.9062  Val MSE: 251.6936  Val R2: 0.9527\n",
      "Epoch 346/500  Train Loss: 1187658.3750  Val Loss: 432974.6562  Val MSE: 251.7294  Val R2: 0.9526\n",
      "Epoch 347/500  Train Loss: 1187594.2500  Val Loss: 433036.3125  Val MSE: 251.7653  Val R2: 0.9526\n",
      "Epoch 348/500  Train Loss: 1187530.3750  Val Loss: 433098.0000  Val MSE: 251.8011  Val R2: 0.9526\n",
      "Epoch 349/500  Train Loss: 1187466.2500  Val Loss: 433159.5625  Val MSE: 251.8369  Val R2: 0.9526\n",
      "Epoch 350/500  Train Loss: 1187402.3750  Val Loss: 433221.1562  Val MSE: 251.8727  Val R2: 0.9526\n",
      "Epoch 351/500  Train Loss: 1187338.3750  Val Loss: 433282.6562  Val MSE: 251.9085  Val R2: 0.9526\n",
      "Epoch 352/500  Train Loss: 1187274.5000  Val Loss: 433344.1562  Val MSE: 251.9443  Val R2: 0.9526\n",
      "Epoch 353/500  Train Loss: 1187210.7500  Val Loss: 433405.6562  Val MSE: 251.9800  Val R2: 0.9526\n",
      "Epoch 354/500  Train Loss: 1187146.7500  Val Loss: 433467.0938  Val MSE: 252.0158  Val R2: 0.9526\n",
      "Epoch 355/500  Train Loss: 1187082.8750  Val Loss: 433528.5625  Val MSE: 252.0515  Val R2: 0.9526\n",
      "Epoch 356/500  Train Loss: 1187019.2500  Val Loss: 433589.9375  Val MSE: 252.0872  Val R2: 0.9526\n",
      "Epoch 357/500  Train Loss: 1186955.2500  Val Loss: 433651.3438  Val MSE: 252.1229  Val R2: 0.9526\n",
      "Epoch 358/500  Train Loss: 1186891.5000  Val Loss: 433712.6875  Val MSE: 252.1585  Val R2: 0.9526\n",
      "Epoch 359/500  Train Loss: 1186828.0000  Val Loss: 433773.9375  Val MSE: 252.1942  Val R2: 0.9526\n",
      "Epoch 360/500  Train Loss: 1186764.1250  Val Loss: 433835.2500  Val MSE: 252.2298  Val R2: 0.9526\n",
      "Epoch 361/500  Train Loss: 1186700.5000  Val Loss: 433896.5000  Val MSE: 252.2654  Val R2: 0.9525\n",
      "Epoch 362/500  Train Loss: 1186636.7500  Val Loss: 433957.7500  Val MSE: 252.3010  Val R2: 0.9525\n",
      "Epoch 363/500  Train Loss: 1186573.2500  Val Loss: 434018.9375  Val MSE: 252.3366  Val R2: 0.9525\n",
      "Epoch 364/500  Train Loss: 1186509.6250  Val Loss: 434080.0938  Val MSE: 252.3722  Val R2: 0.9525\n",
      "Epoch 365/500  Train Loss: 1186446.1250  Val Loss: 434141.2500  Val MSE: 252.4077  Val R2: 0.9525\n",
      "Epoch 366/500  Train Loss: 1186382.6250  Val Loss: 434202.3125  Val MSE: 252.4432  Val R2: 0.9525\n",
      "Epoch 367/500  Train Loss: 1186319.0000  Val Loss: 434263.4375  Val MSE: 252.4787  Val R2: 0.9525\n",
      "Epoch 368/500  Train Loss: 1186255.5000  Val Loss: 434324.4375  Val MSE: 252.5142  Val R2: 0.9525\n",
      "Epoch 369/500  Train Loss: 1186191.8750  Val Loss: 434385.5625  Val MSE: 252.5497  Val R2: 0.9525\n",
      "Epoch 370/500  Train Loss: 1186128.5000  Val Loss: 434446.5625  Val MSE: 252.5852  Val R2: 0.9525\n",
      "Epoch 371/500  Train Loss: 1186065.1250  Val Loss: 434507.4375  Val MSE: 252.6206  Val R2: 0.9525\n",
      "Epoch 372/500  Train Loss: 1186001.7500  Val Loss: 434568.4375  Val MSE: 252.6561  Val R2: 0.9525\n",
      "Epoch 373/500  Train Loss: 1185938.2500  Val Loss: 434629.4062  Val MSE: 252.6915  Val R2: 0.9525\n",
      "Epoch 374/500  Train Loss: 1185874.8750  Val Loss: 434690.3125  Val MSE: 252.7269  Val R2: 0.9525\n",
      "Epoch 375/500  Train Loss: 1185811.7500  Val Loss: 434751.1562  Val MSE: 252.7623  Val R2: 0.9525\n",
      "Epoch 376/500  Train Loss: 1185748.2500  Val Loss: 434812.0000  Val MSE: 252.7977  Val R2: 0.9524\n",
      "Epoch 377/500  Train Loss: 1185685.1250  Val Loss: 434872.8438  Val MSE: 252.8330  Val R2: 0.9524\n",
      "Epoch 378/500  Train Loss: 1185621.7500  Val Loss: 434933.5938  Val MSE: 252.8684  Val R2: 0.9524\n",
      "Epoch 379/500  Train Loss: 1185558.5000  Val Loss: 434994.3125  Val MSE: 252.9037  Val R2: 0.9524\n",
      "Epoch 380/500  Train Loss: 1185495.3750  Val Loss: 435055.0938  Val MSE: 252.9390  Val R2: 0.9524\n",
      "Epoch 381/500  Train Loss: 1185432.2500  Val Loss: 435115.8125  Val MSE: 252.9743  Val R2: 0.9524\n",
      "Epoch 382/500  Train Loss: 1185368.8750  Val Loss: 435176.5625  Val MSE: 253.0096  Val R2: 0.9524\n",
      "Epoch 383/500  Train Loss: 1185305.7500  Val Loss: 435237.1562  Val MSE: 253.0448  Val R2: 0.9524\n",
      "Epoch 384/500  Train Loss: 1185242.6250  Val Loss: 435297.7500  Val MSE: 253.0801  Val R2: 0.9524\n",
      "Epoch 385/500  Train Loss: 1185179.7500  Val Loss: 435358.4062  Val MSE: 253.1153  Val R2: 0.9524\n",
      "Epoch 386/500  Train Loss: 1185116.3750  Val Loss: 435418.9062  Val MSE: 253.1506  Val R2: 0.9524\n",
      "Epoch 387/500  Train Loss: 1185053.5000  Val Loss: 435479.4375  Val MSE: 253.1858  Val R2: 0.9524\n",
      "Epoch 388/500  Train Loss: 1184989.3750  Val Loss: 435540.0000  Val MSE: 253.2210  Val R2: 0.9524\n",
      "Epoch 389/500  Train Loss: 1184920.2500  Val Loss: 435600.5625  Val MSE: 253.2562  Val R2: 0.9524\n",
      "Epoch 390/500  Train Loss: 1184856.8750  Val Loss: 435661.0625  Val MSE: 253.2913  Val R2: 0.9524\n",
      "Epoch 391/500  Train Loss: 1184794.0000  Val Loss: 435721.5938  Val MSE: 253.3265  Val R2: 0.9523\n",
      "Epoch 392/500  Train Loss: 1184731.2500  Val Loss: 435782.0938  Val MSE: 253.3617  Val R2: 0.9523\n",
      "Epoch 393/500  Train Loss: 1184667.8750  Val Loss: 435842.5000  Val MSE: 253.3968  Val R2: 0.9523\n",
      "Epoch 394/500  Train Loss: 1184605.2500  Val Loss: 435902.9375  Val MSE: 253.4320  Val R2: 0.9523\n",
      "Epoch 395/500  Train Loss: 1184542.2500  Val Loss: 435963.4062  Val MSE: 253.4671  Val R2: 0.9523\n",
      "Epoch 396/500  Train Loss: 1184479.5000  Val Loss: 436023.7500  Val MSE: 253.5022  Val R2: 0.9523\n",
      "Epoch 397/500  Train Loss: 1184416.7500  Val Loss: 436084.1562  Val MSE: 253.5373  Val R2: 0.9523\n",
      "Epoch 398/500  Train Loss: 1184354.0000  Val Loss: 436144.5000  Val MSE: 253.5724  Val R2: 0.9523\n",
      "Epoch 399/500  Train Loss: 1184291.1250  Val Loss: 436204.8125  Val MSE: 253.6074  Val R2: 0.9523\n",
      "Epoch 400/500  Train Loss: 1184228.3750  Val Loss: 436265.0938  Val MSE: 253.6425  Val R2: 0.9523\n",
      "Epoch 401/500  Train Loss: 1184165.6250  Val Loss: 436325.3438  Val MSE: 253.6775  Val R2: 0.9523\n",
      "Epoch 402/500  Train Loss: 1184103.0000  Val Loss: 436385.5625  Val MSE: 253.7125  Val R2: 0.9523\n",
      "Epoch 403/500  Train Loss: 1184040.3750  Val Loss: 436445.7500  Val MSE: 253.7475  Val R2: 0.9523\n",
      "Epoch 404/500  Train Loss: 1183977.5000  Val Loss: 436505.9375  Val MSE: 253.7825  Val R2: 0.9523\n",
      "Epoch 405/500  Train Loss: 1183915.0000  Val Loss: 436566.0938  Val MSE: 253.8175  Val R2: 0.9523\n",
      "Epoch 406/500  Train Loss: 1183852.2500  Val Loss: 436626.2500  Val MSE: 253.8525  Val R2: 0.9522\n",
      "Epoch 407/500  Train Loss: 1183789.6250  Val Loss: 436686.3125  Val MSE: 253.8874  Val R2: 0.9522\n",
      "Epoch 408/500  Train Loss: 1183727.2500  Val Loss: 436746.3438  Val MSE: 253.9223  Val R2: 0.9522\n",
      "Epoch 409/500  Train Loss: 1183664.3750  Val Loss: 436806.3438  Val MSE: 253.9572  Val R2: 0.9522\n",
      "Epoch 410/500  Train Loss: 1183602.1250  Val Loss: 436866.3438  Val MSE: 253.9921  Val R2: 0.9522\n",
      "Epoch 411/500  Train Loss: 1183539.6250  Val Loss: 436926.4062  Val MSE: 254.0270  Val R2: 0.9522\n",
      "Epoch 412/500  Train Loss: 1183477.1250  Val Loss: 436986.3125  Val MSE: 254.0618  Val R2: 0.9522\n",
      "Epoch 413/500  Train Loss: 1183414.3750  Val Loss: 437046.1875  Val MSE: 254.0966  Val R2: 0.9522\n",
      "Epoch 414/500  Train Loss: 1183352.0000  Val Loss: 437106.0938  Val MSE: 254.1315  Val R2: 0.9522\n",
      "Epoch 415/500  Train Loss: 1183289.7500  Val Loss: 437165.9375  Val MSE: 254.1663  Val R2: 0.9522\n",
      "Epoch 416/500  Train Loss: 1183227.2500  Val Loss: 437225.8125  Val MSE: 254.2011  Val R2: 0.9522\n",
      "Epoch 417/500  Train Loss: 1183164.7500  Val Loss: 437285.5625  Val MSE: 254.2358  Val R2: 0.9522\n",
      "Epoch 418/500  Train Loss: 1183102.3750  Val Loss: 437345.4062  Val MSE: 254.2706  Val R2: 0.9522\n",
      "Epoch 419/500  Train Loss: 1183040.1250  Val Loss: 437405.1875  Val MSE: 254.3053  Val R2: 0.9522\n",
      "Epoch 420/500  Train Loss: 1182977.6250  Val Loss: 437464.9062  Val MSE: 254.3401  Val R2: 0.9522\n",
      "Epoch 421/500  Train Loss: 1182915.3750  Val Loss: 437524.6562  Val MSE: 254.3748  Val R2: 0.9521\n",
      "Epoch 422/500  Train Loss: 1182853.0000  Val Loss: 437584.3125  Val MSE: 254.4095  Val R2: 0.9521\n",
      "Epoch 423/500  Train Loss: 1182790.6250  Val Loss: 437644.0000  Val MSE: 254.4442  Val R2: 0.9521\n",
      "Epoch 424/500  Train Loss: 1182728.6250  Val Loss: 437703.5938  Val MSE: 254.4789  Val R2: 0.9521\n",
      "Epoch 425/500  Train Loss: 1182666.2500  Val Loss: 437763.1875  Val MSE: 254.5135  Val R2: 0.9521\n",
      "Epoch 426/500  Train Loss: 1182604.1250  Val Loss: 437822.8438  Val MSE: 254.5482  Val R2: 0.9521\n",
      "Epoch 427/500  Train Loss: 1182541.8750  Val Loss: 437882.4375  Val MSE: 254.5828  Val R2: 0.9521\n",
      "Epoch 428/500  Train Loss: 1182479.6250  Val Loss: 437941.9375  Val MSE: 254.6174  Val R2: 0.9521\n",
      "Epoch 429/500  Train Loss: 1182417.6250  Val Loss: 438001.5000  Val MSE: 254.6520  Val R2: 0.9521\n",
      "Epoch 430/500  Train Loss: 1182355.3750  Val Loss: 438061.0625  Val MSE: 254.6867  Val R2: 0.9521\n",
      "Epoch 431/500  Train Loss: 1182293.3750  Val Loss: 438120.5625  Val MSE: 254.7212  Val R2: 0.9521\n",
      "Epoch 432/500  Train Loss: 1182231.1250  Val Loss: 438180.0625  Val MSE: 254.7558  Val R2: 0.9521\n",
      "Epoch 433/500  Train Loss: 1182169.1250  Val Loss: 438239.4375  Val MSE: 254.7904  Val R2: 0.9521\n",
      "Epoch 434/500  Train Loss: 1182107.2500  Val Loss: 438298.9062  Val MSE: 254.8249  Val R2: 0.9521\n",
      "Epoch 435/500  Train Loss: 1182045.1250  Val Loss: 438358.3125  Val MSE: 254.8595  Val R2: 0.9521\n",
      "Epoch 436/500  Train Loss: 1181983.0000  Val Loss: 438417.6875  Val MSE: 254.8940  Val R2: 0.9521\n",
      "Epoch 437/500  Train Loss: 1181920.7500  Val Loss: 438477.0625  Val MSE: 254.9285  Val R2: 0.9520\n",
      "Epoch 438/500  Train Loss: 1181859.0000  Val Loss: 438536.3438  Val MSE: 254.9630  Val R2: 0.9520\n",
      "Epoch 439/500  Train Loss: 1181796.8750  Val Loss: 438595.6875  Val MSE: 254.9975  Val R2: 0.9520\n",
      "Epoch 440/500  Train Loss: 1181735.1250  Val Loss: 438655.0000  Val MSE: 255.0320  Val R2: 0.9520\n",
      "Epoch 441/500  Train Loss: 1181673.0000  Val Loss: 438714.2500  Val MSE: 255.0665  Val R2: 0.9520\n",
      "Epoch 442/500  Train Loss: 1181611.2500  Val Loss: 438773.5625  Val MSE: 255.1009  Val R2: 0.9520\n",
      "Epoch 443/500  Train Loss: 1181549.3750  Val Loss: 438832.7500  Val MSE: 255.1353  Val R2: 0.9520\n",
      "Epoch 444/500  Train Loss: 1181487.3750  Val Loss: 438892.0000  Val MSE: 255.1698  Val R2: 0.9520\n",
      "Epoch 445/500  Train Loss: 1181425.6250  Val Loss: 438951.1875  Val MSE: 255.2042  Val R2: 0.9520\n",
      "Epoch 446/500  Train Loss: 1181363.7500  Val Loss: 439010.4062  Val MSE: 255.2386  Val R2: 0.9520\n",
      "Epoch 447/500  Train Loss: 1181302.0000  Val Loss: 439069.5625  Val MSE: 255.2730  Val R2: 0.9520\n",
      "Epoch 448/500  Train Loss: 1181239.8750  Val Loss: 439128.6875  Val MSE: 255.3074  Val R2: 0.9520\n",
      "Epoch 449/500  Train Loss: 1181178.2500  Val Loss: 439187.8125  Val MSE: 255.3417  Val R2: 0.9520\n",
      "Epoch 450/500  Train Loss: 1181116.5000  Val Loss: 439246.8438  Val MSE: 255.3761  Val R2: 0.9520\n",
      "Epoch 451/500  Train Loss: 1181054.6250  Val Loss: 439305.9375  Val MSE: 255.4104  Val R2: 0.9520\n",
      "Epoch 452/500  Train Loss: 1180993.0000  Val Loss: 439365.0000  Val MSE: 255.4448  Val R2: 0.9519\n",
      "Epoch 453/500  Train Loss: 1180931.2500  Val Loss: 439424.0625  Val MSE: 255.4791  Val R2: 0.9519\n",
      "Epoch 454/500  Train Loss: 1180869.6250  Val Loss: 439483.0000  Val MSE: 255.5134  Val R2: 0.9519\n",
      "Epoch 455/500  Train Loss: 1180808.0000  Val Loss: 439542.0000  Val MSE: 255.5477  Val R2: 0.9519\n",
      "Epoch 456/500  Train Loss: 1180746.2500  Val Loss: 439600.9375  Val MSE: 255.5819  Val R2: 0.9519\n",
      "Epoch 457/500  Train Loss: 1180684.5000  Val Loss: 439659.8438  Val MSE: 255.6162  Val R2: 0.9519\n",
      "Epoch 458/500  Train Loss: 1180623.0000  Val Loss: 439718.7500  Val MSE: 255.6505  Val R2: 0.9519\n",
      "Epoch 459/500  Train Loss: 1180561.2500  Val Loss: 439777.6875  Val MSE: 255.6847  Val R2: 0.9519\n",
      "Epoch 460/500  Train Loss: 1180499.7500  Val Loss: 439836.5625  Val MSE: 255.7189  Val R2: 0.9519\n",
      "Epoch 461/500  Train Loss: 1180438.1250  Val Loss: 439895.4375  Val MSE: 255.7532  Val R2: 0.9519\n",
      "Epoch 462/500  Train Loss: 1180376.7500  Val Loss: 439954.3125  Val MSE: 255.7874  Val R2: 0.9519\n",
      "Epoch 463/500  Train Loss: 1180315.1250  Val Loss: 440013.0938  Val MSE: 255.8216  Val R2: 0.9519\n",
      "Epoch 464/500  Train Loss: 1180253.5000  Val Loss: 440071.8438  Val MSE: 255.8557  Val R2: 0.9519\n",
      "Epoch 465/500  Train Loss: 1180191.8750  Val Loss: 440130.6562  Val MSE: 255.8899  Val R2: 0.9519\n",
      "Epoch 466/500  Train Loss: 1180130.6250  Val Loss: 440189.4062  Val MSE: 255.9241  Val R2: 0.9519\n",
      "Epoch 467/500  Train Loss: 1180069.1250  Val Loss: 440248.1562  Val MSE: 255.9582  Val R2: 0.9519\n",
      "Epoch 468/500  Train Loss: 1180007.5000  Val Loss: 440306.8125  Val MSE: 255.9923  Val R2: 0.9518\n",
      "Epoch 469/500  Train Loss: 1179946.0000  Val Loss: 440365.5000  Val MSE: 256.0264  Val R2: 0.9518\n",
      "Epoch 470/500  Train Loss: 1179884.5000  Val Loss: 440424.0938  Val MSE: 256.0606  Val R2: 0.9518\n",
      "Epoch 471/500  Train Loss: 1179823.2500  Val Loss: 440482.7500  Val MSE: 256.0946  Val R2: 0.9518\n",
      "Epoch 472/500  Train Loss: 1179761.8750  Val Loss: 440541.4375  Val MSE: 256.1287  Val R2: 0.9518\n",
      "Epoch 473/500  Train Loss: 1179700.5000  Val Loss: 440600.0000  Val MSE: 256.1628  Val R2: 0.9518\n",
      "Epoch 474/500  Train Loss: 1179639.1250  Val Loss: 440658.5938  Val MSE: 256.1969  Val R2: 0.9518\n",
      "Epoch 475/500  Train Loss: 1179577.7500  Val Loss: 440717.1875  Val MSE: 256.2309  Val R2: 0.9518\n",
      "Epoch 476/500  Train Loss: 1179516.5000  Val Loss: 440775.6562  Val MSE: 256.2649  Val R2: 0.9518\n",
      "Epoch 477/500  Train Loss: 1179455.2500  Val Loss: 440834.2500  Val MSE: 256.2990  Val R2: 0.9518\n",
      "Epoch 478/500  Train Loss: 1179393.8750  Val Loss: 440892.6875  Val MSE: 256.3330  Val R2: 0.9518\n",
      "Epoch 479/500  Train Loss: 1179332.7500  Val Loss: 440951.1875  Val MSE: 256.3670  Val R2: 0.9518\n",
      "Epoch 480/500  Train Loss: 1179271.3750  Val Loss: 441009.6562  Val MSE: 256.4010  Val R2: 0.9518\n",
      "Epoch 481/500  Train Loss: 1179210.2500  Val Loss: 441068.0938  Val MSE: 256.4349  Val R2: 0.9518\n",
      "Epoch 482/500  Train Loss: 1179148.8750  Val Loss: 441126.5625  Val MSE: 256.4689  Val R2: 0.9518\n",
      "Epoch 483/500  Train Loss: 1179087.6250  Val Loss: 441184.9062  Val MSE: 256.5029  Val R2: 0.9517\n",
      "Epoch 484/500  Train Loss: 1179026.5000  Val Loss: 441243.3125  Val MSE: 256.5368  Val R2: 0.9517\n",
      "Epoch 485/500  Train Loss: 1178965.2500  Val Loss: 441301.6562  Val MSE: 256.5707  Val R2: 0.9517\n",
      "Epoch 486/500  Train Loss: 1178904.0000  Val Loss: 441360.0000  Val MSE: 256.6047  Val R2: 0.9517\n",
      "Epoch 487/500  Train Loss: 1178842.8750  Val Loss: 441418.3438  Val MSE: 256.6386  Val R2: 0.9517\n",
      "Epoch 488/500  Train Loss: 1178781.7500  Val Loss: 441476.5938  Val MSE: 256.6725  Val R2: 0.9517\n",
      "Epoch 489/500  Train Loss: 1178720.7500  Val Loss: 441534.9375  Val MSE: 256.7064  Val R2: 0.9517\n",
      "Epoch 490/500  Train Loss: 1178659.3750  Val Loss: 441593.1875  Val MSE: 256.7402  Val R2: 0.9517\n",
      "Epoch 491/500  Train Loss: 1178598.6250  Val Loss: 441651.4062  Val MSE: 256.7741  Val R2: 0.9517\n",
      "Epoch 492/500  Train Loss: 1178537.5000  Val Loss: 441709.6875  Val MSE: 256.8079  Val R2: 0.9517\n",
      "Epoch 493/500  Train Loss: 1178476.2500  Val Loss: 441767.8438  Val MSE: 256.8418  Val R2: 0.9517\n",
      "Epoch 494/500  Train Loss: 1178415.2500  Val Loss: 441826.0625  Val MSE: 256.8756  Val R2: 0.9517\n",
      "Epoch 495/500  Train Loss: 1178354.2500  Val Loss: 441884.2500  Val MSE: 256.9094  Val R2: 0.9517\n",
      "Epoch 496/500  Train Loss: 1178293.2500  Val Loss: 441942.4062  Val MSE: 256.9432  Val R2: 0.9517\n",
      "Epoch 497/500  Train Loss: 1178232.2500  Val Loss: 442000.5000  Val MSE: 256.9770  Val R2: 0.9517\n",
      "Epoch 498/500  Train Loss: 1178171.3750  Val Loss: 442058.5938  Val MSE: 257.0108  Val R2: 0.9517\n",
      "Epoch 499/500  Train Loss: 1178110.3750  Val Loss: 442116.6875  Val MSE: 257.0446  Val R2: 0.9516\n",
      "Epoch 500/500  Train Loss: 1178049.5000  Val Loss: 442174.6875  Val MSE: 257.0784  Val R2: 0.9516\n",
      "Training finished. Best epoch: 1 with val_loss=409020.6875\n",
      "== Son Performans Metrikleri ==\n",
      "mse: 257.07835307871477\n",
      "mae: 8.924217522852752\n",
      "r2: 0.9516405900121105\n"
     ]
    }
   ],
   "source": [
    "predictor = TrafficPredictor(\n",
    "    'lstm',\n",
    "    sensors,\n",
    "    X_STEP,\n",
    "    Y_STEP,\n",
    "    pca_model=dataset.pca\n",
    ")\n",
    "predictor.train(train_loader, val_loader, epochs=500, \n",
    "                save_path=PROJECT_ROOT.joinpath(\"models/lstm.pt\"), \n",
    "                save_optimizer=True)\n",
    "predictor.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
