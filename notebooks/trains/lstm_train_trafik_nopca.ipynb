{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d924a0ab",
   "metadata": {},
   "source": [
    "# LSTM Train - Trafik - No PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "100dc28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append('../..')\n",
    "from src import config\n",
    "from src.utils.dataset import TrafficDataset\n",
    "from src.utils.model import TrafficPredictor\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7159ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = config.DATA_INTERIM\n",
    "df = pd.read_parquet(DATASET_PATH / 'sample.parquet')\n",
    "df = df.fillna(0)\n",
    "X_STEP, Y_STEP = 2, 1\n",
    "data_array = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ae0354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000  Train Loss: 15461.1621  Val Loss: 15185.7363  Val MSE: 15185.7354  Val R2: -1.6409\n",
      "Epoch 2/1000  Train Loss: 15450.1309  Val Loss: 15173.7812  Val MSE: 15173.7803  Val R2: -1.6388\n",
      "Epoch 3/1000  Train Loss: 15438.2051  Val Loss: 15161.0498  Val MSE: 15161.0498  Val R2: -1.6366\n",
      "Epoch 4/1000  Train Loss: 15425.5039  Val Loss: 15147.6631  Val MSE: 15147.6631  Val R2: -1.6343\n",
      "Epoch 5/1000  Train Loss: 15412.1504  Val Loss: 15133.7363  Val MSE: 15133.7354  Val R2: -1.6319\n",
      "Epoch 6/1000  Train Loss: 15398.2549  Val Loss: 15119.3672  Val MSE: 15119.3672  Val R2: -1.6294\n",
      "Epoch 7/1000  Train Loss: 15383.9199  Val Loss: 15104.6436  Val MSE: 15104.6455  Val R2: -1.6268\n",
      "Epoch 8/1000  Train Loss: 15369.2324  Val Loss: 15089.6484  Val MSE: 15089.6475  Val R2: -1.6242\n",
      "Epoch 9/1000  Train Loss: 15354.2695  Val Loss: 15074.4404  Val MSE: 15074.4395  Val R2: -1.6216\n",
      "Epoch 10/1000  Train Loss: 15339.0957  Val Loss: 15059.0771  Val MSE: 15059.0771  Val R2: -1.6189\n",
      "Epoch 11/1000  Train Loss: 15323.7715  Val Loss: 15043.6123  Val MSE: 15043.6123  Val R2: -1.6162\n",
      "Epoch 12/1000  Train Loss: 15308.3428  Val Loss: 15028.0869  Val MSE: 15028.0859  Val R2: -1.6135\n",
      "Epoch 13/1000  Train Loss: 15292.8525  Val Loss: 15012.5361  Val MSE: 15012.5361  Val R2: -1.6108\n",
      "Epoch 14/1000  Train Loss: 15277.3398  Val Loss: 14996.9941  Val MSE: 14996.9941  Val R2: -1.6081\n",
      "Epoch 15/1000  Train Loss: 15261.8340  Val Loss: 14981.4873  Val MSE: 14981.4873  Val R2: -1.6054\n",
      "Epoch 16/1000  Train Loss: 15246.3633  Val Loss: 14966.0371  Val MSE: 14966.0371  Val R2: -1.6027\n",
      "Epoch 17/1000  Train Loss: 15230.9502  Val Loss: 14950.6621  Val MSE: 14950.6621  Val R2: -1.6000\n",
      "Epoch 18/1000  Train Loss: 15215.6133  Val Loss: 14935.3760  Val MSE: 14935.3750  Val R2: -1.5974\n",
      "Epoch 19/1000  Train Loss: 15200.3613  Val Loss: 14920.1885  Val MSE: 14920.1885  Val R2: -1.5947\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 20/1000  Train Loss: 15185.2100  Val Loss: 14905.1074  Val MSE: 14905.1064  Val R2: -1.5921\n",
      "Epoch 21/1000  Train Loss: 15170.1650  Val Loss: 14890.1338  Val MSE: 14890.1338  Val R2: -1.5895\n",
      "Epoch 22/1000  Train Loss: 15155.2266  Val Loss: 14875.2725  Val MSE: 14875.2725  Val R2: -1.5869\n",
      "Epoch 23/1000  Train Loss: 15140.4014  Val Loss: 14860.5195  Val MSE: 14860.5195  Val R2: -1.5844\n",
      "Epoch 24/1000  Train Loss: 15125.6836  Val Loss: 14845.8750  Val MSE: 14845.8750  Val R2: -1.5818\n",
      "Epoch 25/1000  Train Loss: 15111.0742  Val Loss: 14831.3369  Val MSE: 14831.3359  Val R2: -1.5793\n",
      "Epoch 26/1000  Train Loss: 15096.5684  Val Loss: 14816.8965  Val MSE: 14816.8965  Val R2: -1.5768\n",
      "Epoch 27/1000  Train Loss: 15082.1641  Val Loss: 14802.5537  Val MSE: 14802.5527  Val R2: -1.5743\n",
      "Epoch 28/1000  Train Loss: 15067.8525  Val Loss: 14788.2998  Val MSE: 14788.3008  Val R2: -1.5718\n",
      "Epoch 29/1000  Train Loss: 15053.6338  Val Loss: 14774.1328  Val MSE: 14774.1338  Val R2: -1.5693\n",
      "Epoch 30/1000  Train Loss: 15039.5000  Val Loss: 14760.0488  Val MSE: 14760.0488  Val R2: -1.5669\n",
      "Epoch 31/1000  Train Loss: 15025.4482  Val Loss: 14746.0400  Val MSE: 14746.0391  Val R2: -1.5645\n",
      "Epoch 32/1000  Train Loss: 15011.4727  Val Loss: 14732.1055  Val MSE: 14732.1045  Val R2: -1.5620\n",
      "Epoch 33/1000  Train Loss: 14997.5703  Val Loss: 14718.2363  Val MSE: 14718.2373  Val R2: -1.5596\n",
      "Epoch 34/1000  Train Loss: 14983.7354  Val Loss: 14704.4365  Val MSE: 14704.4365  Val R2: -1.5572\n",
      "Epoch 35/1000  Train Loss: 14969.9658  Val Loss: 14690.6963  Val MSE: 14690.6963  Val R2: -1.5548\n",
      "Epoch 36/1000  Train Loss: 14956.2568  Val Loss: 14677.0146  Val MSE: 14677.0137  Val R2: -1.5525\n",
      "Epoch 37/1000  Train Loss: 14942.6074  Val Loss: 14663.3896  Val MSE: 14663.3877  Val R2: -1.5501\n",
      "Epoch 38/1000  Train Loss: 14929.0127  Val Loss: 14649.8145  Val MSE: 14649.8135  Val R2: -1.5477\n",
      "Epoch 39/1000  Train Loss: 14915.4707  Val Loss: 14636.2939  Val MSE: 14636.2920  Val R2: -1.5454\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 40/1000  Train Loss: 14901.9805  Val Loss: 14622.8184  Val MSE: 14622.8193  Val R2: -1.5430\n",
      "Epoch 41/1000  Train Loss: 14888.5371  Val Loss: 14609.3906  Val MSE: 14609.3916  Val R2: -1.5407\n",
      "Epoch 42/1000  Train Loss: 14875.1416  Val Loss: 14596.0098  Val MSE: 14596.0098  Val R2: -1.5384\n",
      "Epoch 43/1000  Train Loss: 14861.7900  Val Loss: 14582.6709  Val MSE: 14582.6709  Val R2: -1.5360\n",
      "Epoch 44/1000  Train Loss: 14848.4824  Val Loss: 14569.3730  Val MSE: 14569.3730  Val R2: -1.5337\n",
      "Epoch 45/1000  Train Loss: 14835.2158  Val Loss: 14556.1182  Val MSE: 14556.1172  Val R2: -1.5314\n",
      "Epoch 46/1000  Train Loss: 14821.9912  Val Loss: 14542.9014  Val MSE: 14542.9014  Val R2: -1.5291\n",
      "Epoch 47/1000  Train Loss: 14808.8057  Val Loss: 14529.7227  Val MSE: 14529.7227  Val R2: -1.5268\n",
      "Epoch 48/1000  Train Loss: 14795.6572  Val Loss: 14516.5820  Val MSE: 14516.5830  Val R2: -1.5246\n",
      "Epoch 49/1000  Train Loss: 14782.5479  Val Loss: 14503.4795  Val MSE: 14503.4775  Val R2: -1.5223\n",
      "Epoch 50/1000  Train Loss: 14769.4736  Val Loss: 14490.4092  Val MSE: 14490.4092  Val R2: -1.5200\n",
      "Epoch 51/1000  Train Loss: 14756.4346  Val Loss: 14477.3750  Val MSE: 14477.3760  Val R2: -1.5177\n",
      "Epoch 52/1000  Train Loss: 14743.4307  Val Loss: 14464.3760  Val MSE: 14464.3760  Val R2: -1.5155\n",
      "Epoch 53/1000  Train Loss: 14730.4600  Val Loss: 14451.4082  Val MSE: 14451.4082  Val R2: -1.5132\n",
      "Epoch 54/1000  Train Loss: 14717.5254  Val Loss: 14438.4766  Val MSE: 14438.4756  Val R2: -1.5110\n",
      "Epoch 55/1000  Train Loss: 14704.6211  Val Loss: 14425.5732  Val MSE: 14425.5742  Val R2: -1.5087\n",
      "Epoch 56/1000  Train Loss: 14691.7480  Val Loss: 14412.7021  Val MSE: 14412.7031  Val R2: -1.5065\n",
      "Epoch 57/1000  Train Loss: 14678.9082  Val Loss: 14399.8623  Val MSE: 14399.8633  Val R2: -1.5043\n",
      "Epoch 58/1000  Train Loss: 14666.0977  Val Loss: 14387.0537  Val MSE: 14387.0527  Val R2: -1.5020\n",
      "Epoch 59/1000  Train Loss: 14653.3184  Val Loss: 14374.2734  Val MSE: 14374.2734  Val R2: -1.4998\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 60/1000  Train Loss: 14640.5684  Val Loss: 14361.5215  Val MSE: 14361.5215  Val R2: -1.4976\n",
      "Epoch 61/1000  Train Loss: 14627.8447  Val Loss: 14348.8018  Val MSE: 14348.8008  Val R2: -1.4954\n",
      "Epoch 62/1000  Train Loss: 14615.1533  Val Loss: 14336.1074  Val MSE: 14336.1074  Val R2: -1.4932\n",
      "Epoch 63/1000  Train Loss: 14602.4893  Val Loss: 14323.4414  Val MSE: 14323.4414  Val R2: -1.4910\n",
      "Epoch 64/1000  Train Loss: 14589.8516  Val Loss: 14310.8027  Val MSE: 14310.8027  Val R2: -1.4888\n",
      "Epoch 65/1000  Train Loss: 14577.2432  Val Loss: 14298.1895  Val MSE: 14298.1914  Val R2: -1.4866\n",
      "Epoch 66/1000  Train Loss: 14564.6592  Val Loss: 14285.6055  Val MSE: 14285.6055  Val R2: -1.4844\n",
      "Epoch 67/1000  Train Loss: 14552.1035  Val Loss: 14273.0459  Val MSE: 14273.0479  Val R2: -1.4822\n",
      "Epoch 68/1000  Train Loss: 14539.5713  Val Loss: 14260.5127  Val MSE: 14260.5127  Val R2: -1.4800\n",
      "Epoch 69/1000  Train Loss: 14527.0664  Val Loss: 14248.0059  Val MSE: 14248.0049  Val R2: -1.4778\n",
      "Epoch 70/1000  Train Loss: 14514.5889  Val Loss: 14235.5215  Val MSE: 14235.5215  Val R2: -1.4757\n",
      "Epoch 71/1000  Train Loss: 14502.1338  Val Loss: 14223.0645  Val MSE: 14223.0635  Val R2: -1.4735\n",
      "Epoch 72/1000  Train Loss: 14489.7041  Val Loss: 14210.6299  Val MSE: 14210.6289  Val R2: -1.4713\n",
      "Epoch 73/1000  Train Loss: 14477.2988  Val Loss: 14198.2188  Val MSE: 14198.2207  Val R2: -1.4692\n",
      "Epoch 74/1000  Train Loss: 14464.9170  Val Loss: 14185.8340  Val MSE: 14185.8330  Val R2: -1.4670\n",
      "Epoch 75/1000  Train Loss: 14452.5586  Val Loss: 14173.4697  Val MSE: 14173.4697  Val R2: -1.4649\n",
      "Epoch 76/1000  Train Loss: 14440.2236  Val Loss: 14161.1299  Val MSE: 14161.1289  Val R2: -1.4627\n",
      "Epoch 77/1000  Train Loss: 14427.9121  Val Loss: 14148.8135  Val MSE: 14148.8135  Val R2: -1.4606\n",
      "Epoch 78/1000  Train Loss: 14415.6221  Val Loss: 14136.5176  Val MSE: 14136.5176  Val R2: -1.4585\n",
      "Epoch 79/1000  Train Loss: 14403.3545  Val Loss: 14124.2451  Val MSE: 14124.2451  Val R2: -1.4563\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 80/1000  Train Loss: 14391.1104  Val Loss: 14111.9941  Val MSE: 14111.9941  Val R2: -1.4542\n",
      "Epoch 81/1000  Train Loss: 14378.8877  Val Loss: 14099.7637  Val MSE: 14099.7646  Val R2: -1.4521\n",
      "Epoch 82/1000  Train Loss: 14366.6855  Val Loss: 14087.5576  Val MSE: 14087.5576  Val R2: -1.4499\n",
      "Epoch 83/1000  Train Loss: 14354.5059  Val Loss: 14075.3701  Val MSE: 14075.3711  Val R2: -1.4478\n",
      "Epoch 84/1000  Train Loss: 14342.3477  Val Loss: 14063.2041  Val MSE: 14063.2051  Val R2: -1.4457\n",
      "Epoch 85/1000  Train Loss: 14330.2090  Val Loss: 14051.0596  Val MSE: 14051.0605  Val R2: -1.4436\n",
      "Epoch 86/1000  Train Loss: 14318.0928  Val Loss: 14038.9365  Val MSE: 14038.9355  Val R2: -1.4415\n",
      "Epoch 87/1000  Train Loss: 14305.9941  Val Loss: 14026.8311  Val MSE: 14026.8320  Val R2: -1.4394\n",
      "Epoch 88/1000  Train Loss: 14293.9180  Val Loss: 14014.7461  Val MSE: 14014.7471  Val R2: -1.4373\n",
      "Epoch 89/1000  Train Loss: 14281.8613  Val Loss: 14002.6826  Val MSE: 14002.6826  Val R2: -1.4352\n",
      "Epoch 90/1000  Train Loss: 14269.8232  Val Loss: 13990.6377  Val MSE: 13990.6377  Val R2: -1.4331\n",
      "Epoch 91/1000  Train Loss: 14257.8057  Val Loss: 13978.6113  Val MSE: 13978.6113  Val R2: -1.4310\n",
      "Epoch 92/1000  Train Loss: 14245.8086  Val Loss: 13966.6064  Val MSE: 13966.6055  Val R2: -1.4289\n",
      "Epoch 93/1000  Train Loss: 14233.8291  Val Loss: 13954.6172  Val MSE: 13954.6172  Val R2: -1.4268\n",
      "Epoch 94/1000  Train Loss: 14221.8691  Val Loss: 13942.6504  Val MSE: 13942.6494  Val R2: -1.4247\n",
      "Epoch 95/1000  Train Loss: 14209.9268  Val Loss: 13930.6992  Val MSE: 13930.6992  Val R2: -1.4227\n",
      "Epoch 96/1000  Train Loss: 14198.0059  Val Loss: 13918.7676  Val MSE: 13918.7686  Val R2: -1.4206\n",
      "Epoch 97/1000  Train Loss: 14186.0996  Val Loss: 13906.8555  Val MSE: 13906.8545  Val R2: -1.4185\n",
      "Epoch 98/1000  Train Loss: 14174.2139  Val Loss: 13894.9609  Val MSE: 13894.9600  Val R2: -1.4164\n",
      "Epoch 99/1000  Train Loss: 14162.3457  Val Loss: 13883.0840  Val MSE: 13883.0840  Val R2: -1.4144\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 100/1000  Train Loss: 14150.4961  Val Loss: 13871.2256  Val MSE: 13871.2246  Val R2: -1.4123\n",
      "Epoch 101/1000  Train Loss: 14138.6631  Val Loss: 13859.3828  Val MSE: 13859.3828  Val R2: -1.4103\n",
      "Epoch 102/1000  Train Loss: 14126.8486  Val Loss: 13847.5586  Val MSE: 13847.5586  Val R2: -1.4082\n",
      "Epoch 103/1000  Train Loss: 14115.0498  Val Loss: 13835.7529  Val MSE: 13835.7529  Val R2: -1.4062\n",
      "Epoch 104/1000  Train Loss: 14103.2715  Val Loss: 13823.9619  Val MSE: 13823.9639  Val R2: -1.4041\n",
      "Epoch 105/1000  Train Loss: 14091.5088  Val Loss: 13812.1885  Val MSE: 13812.1895  Val R2: -1.4021\n",
      "Epoch 106/1000  Train Loss: 14079.7637  Val Loss: 13800.4355  Val MSE: 13800.4355  Val R2: -1.4000\n",
      "Epoch 107/1000  Train Loss: 14068.0342  Val Loss: 13788.6963  Val MSE: 13788.6963  Val R2: -1.3980\n",
      "Epoch 108/1000  Train Loss: 14056.3213  Val Loss: 13776.9727  Val MSE: 13776.9736  Val R2: -1.3959\n",
      "Epoch 109/1000  Train Loss: 14044.6250  Val Loss: 13765.2676  Val MSE: 13765.2686  Val R2: -1.3939\n",
      "Epoch 110/1000  Train Loss: 14032.9463  Val Loss: 13753.5791  Val MSE: 13753.5791  Val R2: -1.3919\n",
      "Epoch 111/1000  Train Loss: 14021.2842  Val Loss: 13741.9062  Val MSE: 13741.9072  Val R2: -1.3898\n",
      "Epoch 112/1000  Train Loss: 14009.6367  Val Loss: 13730.2500  Val MSE: 13730.2490  Val R2: -1.3878\n",
      "Epoch 113/1000  Train Loss: 13998.0078  Val Loss: 13718.6084  Val MSE: 13718.6094  Val R2: -1.3858\n",
      "Epoch 114/1000  Train Loss: 13986.3936  Val Loss: 13706.9844  Val MSE: 13706.9844  Val R2: -1.3838\n",
      "Epoch 115/1000  Train Loss: 13974.7939  Val Loss: 13695.3750  Val MSE: 13695.3750  Val R2: -1.3817\n",
      "Epoch 116/1000  Train Loss: 13963.2109  Val Loss: 13683.7812  Val MSE: 13683.7822  Val R2: -1.3797\n",
      "Epoch 117/1000  Train Loss: 13951.6436  Val Loss: 13672.2051  Val MSE: 13672.2051  Val R2: -1.3777\n",
      "Epoch 118/1000  Train Loss: 13940.0908  Val Loss: 13660.6416  Val MSE: 13660.6416  Val R2: -1.3757\n",
      "Epoch 119/1000  Train Loss: 13928.5566  Val Loss: 13649.0947  Val MSE: 13649.0938  Val R2: -1.3737\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 120/1000  Train Loss: 13917.0361  Val Loss: 13637.5625  Val MSE: 13637.5625  Val R2: -1.3717\n",
      "Epoch 121/1000  Train Loss: 13905.5293  Val Loss: 13626.0469  Val MSE: 13626.0469  Val R2: -1.3697\n",
      "Epoch 122/1000  Train Loss: 13894.0381  Val Loss: 13614.5449  Val MSE: 13614.5449  Val R2: -1.3677\n",
      "Epoch 123/1000  Train Loss: 13882.5615  Val Loss: 13603.0586  Val MSE: 13603.0586  Val R2: -1.3657\n",
      "Epoch 124/1000  Train Loss: 13871.1025  Val Loss: 13591.5869  Val MSE: 13591.5869  Val R2: -1.3637\n",
      "Epoch 125/1000  Train Loss: 13859.6572  Val Loss: 13580.1299  Val MSE: 13580.1299  Val R2: -1.3617\n",
      "Epoch 126/1000  Train Loss: 13848.2256  Val Loss: 13568.6885  Val MSE: 13568.6885  Val R2: -1.3597\n",
      "Epoch 127/1000  Train Loss: 13836.8096  Val Loss: 13557.2607  Val MSE: 13557.2598  Val R2: -1.3577\n",
      "Epoch 128/1000  Train Loss: 13825.4062  Val Loss: 13545.8477  Val MSE: 13545.8477  Val R2: -1.3557\n",
      "Epoch 129/1000  Train Loss: 13814.0195  Val Loss: 13534.4482  Val MSE: 13534.4482  Val R2: -1.3538\n",
      "Epoch 130/1000  Train Loss: 13802.6475  Val Loss: 13523.0645  Val MSE: 13523.0645  Val R2: -1.3518\n",
      "Epoch 131/1000  Train Loss: 13791.2871  Val Loss: 13511.6934  Val MSE: 13511.6943  Val R2: -1.3498\n",
      "Epoch 132/1000  Train Loss: 13779.9434  Val Loss: 13500.3379  Val MSE: 13500.3389  Val R2: -1.3478\n",
      "Epoch 133/1000  Train Loss: 13768.6123  Val Loss: 13488.9951  Val MSE: 13488.9961  Val R2: -1.3458\n",
      "Epoch 134/1000  Train Loss: 13757.2969  Val Loss: 13477.6680  Val MSE: 13477.6689  Val R2: -1.3439\n",
      "Epoch 135/1000  Train Loss: 13745.9941  Val Loss: 13466.3545  Val MSE: 13466.3545  Val R2: -1.3419\n",
      "Epoch 136/1000  Train Loss: 13734.7051  Val Loss: 13455.0537  Val MSE: 13455.0547  Val R2: -1.3399\n",
      "Epoch 137/1000  Train Loss: 13723.4307  Val Loss: 13443.7686  Val MSE: 13443.7676  Val R2: -1.3380\n",
      "Epoch 138/1000  Train Loss: 13712.1709  Val Loss: 13432.4961  Val MSE: 13432.4951  Val R2: -1.3360\n",
      "Epoch 139/1000  Train Loss: 13700.9238  Val Loss: 13421.2354  Val MSE: 13421.2354  Val R2: -1.3341\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 140/1000  Train Loss: 13689.6895  Val Loss: 13409.9902  Val MSE: 13409.9912  Val R2: -1.3321\n",
      "Epoch 141/1000  Train Loss: 13678.4697  Val Loss: 13398.7588  Val MSE: 13398.7588  Val R2: -1.3302\n",
      "Epoch 142/1000  Train Loss: 13667.2617  Val Loss: 13387.5410  Val MSE: 13387.5400  Val R2: -1.3282\n",
      "Epoch 143/1000  Train Loss: 13656.0684  Val Loss: 13376.3359  Val MSE: 13376.3359  Val R2: -1.3263\n",
      "Epoch 144/1000  Train Loss: 13644.8906  Val Loss: 13365.1445  Val MSE: 13365.1445  Val R2: -1.3243\n",
      "Epoch 145/1000  Train Loss: 13633.7227  Val Loss: 13353.9658  Val MSE: 13353.9648  Val R2: -1.3224\n",
      "Epoch 146/1000  Train Loss: 13622.5684  Val Loss: 13342.7998  Val MSE: 13342.7998  Val R2: -1.3204\n",
      "Epoch 147/1000  Train Loss: 13611.4277  Val Loss: 13331.6465  Val MSE: 13331.6475  Val R2: -1.3185\n",
      "Epoch 148/1000  Train Loss: 13600.3027  Val Loss: 13320.5088  Val MSE: 13320.5078  Val R2: -1.3165\n",
      "Epoch 149/1000  Train Loss: 13589.1865  Val Loss: 13309.3828  Val MSE: 13309.3828  Val R2: -1.3146\n",
      "Epoch 150/1000  Train Loss: 13578.0859  Val Loss: 13298.2686  Val MSE: 13298.2676  Val R2: -1.3127\n",
      "Epoch 151/1000  Train Loss: 13566.9980  Val Loss: 13287.1670  Val MSE: 13287.1680  Val R2: -1.3107\n",
      "Epoch 152/1000  Train Loss: 13555.9219  Val Loss: 13276.0801  Val MSE: 13276.0801  Val R2: -1.3088\n",
      "Epoch 153/1000  Train Loss: 13544.8594  Val Loss: 13265.0049  Val MSE: 13265.0049  Val R2: -1.3069\n",
      "Epoch 154/1000  Train Loss: 13533.8086  Val Loss: 13253.9424  Val MSE: 13253.9424  Val R2: -1.3050\n",
      "Epoch 155/1000  Train Loss: 13522.7715  Val Loss: 13242.8926  Val MSE: 13242.8926  Val R2: -1.3030\n",
      "Epoch 156/1000  Train Loss: 13511.7461  Val Loss: 13231.8555  Val MSE: 13231.8555  Val R2: -1.3011\n",
      "Epoch 157/1000  Train Loss: 13500.7334  Val Loss: 13220.8320  Val MSE: 13220.8320  Val R2: -1.2992\n",
      "Epoch 158/1000  Train Loss: 13489.7344  Val Loss: 13209.8193  Val MSE: 13209.8184  Val R2: -1.2973\n",
      "Epoch 159/1000  Train Loss: 13478.7480  Val Loss: 13198.8203  Val MSE: 13198.8184  Val R2: -1.2954\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 160/1000  Train Loss: 13467.7715  Val Loss: 13187.8330  Val MSE: 13187.8330  Val R2: -1.2935\n",
      "Epoch 161/1000  Train Loss: 13456.8086  Val Loss: 13176.8574  Val MSE: 13176.8555  Val R2: -1.2916\n",
      "Epoch 162/1000  Train Loss: 13445.8584  Val Loss: 13165.8936  Val MSE: 13165.8936  Val R2: -1.2897\n",
      "Epoch 163/1000  Train Loss: 13434.9189  Val Loss: 13154.9434  Val MSE: 13154.9434  Val R2: -1.2878\n",
      "Epoch 164/1000  Train Loss: 13423.9951  Val Loss: 13144.0059  Val MSE: 13144.0049  Val R2: -1.2859\n",
      "Epoch 165/1000  Train Loss: 13413.0811  Val Loss: 13133.0781  Val MSE: 13133.0781  Val R2: -1.2840\n",
      "Epoch 166/1000  Train Loss: 13402.1787  Val Loss: 13122.1641  Val MSE: 13122.1650  Val R2: -1.2821\n",
      "Epoch 167/1000  Train Loss: 13391.2891  Val Loss: 13111.2617  Val MSE: 13111.2627  Val R2: -1.2802\n",
      "Epoch 168/1000  Train Loss: 13380.4121  Val Loss: 13100.3721  Val MSE: 13100.3721  Val R2: -1.2783\n",
      "Epoch 169/1000  Train Loss: 13369.5449  Val Loss: 13089.4941  Val MSE: 13089.4941  Val R2: -1.2764\n",
      "Epoch 170/1000  Train Loss: 13358.6914  Val Loss: 13078.6270  Val MSE: 13078.6270  Val R2: -1.2745\n",
      "Epoch 171/1000  Train Loss: 13347.8496  Val Loss: 13067.7725  Val MSE: 13067.7715  Val R2: -1.2726\n",
      "Epoch 172/1000  Train Loss: 13337.0205  Val Loss: 13056.9297  Val MSE: 13056.9297  Val R2: -1.2707\n",
      "Epoch 173/1000  Train Loss: 13326.2002  Val Loss: 13046.0977  Val MSE: 13046.0986  Val R2: -1.2688\n",
      "Epoch 174/1000  Train Loss: 13315.3936  Val Loss: 13035.2793  Val MSE: 13035.2783  Val R2: -1.2669\n",
      "Epoch 175/1000  Train Loss: 13304.5986  Val Loss: 13024.4717  Val MSE: 13024.4707  Val R2: -1.2651\n",
      "Epoch 176/1000  Train Loss: 13293.8164  Val Loss: 13013.6748  Val MSE: 13013.6748  Val R2: -1.2632\n",
      "Epoch 177/1000  Train Loss: 13283.0430  Val Loss: 13002.8916  Val MSE: 13002.8916  Val R2: -1.2613\n",
      "Epoch 178/1000  Train Loss: 13272.2842  Val Loss: 12992.1182  Val MSE: 12992.1172  Val R2: -1.2594\n",
      "Epoch 179/1000  Train Loss: 13261.5361  Val Loss: 12981.3574  Val MSE: 12981.3564  Val R2: -1.2576\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 180/1000  Train Loss: 13250.7979  Val Loss: 12970.6064  Val MSE: 12970.6064  Val R2: -1.2557\n",
      "Epoch 181/1000  Train Loss: 13240.0723  Val Loss: 12959.8672  Val MSE: 12959.8682  Val R2: -1.2538\n",
      "Epoch 182/1000  Train Loss: 13229.3584  Val Loss: 12949.1396  Val MSE: 12949.1406  Val R2: -1.2520\n",
      "Epoch 183/1000  Train Loss: 13218.6553  Val Loss: 12938.4248  Val MSE: 12938.4248  Val R2: -1.2501\n",
      "Epoch 184/1000  Train Loss: 13207.9658  Val Loss: 12927.7207  Val MSE: 12927.7207  Val R2: -1.2482\n",
      "Epoch 185/1000  Train Loss: 13197.2842  Val Loss: 12917.0293  Val MSE: 12917.0283  Val R2: -1.2464\n",
      "Epoch 186/1000  Train Loss: 13186.6162  Val Loss: 12906.3457  Val MSE: 12906.3457  Val R2: -1.2445\n",
      "Epoch 187/1000  Train Loss: 13175.9580  Val Loss: 12895.6758  Val MSE: 12895.6748  Val R2: -1.2427\n",
      "Epoch 188/1000  Train Loss: 13165.3105  Val Loss: 12885.0166  Val MSE: 12885.0156  Val R2: -1.2408\n",
      "Epoch 189/1000  Train Loss: 13154.6748  Val Loss: 12874.3662  Val MSE: 12874.3682  Val R2: -1.2390\n",
      "Epoch 190/1000  Train Loss: 13144.0508  Val Loss: 12863.7285  Val MSE: 12863.7305  Val R2: -1.2371\n",
      "Epoch 191/1000  Train Loss: 13133.4385  Val Loss: 12853.1035  Val MSE: 12853.1035  Val R2: -1.2353\n",
      "Epoch 192/1000  Train Loss: 13122.8350  Val Loss: 12842.4883  Val MSE: 12842.4893  Val R2: -1.2334\n",
      "Epoch 193/1000  Train Loss: 13112.2451  Val Loss: 12831.8848  Val MSE: 12831.8848  Val R2: -1.2316\n",
      "Epoch 194/1000  Train Loss: 13101.6650  Val Loss: 12821.2910  Val MSE: 12821.2910  Val R2: -1.2297\n",
      "Epoch 195/1000  Train Loss: 13091.0947  Val Loss: 12810.7090  Val MSE: 12810.7090  Val R2: -1.2279\n",
      "Epoch 196/1000  Train Loss: 13080.5371  Val Loss: 12800.1387  Val MSE: 12800.1377  Val R2: -1.2260\n",
      "Epoch 197/1000  Train Loss: 13069.9893  Val Loss: 12789.5781  Val MSE: 12789.5771  Val R2: -1.2242\n",
      "Epoch 198/1000  Train Loss: 13059.4531  Val Loss: 12779.0293  Val MSE: 12779.0283  Val R2: -1.2224\n",
      "Epoch 199/1000  Train Loss: 13048.9268  Val Loss: 12768.4902  Val MSE: 12768.4893  Val R2: -1.2205\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 200/1000  Train Loss: 13038.4121  Val Loss: 12757.9619  Val MSE: 12757.9609  Val R2: -1.2187\n",
      "Epoch 201/1000  Train Loss: 13027.9092  Val Loss: 12747.4453  Val MSE: 12747.4443  Val R2: -1.2169\n",
      "Epoch 202/1000  Train Loss: 13017.4150  Val Loss: 12736.9375  Val MSE: 12736.9375  Val R2: -1.2151\n",
      "Epoch 203/1000  Train Loss: 13006.9316  Val Loss: 12726.4414  Val MSE: 12726.4414  Val R2: -1.2132\n",
      "Epoch 204/1000  Train Loss: 12996.4600  Val Loss: 12715.9570  Val MSE: 12715.9570  Val R2: -1.2114\n",
      "Epoch 205/1000  Train Loss: 12985.9990  Val Loss: 12705.4814  Val MSE: 12705.4824  Val R2: -1.2096\n",
      "Epoch 206/1000  Train Loss: 12975.5498  Val Loss: 12695.0195  Val MSE: 12695.0186  Val R2: -1.2078\n",
      "Epoch 207/1000  Train Loss: 12965.1084  Val Loss: 12684.5645  Val MSE: 12684.5654  Val R2: -1.2060\n",
      "Epoch 208/1000  Train Loss: 12954.6787  Val Loss: 12674.1250  Val MSE: 12674.1230  Val R2: -1.2041\n",
      "Epoch 209/1000  Train Loss: 12944.2598  Val Loss: 12663.6904  Val MSE: 12663.6904  Val R2: -1.2023\n",
      "Epoch 210/1000  Train Loss: 12933.8516  Val Loss: 12653.2695  Val MSE: 12653.2686  Val R2: -1.2005\n",
      "Epoch 211/1000  Train Loss: 12923.4521  Val Loss: 12642.8564  Val MSE: 12642.8574  Val R2: -1.1987\n",
      "Epoch 212/1000  Train Loss: 12913.0654  Val Loss: 12632.4570  Val MSE: 12632.4570  Val R2: -1.1969\n",
      "Epoch 213/1000  Train Loss: 12902.6895  Val Loss: 12622.0664  Val MSE: 12622.0664  Val R2: -1.1951\n",
      "Epoch 214/1000  Train Loss: 12892.3223  Val Loss: 12611.6855  Val MSE: 12611.6855  Val R2: -1.1933\n",
      "Epoch 215/1000  Train Loss: 12881.9658  Val Loss: 12601.3164  Val MSE: 12601.3164  Val R2: -1.1915\n",
      "Epoch 216/1000  Train Loss: 12871.6191  Val Loss: 12590.9561  Val MSE: 12590.9561  Val R2: -1.1897\n",
      "Epoch 217/1000  Train Loss: 12861.2842  Val Loss: 12580.6084  Val MSE: 12580.6084  Val R2: -1.1879\n",
      "Epoch 218/1000  Train Loss: 12850.9580  Val Loss: 12570.2695  Val MSE: 12570.2695  Val R2: -1.1861\n",
      "Epoch 219/1000  Train Loss: 12840.6436  Val Loss: 12559.9404  Val MSE: 12559.9414  Val R2: -1.1843\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 220/1000  Train Loss: 12830.3389  Val Loss: 12549.6221  Val MSE: 12549.6221  Val R2: -1.1825\n",
      "Epoch 221/1000  Train Loss: 12820.0449  Val Loss: 12539.3154  Val MSE: 12539.3135  Val R2: -1.1807\n",
      "Epoch 222/1000  Train Loss: 12809.7598  Val Loss: 12529.0166  Val MSE: 12529.0156  Val R2: -1.1789\n",
      "Epoch 223/1000  Train Loss: 12799.4844  Val Loss: 12518.7305  Val MSE: 12518.7295  Val R2: -1.1771\n",
      "Epoch 224/1000  Train Loss: 12789.2207  Val Loss: 12508.4521  Val MSE: 12508.4512  Val R2: -1.1753\n",
      "Epoch 225/1000  Train Loss: 12778.9668  Val Loss: 12498.1865  Val MSE: 12498.1855  Val R2: -1.1735\n",
      "Epoch 226/1000  Train Loss: 12768.7227  Val Loss: 12487.9287  Val MSE: 12487.9277  Val R2: -1.1718\n",
      "Epoch 227/1000  Train Loss: 12758.4893  Val Loss: 12477.6797  Val MSE: 12477.6797  Val R2: -1.1700\n",
      "Epoch 228/1000  Train Loss: 12748.2646  Val Loss: 12467.4424  Val MSE: 12467.4434  Val R2: -1.1682\n",
      "Epoch 229/1000  Train Loss: 12738.0498  Val Loss: 12457.2148  Val MSE: 12457.2148  Val R2: -1.1664\n",
      "Epoch 230/1000  Train Loss: 12727.8477  Val Loss: 12446.9990  Val MSE: 12446.9971  Val R2: -1.1646\n",
      "Epoch 231/1000  Train Loss: 12717.6553  Val Loss: 12436.7920  Val MSE: 12436.7930  Val R2: -1.1629\n",
      "Epoch 232/1000  Train Loss: 12707.4697  Val Loss: 12426.5938  Val MSE: 12426.5938  Val R2: -1.1611\n",
      "Epoch 233/1000  Train Loss: 12697.2969  Val Loss: 12416.4072  Val MSE: 12416.4062  Val R2: -1.1593\n",
      "Epoch 234/1000  Train Loss: 12687.1309  Val Loss: 12406.2285  Val MSE: 12406.2285  Val R2: -1.1575\n",
      "Epoch 235/1000  Train Loss: 12676.9785  Val Loss: 12396.0615  Val MSE: 12396.0615  Val R2: -1.1558\n",
      "Epoch 236/1000  Train Loss: 12666.8350  Val Loss: 12385.9033  Val MSE: 12385.9043  Val R2: -1.1540\n",
      "Epoch 237/1000  Train Loss: 12656.6992  Val Loss: 12375.7559  Val MSE: 12375.7559  Val R2: -1.1522\n",
      "Epoch 238/1000  Train Loss: 12646.5771  Val Loss: 12365.6182  Val MSE: 12365.6182  Val R2: -1.1505\n",
      "Epoch 239/1000  Train Loss: 12636.4609  Val Loss: 12355.4912  Val MSE: 12355.4902  Val R2: -1.1487\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 240/1000  Train Loss: 12626.3564  Val Loss: 12345.3721  Val MSE: 12345.3721  Val R2: -1.1470\n",
      "Epoch 241/1000  Train Loss: 12616.2607  Val Loss: 12335.2637  Val MSE: 12335.2637  Val R2: -1.1452\n",
      "Epoch 242/1000  Train Loss: 12606.1748  Val Loss: 12325.1641  Val MSE: 12325.1641  Val R2: -1.1434\n",
      "Epoch 243/1000  Train Loss: 12596.0986  Val Loss: 12315.0742  Val MSE: 12315.0752  Val R2: -1.1417\n",
      "Epoch 244/1000  Train Loss: 12586.0332  Val Loss: 12304.9941  Val MSE: 12304.9951  Val R2: -1.1399\n",
      "Epoch 245/1000  Train Loss: 12575.9775  Val Loss: 12294.9258  Val MSE: 12294.9258  Val R2: -1.1382\n",
      "Epoch 246/1000  Train Loss: 12565.9316  Val Loss: 12284.8652  Val MSE: 12284.8652  Val R2: -1.1364\n",
      "Epoch 247/1000  Train Loss: 12555.8945  Val Loss: 12274.8145  Val MSE: 12274.8145  Val R2: -1.1347\n",
      "Epoch 248/1000  Train Loss: 12545.8662  Val Loss: 12264.7734  Val MSE: 12264.7744  Val R2: -1.1329\n",
      "Epoch 249/1000  Train Loss: 12535.8496  Val Loss: 12254.7412  Val MSE: 12254.7422  Val R2: -1.1312\n",
      "Epoch 250/1000  Train Loss: 12525.8398  Val Loss: 12244.7217  Val MSE: 12244.7207  Val R2: -1.1295\n",
      "Epoch 251/1000  Train Loss: 12515.8418  Val Loss: 12234.7080  Val MSE: 12234.7090  Val R2: -1.1277\n",
      "Epoch 252/1000  Train Loss: 12505.8525  Val Loss: 12224.7051  Val MSE: 12224.7061  Val R2: -1.1260\n",
      "Epoch 253/1000  Train Loss: 12495.8730  Val Loss: 12214.7139  Val MSE: 12214.7129  Val R2: -1.1242\n",
      "Epoch 254/1000  Train Loss: 12485.9043  Val Loss: 12204.7295  Val MSE: 12204.7295  Val R2: -1.1225\n",
      "Epoch 255/1000  Train Loss: 12475.9443  Val Loss: 12194.7549  Val MSE: 12194.7549  Val R2: -1.1208\n",
      "Epoch 256/1000  Train Loss: 12465.9922  Val Loss: 12184.7891  Val MSE: 12184.7910  Val R2: -1.1190\n",
      "Epoch 257/1000  Train Loss: 12456.0508  Val Loss: 12174.8350  Val MSE: 12174.8350  Val R2: -1.1173\n",
      "Epoch 258/1000  Train Loss: 12446.1191  Val Loss: 12164.8906  Val MSE: 12164.8896  Val R2: -1.1156\n",
      "Epoch 259/1000  Train Loss: 12436.1973  Val Loss: 12154.9531  Val MSE: 12154.9521  Val R2: -1.1138\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 260/1000  Train Loss: 12426.2832  Val Loss: 12145.0273  Val MSE: 12145.0264  Val R2: -1.1121\n",
      "Epoch 261/1000  Train Loss: 12416.3799  Val Loss: 12135.1074  Val MSE: 12135.1084  Val R2: -1.1104\n",
      "Epoch 262/1000  Train Loss: 12406.4844  Val Loss: 12125.2012  Val MSE: 12125.2012  Val R2: -1.1087\n",
      "Epoch 263/1000  Train Loss: 12396.5977  Val Loss: 12115.3027  Val MSE: 12115.3008  Val R2: -1.1070\n",
      "Epoch 264/1000  Train Loss: 12386.7236  Val Loss: 12105.4111  Val MSE: 12105.4121  Val R2: -1.1052\n",
      "Epoch 265/1000  Train Loss: 12376.8555  Val Loss: 12095.5322  Val MSE: 12095.5312  Val R2: -1.1035\n",
      "Epoch 266/1000  Train Loss: 12366.9990  Val Loss: 12085.6602  Val MSE: 12085.6592  Val R2: -1.1018\n",
      "Epoch 267/1000  Train Loss: 12357.1494  Val Loss: 12075.7998  Val MSE: 12075.7988  Val R2: -1.1001\n",
      "Epoch 268/1000  Train Loss: 12347.3135  Val Loss: 12065.9463  Val MSE: 12065.9473  Val R2: -1.0984\n",
      "Epoch 269/1000  Train Loss: 12337.4834  Val Loss: 12056.1035  Val MSE: 12056.1045  Val R2: -1.0967\n",
      "Epoch 270/1000  Train Loss: 12327.6631  Val Loss: 12046.2695  Val MSE: 12046.2695  Val R2: -1.0949\n",
      "Epoch 271/1000  Train Loss: 12317.8516  Val Loss: 12036.4443  Val MSE: 12036.4443  Val R2: -1.0932\n",
      "Epoch 272/1000  Train Loss: 12308.0508  Val Loss: 12026.6289  Val MSE: 12026.6299  Val R2: -1.0915\n",
      "Epoch 273/1000  Train Loss: 12298.2578  Val Loss: 12016.8232  Val MSE: 12016.8223  Val R2: -1.0898\n",
      "Epoch 274/1000  Train Loss: 12288.4746  Val Loss: 12007.0254  Val MSE: 12007.0254  Val R2: -1.0881\n",
      "Epoch 275/1000  Train Loss: 12278.6992  Val Loss: 11997.2373  Val MSE: 11997.2373  Val R2: -1.0864\n",
      "Epoch 276/1000  Train Loss: 12268.9346  Val Loss: 11987.4590  Val MSE: 11987.4590  Val R2: -1.0847\n",
      "Epoch 277/1000  Train Loss: 12259.1787  Val Loss: 11977.6895  Val MSE: 11977.6885  Val R2: -1.0830\n",
      "Epoch 278/1000  Train Loss: 12249.4316  Val Loss: 11967.9277  Val MSE: 11967.9277  Val R2: -1.0813\n",
      "Epoch 279/1000  Train Loss: 12239.6934  Val Loss: 11958.1768  Val MSE: 11958.1758  Val R2: -1.0796\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 280/1000  Train Loss: 12229.9639  Val Loss: 11948.4336  Val MSE: 11948.4336  Val R2: -1.0779\n",
      "Epoch 281/1000  Train Loss: 12220.2451  Val Loss: 11938.7002  Val MSE: 11938.6992  Val R2: -1.0762\n",
      "Epoch 282/1000  Train Loss: 12210.5352  Val Loss: 11928.9746  Val MSE: 11928.9756  Val R2: -1.0745\n",
      "Epoch 283/1000  Train Loss: 12200.8330  Val Loss: 11919.2598  Val MSE: 11919.2598  Val R2: -1.0729\n",
      "Epoch 284/1000  Train Loss: 12191.1396  Val Loss: 11909.5527  Val MSE: 11909.5527  Val R2: -1.0712\n",
      "Epoch 285/1000  Train Loss: 12181.4570  Val Loss: 11899.8545  Val MSE: 11899.8555  Val R2: -1.0695\n",
      "Epoch 286/1000  Train Loss: 12171.7822  Val Loss: 11890.1670  Val MSE: 11890.1670  Val R2: -1.0678\n",
      "Epoch 287/1000  Train Loss: 12162.1162  Val Loss: 11880.4873  Val MSE: 11880.4873  Val R2: -1.0661\n",
      "Epoch 288/1000  Train Loss: 12152.4600  Val Loss: 11870.8154  Val MSE: 11870.8164  Val R2: -1.0644\n",
      "Epoch 289/1000  Train Loss: 12142.8115  Val Loss: 11861.1553  Val MSE: 11861.1553  Val R2: -1.0628\n",
      "Epoch 290/1000  Train Loss: 12133.1729  Val Loss: 11851.5029  Val MSE: 11851.5020  Val R2: -1.0611\n",
      "Epoch 291/1000  Train Loss: 12123.5410  Val Loss: 11841.8584  Val MSE: 11841.8574  Val R2: -1.0594\n",
      "Epoch 292/1000  Train Loss: 12113.9199  Val Loss: 11832.2227  Val MSE: 11832.2236  Val R2: -1.0577\n",
      "Epoch 293/1000  Train Loss: 12104.3076  Val Loss: 11822.5977  Val MSE: 11822.5977  Val R2: -1.0560\n",
      "Epoch 294/1000  Train Loss: 12094.7051  Val Loss: 11812.9795  Val MSE: 11812.9795  Val R2: -1.0544\n",
      "Epoch 295/1000  Train Loss: 12085.1104  Val Loss: 11803.3711  Val MSE: 11803.3701  Val R2: -1.0527\n",
      "Epoch 296/1000  Train Loss: 12075.5254  Val Loss: 11793.7715  Val MSE: 11793.7715  Val R2: -1.0510\n",
      "Epoch 297/1000  Train Loss: 12065.9473  Val Loss: 11784.1807  Val MSE: 11784.1807  Val R2: -1.0494\n",
      "Epoch 298/1000  Train Loss: 12056.3799  Val Loss: 11774.5977  Val MSE: 11774.5986  Val R2: -1.0477\n",
      "Epoch 299/1000  Train Loss: 12046.8203  Val Loss: 11765.0254  Val MSE: 11765.0254  Val R2: -1.0460\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 300/1000  Train Loss: 12037.2705  Val Loss: 11755.4600  Val MSE: 11755.4609  Val R2: -1.0444\n",
      "Epoch 301/1000  Train Loss: 12027.7275  Val Loss: 11745.9043  Val MSE: 11745.9053  Val R2: -1.0427\n",
      "Epoch 302/1000  Train Loss: 12018.1953  Val Loss: 11736.3574  Val MSE: 11736.3574  Val R2: -1.0410\n",
      "Epoch 303/1000  Train Loss: 12008.6719  Val Loss: 11726.8184  Val MSE: 11726.8193  Val R2: -1.0394\n",
      "Epoch 304/1000  Train Loss: 11999.1543  Val Loss: 11717.2900  Val MSE: 11717.2891  Val R2: -1.0377\n",
      "Epoch 305/1000  Train Loss: 11989.6484  Val Loss: 11707.7686  Val MSE: 11707.7686  Val R2: -1.0361\n",
      "Epoch 306/1000  Train Loss: 11980.1504  Val Loss: 11698.2568  Val MSE: 11698.2568  Val R2: -1.0344\n",
      "Epoch 307/1000  Train Loss: 11970.6602  Val Loss: 11688.7529  Val MSE: 11688.7529  Val R2: -1.0328\n",
      "Epoch 308/1000  Train Loss: 11961.1787  Val Loss: 11679.2588  Val MSE: 11679.2578  Val R2: -1.0311\n",
      "Epoch 309/1000  Train Loss: 11951.7070  Val Loss: 11669.7715  Val MSE: 11669.7725  Val R2: -1.0295\n",
      "Epoch 310/1000  Train Loss: 11942.2432  Val Loss: 11660.2949  Val MSE: 11660.2939  Val R2: -1.0278\n",
      "Epoch 311/1000  Train Loss: 11932.7881  Val Loss: 11650.8252  Val MSE: 11650.8262  Val R2: -1.0262\n",
      "Epoch 312/1000  Train Loss: 11923.3418  Val Loss: 11641.3643  Val MSE: 11641.3652  Val R2: -1.0245\n",
      "Epoch 313/1000  Train Loss: 11913.9062  Val Loss: 11631.9121  Val MSE: 11631.9121  Val R2: -1.0229\n",
      "Epoch 314/1000  Train Loss: 11904.4746  Val Loss: 11622.4707  Val MSE: 11622.4697  Val R2: -1.0212\n",
      "Epoch 315/1000  Train Loss: 11895.0537  Val Loss: 11613.0352  Val MSE: 11613.0352  Val R2: -1.0196\n",
      "Epoch 316/1000  Train Loss: 11885.6426  Val Loss: 11603.6094  Val MSE: 11603.6094  Val R2: -1.0180\n",
      "Epoch 317/1000  Train Loss: 11876.2393  Val Loss: 11594.1914  Val MSE: 11594.1914  Val R2: -1.0163\n",
      "Epoch 318/1000  Train Loss: 11866.8447  Val Loss: 11584.7822  Val MSE: 11584.7832  Val R2: -1.0147\n",
      "Epoch 319/1000  Train Loss: 11857.4580  Val Loss: 11575.3828  Val MSE: 11575.3828  Val R2: -1.0131\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 320/1000  Train Loss: 11848.0801  Val Loss: 11565.9902  Val MSE: 11565.9902  Val R2: -1.0114\n",
      "Epoch 321/1000  Train Loss: 11838.7109  Val Loss: 11556.6064  Val MSE: 11556.6064  Val R2: -1.0098\n",
      "Epoch 322/1000  Train Loss: 11829.3496  Val Loss: 11547.2314  Val MSE: 11547.2314  Val R2: -1.0082\n",
      "Epoch 323/1000  Train Loss: 11819.9980  Val Loss: 11537.8643  Val MSE: 11537.8652  Val R2: -1.0065\n",
      "Epoch 324/1000  Train Loss: 11810.6533  Val Loss: 11528.5068  Val MSE: 11528.5068  Val R2: -1.0049\n",
      "Epoch 325/1000  Train Loss: 11801.3164  Val Loss: 11519.1572  Val MSE: 11519.1572  Val R2: -1.0033\n",
      "Epoch 326/1000  Train Loss: 11791.9902  Val Loss: 11509.8154  Val MSE: 11509.8154  Val R2: -1.0017\n",
      "Epoch 327/1000  Train Loss: 11782.6719  Val Loss: 11500.4834  Val MSE: 11500.4834  Val R2: -1.0000\n",
      "Epoch 328/1000  Train Loss: 11773.3613  Val Loss: 11491.1592  Val MSE: 11491.1592  Val R2: -0.9984\n",
      "Epoch 329/1000  Train Loss: 11764.0596  Val Loss: 11481.8428  Val MSE: 11481.8438  Val R2: -0.9968\n",
      "Epoch 330/1000  Train Loss: 11754.7666  Val Loss: 11472.5352  Val MSE: 11472.5361  Val R2: -0.9952\n",
      "Epoch 331/1000  Train Loss: 11745.4805  Val Loss: 11463.2363  Val MSE: 11463.2363  Val R2: -0.9936\n",
      "Epoch 332/1000  Train Loss: 11736.2051  Val Loss: 11453.9453  Val MSE: 11453.9453  Val R2: -0.9919\n",
      "Epoch 333/1000  Train Loss: 11726.9355  Val Loss: 11444.6631  Val MSE: 11444.6621  Val R2: -0.9903\n",
      "Epoch 334/1000  Train Loss: 11717.6768  Val Loss: 11435.3877  Val MSE: 11435.3877  Val R2: -0.9887\n",
      "Epoch 335/1000  Train Loss: 11708.4238  Val Loss: 11426.1230  Val MSE: 11426.1230  Val R2: -0.9871\n",
      "Epoch 336/1000  Train Loss: 11699.1826  Val Loss: 11416.8652  Val MSE: 11416.8652  Val R2: -0.9855\n",
      "Epoch 337/1000  Train Loss: 11689.9463  Val Loss: 11407.6162  Val MSE: 11407.6162  Val R2: -0.9839\n",
      "Epoch 338/1000  Train Loss: 11680.7178  Val Loss: 11398.3750  Val MSE: 11398.3740  Val R2: -0.9823\n",
      "Epoch 339/1000  Train Loss: 11671.5000  Val Loss: 11389.1426  Val MSE: 11389.1426  Val R2: -0.9807\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 340/1000  Train Loss: 11662.2900  Val Loss: 11379.9180  Val MSE: 11379.9180  Val R2: -0.9791\n",
      "Epoch 341/1000  Train Loss: 11653.0879  Val Loss: 11370.7012  Val MSE: 11370.7012  Val R2: -0.9775\n",
      "Epoch 342/1000  Train Loss: 11643.8936  Val Loss: 11361.4932  Val MSE: 11361.4941  Val R2: -0.9759\n",
      "Epoch 343/1000  Train Loss: 11634.7090  Val Loss: 11352.2930  Val MSE: 11352.2939  Val R2: -0.9743\n",
      "Epoch 344/1000  Train Loss: 11625.5303  Val Loss: 11343.1025  Val MSE: 11343.1025  Val R2: -0.9727\n",
      "Epoch 345/1000  Train Loss: 11616.3623  Val Loss: 11333.9189  Val MSE: 11333.9189  Val R2: -0.9711\n",
      "Epoch 346/1000  Train Loss: 11607.2021  Val Loss: 11324.7441  Val MSE: 11324.7441  Val R2: -0.9695\n",
      "Epoch 347/1000  Train Loss: 11598.0488  Val Loss: 11315.5781  Val MSE: 11315.5781  Val R2: -0.9679\n",
      "Epoch 348/1000  Train Loss: 11588.9043  Val Loss: 11306.4199  Val MSE: 11306.4189  Val R2: -0.9663\n",
      "Epoch 349/1000  Train Loss: 11579.7676  Val Loss: 11297.2676  Val MSE: 11297.2676  Val R2: -0.9647\n",
      "Epoch 350/1000  Train Loss: 11570.6396  Val Loss: 11288.1250  Val MSE: 11288.1270  Val R2: -0.9631\n",
      "Epoch 351/1000  Train Loss: 11561.5195  Val Loss: 11278.9912  Val MSE: 11278.9912  Val R2: -0.9615\n",
      "Epoch 352/1000  Train Loss: 11552.4072  Val Loss: 11269.8643  Val MSE: 11269.8662  Val R2: -0.9599\n",
      "Epoch 353/1000  Train Loss: 11543.3037  Val Loss: 11260.7471  Val MSE: 11260.7471  Val R2: -0.9583\n",
      "Epoch 354/1000  Train Loss: 11534.2070  Val Loss: 11251.6377  Val MSE: 11251.6377  Val R2: -0.9568\n",
      "Epoch 355/1000  Train Loss: 11525.1221  Val Loss: 11242.5371  Val MSE: 11242.5361  Val R2: -0.9552\n",
      "Epoch 356/1000  Train Loss: 11516.0420  Val Loss: 11233.4414  Val MSE: 11233.4414  Val R2: -0.9536\n",
      "Epoch 357/1000  Train Loss: 11506.9707  Val Loss: 11224.3584  Val MSE: 11224.3564  Val R2: -0.9520\n",
      "Epoch 358/1000  Train Loss: 11497.9072  Val Loss: 11215.2793  Val MSE: 11215.2793  Val R2: -0.9504\n",
      "Epoch 359/1000  Train Loss: 11488.8506  Val Loss: 11206.2100  Val MSE: 11206.2090  Val R2: -0.9489\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 360/1000  Train Loss: 11479.8057  Val Loss: 11197.1484  Val MSE: 11197.1475  Val R2: -0.9473\n",
      "Epoch 361/1000  Train Loss: 11470.7666  Val Loss: 11188.0947  Val MSE: 11188.0947  Val R2: -0.9457\n",
      "Epoch 362/1000  Train Loss: 11461.7354  Val Loss: 11179.0488  Val MSE: 11179.0488  Val R2: -0.9441\n",
      "Epoch 363/1000  Train Loss: 11452.7119  Val Loss: 11170.0117  Val MSE: 11170.0117  Val R2: -0.9426\n",
      "Epoch 364/1000  Train Loss: 11443.6963  Val Loss: 11160.9824  Val MSE: 11160.9824  Val R2: -0.9410\n",
      "Epoch 365/1000  Train Loss: 11434.6895  Val Loss: 11151.9619  Val MSE: 11151.9609  Val R2: -0.9394\n",
      "Epoch 366/1000  Train Loss: 11425.6914  Val Loss: 11142.9473  Val MSE: 11142.9473  Val R2: -0.9378\n",
      "Epoch 367/1000  Train Loss: 11416.6982  Val Loss: 11133.9434  Val MSE: 11133.9424  Val R2: -0.9363\n",
      "Epoch 368/1000  Train Loss: 11407.7158  Val Loss: 11124.9453  Val MSE: 11124.9453  Val R2: -0.9347\n",
      "Epoch 369/1000  Train Loss: 11398.7402  Val Loss: 11115.9551  Val MSE: 11115.9551  Val R2: -0.9332\n",
      "Epoch 370/1000  Train Loss: 11389.7744  Val Loss: 11106.9736  Val MSE: 11106.9727  Val R2: -0.9316\n",
      "Epoch 371/1000  Train Loss: 11380.8145  Val Loss: 11098.0010  Val MSE: 11098.0000  Val R2: -0.9300\n",
      "Epoch 372/1000  Train Loss: 11371.8623  Val Loss: 11089.0352  Val MSE: 11089.0342  Val R2: -0.9285\n",
      "Epoch 373/1000  Train Loss: 11362.9199  Val Loss: 11080.0762  Val MSE: 11080.0771  Val R2: -0.9269\n",
      "Epoch 374/1000  Train Loss: 11353.9854  Val Loss: 11071.1279  Val MSE: 11071.1279  Val R2: -0.9254\n",
      "Epoch 375/1000  Train Loss: 11345.0566  Val Loss: 11062.1846  Val MSE: 11062.1855  Val R2: -0.9238\n",
      "Epoch 376/1000  Train Loss: 11336.1377  Val Loss: 11053.2500  Val MSE: 11053.2510  Val R2: -0.9223\n",
      "Epoch 377/1000  Train Loss: 11327.2256  Val Loss: 11044.3242  Val MSE: 11044.3252  Val R2: -0.9207\n",
      "Epoch 378/1000  Train Loss: 11318.3223  Val Loss: 11035.4062  Val MSE: 11035.4062  Val R2: -0.9191\n",
      "Epoch 379/1000  Train Loss: 11309.4248  Val Loss: 11026.4961  Val MSE: 11026.4961  Val R2: -0.9176\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 380/1000  Train Loss: 11300.5381  Val Loss: 11017.5938  Val MSE: 11017.5947  Val R2: -0.9161\n",
      "Epoch 381/1000  Train Loss: 11291.6562  Val Loss: 11008.6992  Val MSE: 11008.6982  Val R2: -0.9145\n",
      "Epoch 382/1000  Train Loss: 11282.7832  Val Loss: 10999.8125  Val MSE: 10999.8125  Val R2: -0.9130\n",
      "Epoch 383/1000  Train Loss: 11273.9199  Val Loss: 10990.9316  Val MSE: 10990.9316  Val R2: -0.9114\n",
      "Epoch 384/1000  Train Loss: 11265.0625  Val Loss: 10982.0615  Val MSE: 10982.0615  Val R2: -0.9099\n",
      "Epoch 385/1000  Train Loss: 11256.2119  Val Loss: 10973.1982  Val MSE: 10973.1982  Val R2: -0.9083\n",
      "Epoch 386/1000  Train Loss: 11247.3721  Val Loss: 10964.3418  Val MSE: 10964.3418  Val R2: -0.9068\n",
      "Epoch 387/1000  Train Loss: 11238.5381  Val Loss: 10955.4941  Val MSE: 10955.4941  Val R2: -0.9053\n",
      "Epoch 388/1000  Train Loss: 11229.7129  Val Loss: 10946.6533  Val MSE: 10946.6533  Val R2: -0.9037\n",
      "Epoch 389/1000  Train Loss: 11220.8936  Val Loss: 10937.8213  Val MSE: 10937.8213  Val R2: -0.9022\n",
      "Epoch 390/1000  Train Loss: 11212.0830  Val Loss: 10928.9971  Val MSE: 10928.9971  Val R2: -0.9006\n",
      "Epoch 391/1000  Train Loss: 11203.2803  Val Loss: 10920.1797  Val MSE: 10920.1807  Val R2: -0.8991\n",
      "Epoch 392/1000  Train Loss: 11194.4854  Val Loss: 10911.3701  Val MSE: 10911.3711  Val R2: -0.8976\n",
      "Epoch 393/1000  Train Loss: 11185.6992  Val Loss: 10902.5693  Val MSE: 10902.5693  Val R2: -0.8960\n",
      "Epoch 394/1000  Train Loss: 11176.9199  Val Loss: 10893.7754  Val MSE: 10893.7744  Val R2: -0.8945\n",
      "Epoch 395/1000  Train Loss: 11168.1475  Val Loss: 10884.9902  Val MSE: 10884.9893  Val R2: -0.8930\n",
      "Epoch 396/1000  Train Loss: 11159.3838  Val Loss: 10876.2109  Val MSE: 10876.2109  Val R2: -0.8915\n",
      "Epoch 397/1000  Train Loss: 11150.6289  Val Loss: 10867.4404  Val MSE: 10867.4404  Val R2: -0.8899\n",
      "Epoch 398/1000  Train Loss: 11141.8779  Val Loss: 10858.6768  Val MSE: 10858.6768  Val R2: -0.8884\n",
      "Epoch 399/1000  Train Loss: 11133.1377  Val Loss: 10849.9219  Val MSE: 10849.9219  Val R2: -0.8869\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 400/1000  Train Loss: 11124.4053  Val Loss: 10841.1729  Val MSE: 10841.1738  Val R2: -0.8854\n",
      "Epoch 401/1000  Train Loss: 11115.6797  Val Loss: 10832.4336  Val MSE: 10832.4336  Val R2: -0.8838\n",
      "Epoch 402/1000  Train Loss: 11106.9619  Val Loss: 10823.7012  Val MSE: 10823.7021  Val R2: -0.8823\n",
      "Epoch 403/1000  Train Loss: 11098.2510  Val Loss: 10814.9766  Val MSE: 10814.9766  Val R2: -0.8808\n",
      "Epoch 404/1000  Train Loss: 11089.5498  Val Loss: 10806.2588  Val MSE: 10806.2598  Val R2: -0.8793\n",
      "Epoch 405/1000  Train Loss: 11080.8525  Val Loss: 10797.5498  Val MSE: 10797.5498  Val R2: -0.8778\n",
      "Epoch 406/1000  Train Loss: 11072.1660  Val Loss: 10788.8477  Val MSE: 10788.8486  Val R2: -0.8763\n",
      "Epoch 407/1000  Train Loss: 11063.4844  Val Loss: 10780.1543  Val MSE: 10780.1533  Val R2: -0.8748\n",
      "Epoch 408/1000  Train Loss: 11054.8135  Val Loss: 10771.4678  Val MSE: 10771.4658  Val R2: -0.8732\n",
      "Epoch 409/1000  Train Loss: 11046.1484  Val Loss: 10762.7871  Val MSE: 10762.7871  Val R2: -0.8717\n",
      "Epoch 410/1000  Train Loss: 11037.4922  Val Loss: 10754.1162  Val MSE: 10754.1152  Val R2: -0.8702\n",
      "Epoch 411/1000  Train Loss: 11028.8408  Val Loss: 10745.4521  Val MSE: 10745.4521  Val R2: -0.8687\n",
      "Epoch 412/1000  Train Loss: 11020.1992  Val Loss: 10736.7939  Val MSE: 10736.7939  Val R2: -0.8672\n",
      "Epoch 413/1000  Train Loss: 11011.5645  Val Loss: 10728.1455  Val MSE: 10728.1465  Val R2: -0.8657\n",
      "Epoch 414/1000  Train Loss: 11002.9375  Val Loss: 10719.5049  Val MSE: 10719.5039  Val R2: -0.8642\n",
      "Epoch 415/1000  Train Loss: 10994.3184  Val Loss: 10710.8721  Val MSE: 10710.8711  Val R2: -0.8627\n",
      "Epoch 416/1000  Train Loss: 10985.7070  Val Loss: 10702.2441  Val MSE: 10702.2441  Val R2: -0.8612\n",
      "Epoch 417/1000  Train Loss: 10977.1035  Val Loss: 10693.6250  Val MSE: 10693.6240  Val R2: -0.8597\n",
      "Epoch 418/1000  Train Loss: 10968.5049  Val Loss: 10685.0137  Val MSE: 10685.0137  Val R2: -0.8582\n",
      "Epoch 419/1000  Train Loss: 10959.9160  Val Loss: 10676.4102  Val MSE: 10676.4092  Val R2: -0.8567\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 420/1000  Train Loss: 10951.3340  Val Loss: 10667.8135  Val MSE: 10667.8135  Val R2: -0.8552\n",
      "Epoch 421/1000  Train Loss: 10942.7588  Val Loss: 10659.2246  Val MSE: 10659.2246  Val R2: -0.8537\n",
      "Epoch 422/1000  Train Loss: 10934.1934  Val Loss: 10650.6426  Val MSE: 10650.6426  Val R2: -0.8522\n",
      "Epoch 423/1000  Train Loss: 10925.6348  Val Loss: 10642.0684  Val MSE: 10642.0684  Val R2: -0.8507\n",
      "Epoch 424/1000  Train Loss: 10917.0811  Val Loss: 10633.5010  Val MSE: 10633.5010  Val R2: -0.8493\n",
      "Epoch 425/1000  Train Loss: 10908.5361  Val Loss: 10624.9434  Val MSE: 10624.9434  Val R2: -0.8478\n",
      "Epoch 426/1000  Train Loss: 10899.9990  Val Loss: 10616.3906  Val MSE: 10616.3906  Val R2: -0.8463\n",
      "Epoch 427/1000  Train Loss: 10891.4697  Val Loss: 10607.8467  Val MSE: 10607.8477  Val R2: -0.8448\n",
      "Epoch 428/1000  Train Loss: 10882.9473  Val Loss: 10599.3096  Val MSE: 10599.3096  Val R2: -0.8433\n",
      "Epoch 429/1000  Train Loss: 10874.4316  Val Loss: 10590.7803  Val MSE: 10590.7793  Val R2: -0.8418\n",
      "Epoch 430/1000  Train Loss: 10865.9248  Val Loss: 10582.2578  Val MSE: 10582.2588  Val R2: -0.8403\n",
      "Epoch 431/1000  Train Loss: 10857.4238  Val Loss: 10573.7422  Val MSE: 10573.7432  Val R2: -0.8389\n",
      "Epoch 432/1000  Train Loss: 10848.9307  Val Loss: 10565.2363  Val MSE: 10565.2354  Val R2: -0.8374\n",
      "Epoch 433/1000  Train Loss: 10840.4453  Val Loss: 10556.7354  Val MSE: 10556.7354  Val R2: -0.8359\n",
      "Epoch 434/1000  Train Loss: 10831.9668  Val Loss: 10548.2441  Val MSE: 10548.2441  Val R2: -0.8344\n",
      "Epoch 435/1000  Train Loss: 10823.4971  Val Loss: 10539.7568  Val MSE: 10539.7578  Val R2: -0.8330\n",
      "Epoch 436/1000  Train Loss: 10815.0332  Val Loss: 10531.2803  Val MSE: 10531.2803  Val R2: -0.8315\n",
      "Epoch 437/1000  Train Loss: 10806.5781  Val Loss: 10522.8086  Val MSE: 10522.8096  Val R2: -0.8300\n",
      "Epoch 438/1000  Train Loss: 10798.1279  Val Loss: 10514.3447  Val MSE: 10514.3457  Val R2: -0.8285\n",
      "Epoch 439/1000  Train Loss: 10789.6875  Val Loss: 10505.8906  Val MSE: 10505.8906  Val R2: -0.8271\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 440/1000  Train Loss: 10781.2529  Val Loss: 10497.4414  Val MSE: 10497.4414  Val R2: -0.8256\n",
      "Epoch 441/1000  Train Loss: 10772.8262  Val Loss: 10489.0000  Val MSE: 10488.9990  Val R2: -0.8241\n",
      "Epoch 442/1000  Train Loss: 10764.4053  Val Loss: 10480.5664  Val MSE: 10480.5654  Val R2: -0.8227\n",
      "Epoch 443/1000  Train Loss: 10755.9941  Val Loss: 10472.1396  Val MSE: 10472.1396  Val R2: -0.8212\n",
      "Epoch 444/1000  Train Loss: 10747.5898  Val Loss: 10463.7188  Val MSE: 10463.7188  Val R2: -0.8197\n",
      "Epoch 445/1000  Train Loss: 10739.1924  Val Loss: 10455.3066  Val MSE: 10455.3066  Val R2: -0.8183\n",
      "Epoch 446/1000  Train Loss: 10730.8008  Val Loss: 10446.9023  Val MSE: 10446.9023  Val R2: -0.8168\n",
      "Epoch 447/1000  Train Loss: 10722.4189  Val Loss: 10438.5049  Val MSE: 10438.5039  Val R2: -0.8153\n",
      "Epoch 448/1000  Train Loss: 10714.0430  Val Loss: 10430.1133  Val MSE: 10430.1133  Val R2: -0.8139\n",
      "Epoch 449/1000  Train Loss: 10705.6748  Val Loss: 10421.7314  Val MSE: 10421.7305  Val R2: -0.8124\n",
      "Epoch 450/1000  Train Loss: 10697.3125  Val Loss: 10413.3555  Val MSE: 10413.3545  Val R2: -0.8110\n",
      "Epoch 451/1000  Train Loss: 10688.9580  Val Loss: 10404.9854  Val MSE: 10404.9863  Val R2: -0.8095\n",
      "Epoch 452/1000  Train Loss: 10680.6123  Val Loss: 10396.6250  Val MSE: 10396.6240  Val R2: -0.8081\n",
      "Epoch 453/1000  Train Loss: 10672.2715  Val Loss: 10388.2686  Val MSE: 10388.2695  Val R2: -0.8066\n",
      "Epoch 454/1000  Train Loss: 10663.9404  Val Loss: 10379.9229  Val MSE: 10379.9229  Val R2: -0.8052\n",
      "Epoch 455/1000  Train Loss: 10655.6143  Val Loss: 10371.5830  Val MSE: 10371.5830  Val R2: -0.8037\n",
      "Epoch 456/1000  Train Loss: 10647.2959  Val Loss: 10363.2500  Val MSE: 10363.2500  Val R2: -0.8023\n",
      "Epoch 457/1000  Train Loss: 10638.9844  Val Loss: 10354.9238  Val MSE: 10354.9248  Val R2: -0.8008\n",
      "Epoch 458/1000  Train Loss: 10630.6797  Val Loss: 10346.6064  Val MSE: 10346.6064  Val R2: -0.7994\n",
      "Epoch 459/1000  Train Loss: 10622.3838  Val Loss: 10338.2959  Val MSE: 10338.2949  Val R2: -0.7979\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 460/1000  Train Loss: 10614.0957  Val Loss: 10329.9902  Val MSE: 10329.9902  Val R2: -0.7965\n",
      "Epoch 461/1000  Train Loss: 10605.8135  Val Loss: 10321.6953  Val MSE: 10321.6953  Val R2: -0.7950\n",
      "Epoch 462/1000  Train Loss: 10597.5391  Val Loss: 10313.4033  Val MSE: 10313.4033  Val R2: -0.7936\n",
      "Epoch 463/1000  Train Loss: 10589.2686  Val Loss: 10305.1221  Val MSE: 10305.1221  Val R2: -0.7921\n",
      "Epoch 464/1000  Train Loss: 10581.0088  Val Loss: 10296.8457  Val MSE: 10296.8457  Val R2: -0.7907\n",
      "Epoch 465/1000  Train Loss: 10572.7549  Val Loss: 10288.5781  Val MSE: 10288.5771  Val R2: -0.7893\n",
      "Epoch 466/1000  Train Loss: 10564.5078  Val Loss: 10280.3154  Val MSE: 10280.3154  Val R2: -0.7878\n",
      "Epoch 467/1000  Train Loss: 10556.2676  Val Loss: 10272.0615  Val MSE: 10272.0615  Val R2: -0.7864\n",
      "Epoch 468/1000  Train Loss: 10548.0361  Val Loss: 10263.8145  Val MSE: 10263.8135  Val R2: -0.7850\n",
      "Epoch 469/1000  Train Loss: 10539.8105  Val Loss: 10255.5742  Val MSE: 10255.5742  Val R2: -0.7835\n",
      "Epoch 470/1000  Train Loss: 10531.5918  Val Loss: 10247.3418  Val MSE: 10247.3418  Val R2: -0.7821\n",
      "Epoch 471/1000  Train Loss: 10523.3809  Val Loss: 10239.1152  Val MSE: 10239.1152  Val R2: -0.7807\n",
      "Epoch 472/1000  Train Loss: 10515.1768  Val Loss: 10230.8955  Val MSE: 10230.8965  Val R2: -0.7792\n",
      "Epoch 473/1000  Train Loss: 10506.9795  Val Loss: 10222.6846  Val MSE: 10222.6846  Val R2: -0.7778\n",
      "Epoch 474/1000  Train Loss: 10498.7891  Val Loss: 10214.4805  Val MSE: 10214.4805  Val R2: -0.7764\n",
      "Epoch 475/1000  Train Loss: 10490.6064  Val Loss: 10206.2822  Val MSE: 10206.2822  Val R2: -0.7750\n",
      "Epoch 476/1000  Train Loss: 10482.4297  Val Loss: 10198.0898  Val MSE: 10198.0908  Val R2: -0.7735\n",
      "Epoch 477/1000  Train Loss: 10474.2607  Val Loss: 10189.9072  Val MSE: 10189.9072  Val R2: -0.7721\n",
      "Epoch 478/1000  Train Loss: 10466.0996  Val Loss: 10181.7305  Val MSE: 10181.7314  Val R2: -0.7707\n",
      "Epoch 479/1000  Train Loss: 10457.9453  Val Loss: 10173.5605  Val MSE: 10173.5605  Val R2: -0.7693\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 480/1000  Train Loss: 10449.7949  Val Loss: 10165.3994  Val MSE: 10165.3994  Val R2: -0.7678\n",
      "Epoch 481/1000  Train Loss: 10441.6553  Val Loss: 10157.2441  Val MSE: 10157.2432  Val R2: -0.7664\n",
      "Epoch 482/1000  Train Loss: 10433.5215  Val Loss: 10149.0938  Val MSE: 10149.0938  Val R2: -0.7650\n",
      "Epoch 483/1000  Train Loss: 10425.3945  Val Loss: 10140.9521  Val MSE: 10140.9521  Val R2: -0.7636\n",
      "Epoch 484/1000  Train Loss: 10417.2744  Val Loss: 10132.8174  Val MSE: 10132.8174  Val R2: -0.7622\n",
      "Epoch 485/1000  Train Loss: 10409.1611  Val Loss: 10124.6904  Val MSE: 10124.6904  Val R2: -0.7608\n",
      "Epoch 486/1000  Train Loss: 10401.0547  Val Loss: 10116.5693  Val MSE: 10116.5684  Val R2: -0.7594\n",
      "Epoch 487/1000  Train Loss: 10392.9541  Val Loss: 10108.4541  Val MSE: 10108.4551  Val R2: -0.7579\n",
      "Epoch 488/1000  Train Loss: 10384.8633  Val Loss: 10100.3486  Val MSE: 10100.3477  Val R2: -0.7565\n",
      "Epoch 489/1000  Train Loss: 10376.7783  Val Loss: 10092.2480  Val MSE: 10092.2480  Val R2: -0.7551\n",
      "Epoch 490/1000  Train Loss: 10368.7012  Val Loss: 10084.1543  Val MSE: 10084.1543  Val R2: -0.7537\n",
      "Epoch 491/1000  Train Loss: 10360.6279  Val Loss: 10076.0684  Val MSE: 10076.0684  Val R2: -0.7523\n",
      "Epoch 492/1000  Train Loss: 10352.5635  Val Loss: 10067.9902  Val MSE: 10067.9902  Val R2: -0.7509\n",
      "Epoch 493/1000  Train Loss: 10344.5059  Val Loss: 10059.9170  Val MSE: 10059.9170  Val R2: -0.7495\n",
      "Epoch 494/1000  Train Loss: 10336.4551  Val Loss: 10051.8525  Val MSE: 10051.8525  Val R2: -0.7481\n",
      "Epoch 495/1000  Train Loss: 10328.4121  Val Loss: 10043.7939  Val MSE: 10043.7939  Val R2: -0.7467\n",
      "Epoch 496/1000  Train Loss: 10320.3740  Val Loss: 10035.7412  Val MSE: 10035.7412  Val R2: -0.7453\n",
      "Epoch 497/1000  Train Loss: 10312.3438  Val Loss: 10027.6973  Val MSE: 10027.6963  Val R2: -0.7439\n",
      "Epoch 498/1000  Train Loss: 10304.3223  Val Loss: 10019.6592  Val MSE: 10019.6592  Val R2: -0.7425\n",
      "Epoch 499/1000  Train Loss: 10296.3047  Val Loss: 10011.6279  Val MSE: 10011.6279  Val R2: -0.7411\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 500/1000  Train Loss: 10288.2949  Val Loss: 10003.6035  Val MSE: 10003.6035  Val R2: -0.7397\n",
      "Epoch 501/1000  Train Loss: 10280.2920  Val Loss: 9995.5859  Val MSE: 9995.5859  Val R2: -0.7383\n",
      "Epoch 502/1000  Train Loss: 10272.2979  Val Loss: 9987.5762  Val MSE: 9987.5762  Val R2: -0.7369\n",
      "Epoch 503/1000  Train Loss: 10264.3076  Val Loss: 9979.5723  Val MSE: 9979.5723  Val R2: -0.7355\n",
      "Epoch 504/1000  Train Loss: 10256.3271  Val Loss: 9971.5752  Val MSE: 9971.5762  Val R2: -0.7341\n",
      "Epoch 505/1000  Train Loss: 10248.3516  Val Loss: 9963.5850  Val MSE: 9963.5850  Val R2: -0.7327\n",
      "Epoch 506/1000  Train Loss: 10240.3828  Val Loss: 9955.6016  Val MSE: 9955.6016  Val R2: -0.7314\n",
      "Epoch 507/1000  Train Loss: 10232.4219  Val Loss: 9947.6250  Val MSE: 9947.6260  Val R2: -0.7300\n",
      "Epoch 508/1000  Train Loss: 10224.4668  Val Loss: 9939.6562  Val MSE: 9939.6562  Val R2: -0.7286\n",
      "Epoch 509/1000  Train Loss: 10216.5195  Val Loss: 9931.6934  Val MSE: 9931.6934  Val R2: -0.7272\n",
      "Epoch 510/1000  Train Loss: 10208.5771  Val Loss: 9923.7373  Val MSE: 9923.7373  Val R2: -0.7258\n",
      "Epoch 511/1000  Train Loss: 10200.6416  Val Loss: 9915.7881  Val MSE: 9915.7881  Val R2: -0.7244\n",
      "Epoch 512/1000  Train Loss: 10192.7148  Val Loss: 9907.8457  Val MSE: 9907.8457  Val R2: -0.7231\n",
      "Epoch 513/1000  Train Loss: 10184.7939  Val Loss: 9899.9102  Val MSE: 9899.9092  Val R2: -0.7217\n",
      "Epoch 514/1000  Train Loss: 10176.8799  Val Loss: 9891.9814  Val MSE: 9891.9814  Val R2: -0.7203\n",
      "Epoch 515/1000  Train Loss: 10168.9727  Val Loss: 9884.0576  Val MSE: 9884.0586  Val R2: -0.7189\n",
      "Epoch 516/1000  Train Loss: 10161.0703  Val Loss: 9876.1436  Val MSE: 9876.1436  Val R2: -0.7175\n",
      "Epoch 517/1000  Train Loss: 10153.1777  Val Loss: 9868.2344  Val MSE: 9868.2334  Val R2: -0.7162\n",
      "Epoch 518/1000  Train Loss: 10145.2900  Val Loss: 9860.3320  Val MSE: 9860.3320  Val R2: -0.7148\n",
      "Epoch 519/1000  Train Loss: 10137.4092  Val Loss: 9852.4375  Val MSE: 9852.4375  Val R2: -0.7134\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 520/1000  Train Loss: 10129.5371  Val Loss: 9844.5488  Val MSE: 9844.5488  Val R2: -0.7120\n",
      "Epoch 521/1000  Train Loss: 10121.6689  Val Loss: 9836.6670  Val MSE: 9836.6670  Val R2: -0.7107\n",
      "Epoch 522/1000  Train Loss: 10113.8086  Val Loss: 9828.7910  Val MSE: 9828.7910  Val R2: -0.7093\n",
      "Epoch 523/1000  Train Loss: 10105.9551  Val Loss: 9820.9229  Val MSE: 9820.9229  Val R2: -0.7079\n",
      "Epoch 524/1000  Train Loss: 10098.1084  Val Loss: 9813.0615  Val MSE: 9813.0615  Val R2: -0.7066\n",
      "Epoch 525/1000  Train Loss: 10090.2676  Val Loss: 9805.2061  Val MSE: 9805.2061  Val R2: -0.7052\n",
      "Epoch 526/1000  Train Loss: 10082.4346  Val Loss: 9797.3584  Val MSE: 9797.3574  Val R2: -0.7038\n",
      "Epoch 527/1000  Train Loss: 10074.6064  Val Loss: 9789.5166  Val MSE: 9789.5166  Val R2: -0.7025\n",
      "Epoch 528/1000  Train Loss: 10066.7871  Val Loss: 9781.6807  Val MSE: 9781.6816  Val R2: -0.7011\n",
      "Epoch 529/1000  Train Loss: 10058.9736  Val Loss: 9773.8525  Val MSE: 9773.8525  Val R2: -0.6998\n",
      "Epoch 530/1000  Train Loss: 10051.1670  Val Loss: 9766.0303  Val MSE: 9766.0312  Val R2: -0.6984\n",
      "Epoch 531/1000  Train Loss: 10043.3662  Val Loss: 9758.2158  Val MSE: 9758.2158  Val R2: -0.6970\n",
      "Epoch 532/1000  Train Loss: 10035.5732  Val Loss: 9750.4072  Val MSE: 9750.4072  Val R2: -0.6957\n",
      "Epoch 533/1000  Train Loss: 10027.7861  Val Loss: 9742.6055  Val MSE: 9742.6055  Val R2: -0.6943\n",
      "Epoch 534/1000  Train Loss: 10020.0059  Val Loss: 9734.8105  Val MSE: 9734.8105  Val R2: -0.6930\n",
      "Epoch 535/1000  Train Loss: 10012.2314  Val Loss: 9727.0225  Val MSE: 9727.0215  Val R2: -0.6916\n",
      "Epoch 536/1000  Train Loss: 10004.4648  Val Loss: 9719.2402  Val MSE: 9719.2402  Val R2: -0.6903\n",
      "Epoch 537/1000  Train Loss: 9996.7041  Val Loss: 9711.4639  Val MSE: 9711.4639  Val R2: -0.6889\n",
      "Epoch 538/1000  Train Loss: 9988.9502  Val Loss: 9703.6963  Val MSE: 9703.6953  Val R2: -0.6876\n",
      "Epoch 539/1000  Train Loss: 9981.2031  Val Loss: 9695.9336  Val MSE: 9695.9326  Val R2: -0.6862\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 540/1000  Train Loss: 9973.4609  Val Loss: 9688.1768  Val MSE: 9688.1777  Val R2: -0.6849\n",
      "Epoch 541/1000  Train Loss: 9965.7285  Val Loss: 9680.4287  Val MSE: 9680.4287  Val R2: -0.6835\n",
      "Epoch 542/1000  Train Loss: 9958.0000  Val Loss: 9672.6855  Val MSE: 9672.6865  Val R2: -0.6822\n",
      "Epoch 543/1000  Train Loss: 9950.2793  Val Loss: 9664.9502  Val MSE: 9664.9512  Val R2: -0.6808\n",
      "Epoch 544/1000  Train Loss: 9942.5635  Val Loss: 9657.2207  Val MSE: 9657.2207  Val R2: -0.6795\n",
      "Epoch 545/1000  Train Loss: 9934.8574  Val Loss: 9649.4990  Val MSE: 9649.4980  Val R2: -0.6781\n",
      "Epoch 546/1000  Train Loss: 9927.1553  Val Loss: 9641.7822  Val MSE: 9641.7822  Val R2: -0.6768\n",
      "Epoch 547/1000  Train Loss: 9919.4609  Val Loss: 9634.0723  Val MSE: 9634.0723  Val R2: -0.6754\n",
      "Epoch 548/1000  Train Loss: 9911.7725  Val Loss: 9626.3682  Val MSE: 9626.3682  Val R2: -0.6741\n",
      "Epoch 549/1000  Train Loss: 9904.0889  Val Loss: 9618.6719  Val MSE: 9618.6719  Val R2: -0.6728\n",
      "Epoch 550/1000  Train Loss: 9896.4150  Val Loss: 9610.9824  Val MSE: 9610.9824  Val R2: -0.6714\n",
      "Epoch 551/1000  Train Loss: 9888.7471  Val Loss: 9603.2988  Val MSE: 9603.2988  Val R2: -0.6701\n",
      "Epoch 552/1000  Train Loss: 9881.0830  Val Loss: 9595.6221  Val MSE: 9595.6221  Val R2: -0.6688\n",
      "Epoch 553/1000  Train Loss: 9873.4287  Val Loss: 9587.9512  Val MSE: 9587.9512  Val R2: -0.6674\n",
      "Epoch 554/1000  Train Loss: 9865.7793  Val Loss: 9580.2861  Val MSE: 9580.2861  Val R2: -0.6661\n",
      "Epoch 555/1000  Train Loss: 9858.1357  Val Loss: 9572.6289  Val MSE: 9572.6289  Val R2: -0.6648\n",
      "Epoch 556/1000  Train Loss: 9850.5000  Val Loss: 9564.9766  Val MSE: 9564.9766  Val R2: -0.6634\n",
      "Epoch 557/1000  Train Loss: 9842.8711  Val Loss: 9557.3320  Val MSE: 9557.3320  Val R2: -0.6621\n",
      "Epoch 558/1000  Train Loss: 9835.2461  Val Loss: 9549.6953  Val MSE: 9549.6953  Val R2: -0.6608\n",
      "Epoch 559/1000  Train Loss: 9827.6299  Val Loss: 9542.0635  Val MSE: 9542.0635  Val R2: -0.6594\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 560/1000  Train Loss: 9820.0205  Val Loss: 9534.4385  Val MSE: 9534.4375  Val R2: -0.6581\n",
      "Epoch 561/1000  Train Loss: 9812.4160  Val Loss: 9526.8184  Val MSE: 9526.8193  Val R2: -0.6568\n",
      "Epoch 562/1000  Train Loss: 9804.8174  Val Loss: 9519.2061  Val MSE: 9519.2061  Val R2: -0.6555\n",
      "Epoch 563/1000  Train Loss: 9797.2266  Val Loss: 9511.5996  Val MSE: 9511.6006  Val R2: -0.6541\n",
      "Epoch 564/1000  Train Loss: 9789.6416  Val Loss: 9504.0000  Val MSE: 9504.0010  Val R2: -0.6528\n",
      "Epoch 565/1000  Train Loss: 9782.0645  Val Loss: 9496.4082  Val MSE: 9496.4072  Val R2: -0.6515\n",
      "Epoch 566/1000  Train Loss: 9774.4922  Val Loss: 9488.8203  Val MSE: 9488.8203  Val R2: -0.6502\n",
      "Epoch 567/1000  Train Loss: 9766.9268  Val Loss: 9481.2402  Val MSE: 9481.2412  Val R2: -0.6489\n",
      "Epoch 568/1000  Train Loss: 9759.3672  Val Loss: 9473.6670  Val MSE: 9473.6670  Val R2: -0.6475\n",
      "Epoch 569/1000  Train Loss: 9751.8154  Val Loss: 9466.0996  Val MSE: 9466.0996  Val R2: -0.6462\n",
      "Epoch 570/1000  Train Loss: 9744.2686  Val Loss: 9458.5381  Val MSE: 9458.5381  Val R2: -0.6449\n",
      "Epoch 571/1000  Train Loss: 9736.7295  Val Loss: 9450.9834  Val MSE: 9450.9844  Val R2: -0.6436\n",
      "Epoch 572/1000  Train Loss: 9729.1953  Val Loss: 9443.4355  Val MSE: 9443.4346  Val R2: -0.6423\n",
      "Epoch 573/1000  Train Loss: 9721.6699  Val Loss: 9435.8926  Val MSE: 9435.8926  Val R2: -0.6410\n",
      "Epoch 574/1000  Train Loss: 9714.1475  Val Loss: 9428.3574  Val MSE: 9428.3574  Val R2: -0.6397\n",
      "Epoch 575/1000  Train Loss: 9706.6338  Val Loss: 9420.8281  Val MSE: 9420.8281  Val R2: -0.6384\n",
      "Epoch 576/1000  Train Loss: 9699.1260  Val Loss: 9413.3037  Val MSE: 9413.3037  Val R2: -0.6371\n",
      "Epoch 577/1000  Train Loss: 9691.6240  Val Loss: 9405.7881  Val MSE: 9405.7891  Val R2: -0.6357\n",
      "Epoch 578/1000  Train Loss: 9684.1279  Val Loss: 9398.2783  Val MSE: 9398.2783  Val R2: -0.6344\n",
      "Epoch 579/1000  Train Loss: 9676.6387  Val Loss: 9390.7744  Val MSE: 9390.7744  Val R2: -0.6331\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 580/1000  Train Loss: 9669.1572  Val Loss: 9383.2773  Val MSE: 9383.2764  Val R2: -0.6318\n",
      "Epoch 581/1000  Train Loss: 9661.6807  Val Loss: 9375.7861  Val MSE: 9375.7861  Val R2: -0.6305\n",
      "Epoch 582/1000  Train Loss: 9654.2109  Val Loss: 9368.3008  Val MSE: 9368.3008  Val R2: -0.6292\n",
      "Epoch 583/1000  Train Loss: 9646.7480  Val Loss: 9360.8223  Val MSE: 9360.8223  Val R2: -0.6279\n",
      "Epoch 584/1000  Train Loss: 9639.2900  Val Loss: 9353.3486  Val MSE: 9353.3496  Val R2: -0.6266\n",
      "Epoch 585/1000  Train Loss: 9631.8389  Val Loss: 9345.8838  Val MSE: 9345.8848  Val R2: -0.6253\n",
      "Epoch 586/1000  Train Loss: 9624.3936  Val Loss: 9338.4238  Val MSE: 9338.4238  Val R2: -0.6240\n",
      "Epoch 587/1000  Train Loss: 9616.9551  Val Loss: 9330.9707  Val MSE: 9330.9707  Val R2: -0.6227\n",
      "Epoch 588/1000  Train Loss: 9609.5234  Val Loss: 9323.5225  Val MSE: 9323.5234  Val R2: -0.6214\n",
      "Epoch 589/1000  Train Loss: 9602.0977  Val Loss: 9316.0840  Val MSE: 9316.0840  Val R2: -0.6201\n",
      "Epoch 590/1000  Train Loss: 9594.6787  Val Loss: 9308.6484  Val MSE: 9308.6484  Val R2: -0.6189\n",
      "Epoch 591/1000  Train Loss: 9587.2646  Val Loss: 9301.2207  Val MSE: 9301.2197  Val R2: -0.6176\n",
      "Epoch 592/1000  Train Loss: 9579.8564  Val Loss: 9293.7969  Val MSE: 9293.7969  Val R2: -0.6163\n",
      "Epoch 593/1000  Train Loss: 9572.4561  Val Loss: 9286.3818  Val MSE: 9286.3828  Val R2: -0.6150\n",
      "Epoch 594/1000  Train Loss: 9565.0615  Val Loss: 9278.9727  Val MSE: 9278.9727  Val R2: -0.6137\n",
      "Epoch 595/1000  Train Loss: 9557.6738  Val Loss: 9271.5693  Val MSE: 9271.5684  Val R2: -0.6124\n",
      "Epoch 596/1000  Train Loss: 9550.2910  Val Loss: 9264.1729  Val MSE: 9264.1719  Val R2: -0.6111\n",
      "Epoch 597/1000  Train Loss: 9542.9150  Val Loss: 9256.7812  Val MSE: 9256.7812  Val R2: -0.6098\n",
      "Epoch 598/1000  Train Loss: 9535.5459  Val Loss: 9249.3965  Val MSE: 9249.3975  Val R2: -0.6085\n",
      "Epoch 599/1000  Train Loss: 9528.1826  Val Loss: 9242.0176  Val MSE: 9242.0186  Val R2: -0.6073\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 600/1000  Train Loss: 9520.8252  Val Loss: 9234.6455  Val MSE: 9234.6455  Val R2: -0.6060\n",
      "Epoch 601/1000  Train Loss: 9513.4736  Val Loss: 9227.2803  Val MSE: 9227.2803  Val R2: -0.6047\n",
      "Epoch 602/1000  Train Loss: 9506.1289  Val Loss: 9219.9199  Val MSE: 9219.9199  Val R2: -0.6034\n",
      "Epoch 603/1000  Train Loss: 9498.7910  Val Loss: 9212.5664  Val MSE: 9212.5664  Val R2: -0.6021\n",
      "Epoch 604/1000  Train Loss: 9491.4580  Val Loss: 9205.2188  Val MSE: 9205.2188  Val R2: -0.6009\n",
      "Epoch 605/1000  Train Loss: 9484.1318  Val Loss: 9197.8770  Val MSE: 9197.8770  Val R2: -0.5996\n",
      "Epoch 606/1000  Train Loss: 9476.8115  Val Loss: 9190.5420  Val MSE: 9190.5420  Val R2: -0.5983\n",
      "Epoch 607/1000  Train Loss: 9469.4971  Val Loss: 9183.2139  Val MSE: 9183.2129  Val R2: -0.5970\n",
      "Epoch 608/1000  Train Loss: 9462.1895  Val Loss: 9175.8916  Val MSE: 9175.8916  Val R2: -0.5958\n",
      "Epoch 609/1000  Train Loss: 9454.8877  Val Loss: 9168.5752  Val MSE: 9168.5742  Val R2: -0.5945\n",
      "Epoch 610/1000  Train Loss: 9447.5928  Val Loss: 9161.2646  Val MSE: 9161.2637  Val R2: -0.5932\n",
      "Epoch 611/1000  Train Loss: 9440.3037  Val Loss: 9153.9590  Val MSE: 9153.9590  Val R2: -0.5919\n",
      "Epoch 612/1000  Train Loss: 9433.0195  Val Loss: 9146.6621  Val MSE: 9146.6611  Val R2: -0.5907\n",
      "Epoch 613/1000  Train Loss: 9425.7432  Val Loss: 9139.3691  Val MSE: 9139.3691  Val R2: -0.5894\n",
      "Epoch 614/1000  Train Loss: 9418.4717  Val Loss: 9132.0840  Val MSE: 9132.0840  Val R2: -0.5881\n",
      "Epoch 615/1000  Train Loss: 9411.2070  Val Loss: 9124.8027  Val MSE: 9124.8037  Val R2: -0.5869\n",
      "Epoch 616/1000  Train Loss: 9403.9482  Val Loss: 9117.5303  Val MSE: 9117.5293  Val R2: -0.5856\n",
      "Epoch 617/1000  Train Loss: 9396.6963  Val Loss: 9110.2627  Val MSE: 9110.2627  Val R2: -0.5843\n",
      "Epoch 618/1000  Train Loss: 9389.4492  Val Loss: 9103.0000  Val MSE: 9103.0010  Val R2: -0.5831\n",
      "Epoch 619/1000  Train Loss: 9382.2090  Val Loss: 9095.7451  Val MSE: 9095.7451  Val R2: -0.5818\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 620/1000  Train Loss: 9374.9746  Val Loss: 9088.4961  Val MSE: 9088.4971  Val R2: -0.5806\n",
      "Epoch 621/1000  Train Loss: 9367.7471  Val Loss: 9081.2539  Val MSE: 9081.2529  Val R2: -0.5793\n",
      "Epoch 622/1000  Train Loss: 9360.5244  Val Loss: 9074.0156  Val MSE: 9074.0156  Val R2: -0.5780\n",
      "Epoch 623/1000  Train Loss: 9353.3086  Val Loss: 9066.7852  Val MSE: 9066.7852  Val R2: -0.5768\n",
      "Epoch 624/1000  Train Loss: 9346.0986  Val Loss: 9059.5605  Val MSE: 9059.5596  Val R2: -0.5755\n",
      "Epoch 625/1000  Train Loss: 9338.8945  Val Loss: 9052.3428  Val MSE: 9052.3418  Val R2: -0.5743\n",
      "Epoch 626/1000  Train Loss: 9331.6973  Val Loss: 9045.1279  Val MSE: 9045.1279  Val R2: -0.5730\n",
      "Epoch 627/1000  Train Loss: 9324.5049  Val Loss: 9037.9219  Val MSE: 9037.9219  Val R2: -0.5718\n",
      "Epoch 628/1000  Train Loss: 9317.3193  Val Loss: 9030.7207  Val MSE: 9030.7197  Val R2: -0.5705\n",
      "Epoch 629/1000  Train Loss: 9310.1396  Val Loss: 9023.5254  Val MSE: 9023.5254  Val R2: -0.5693\n",
      "Epoch 630/1000  Train Loss: 9302.9658  Val Loss: 9016.3379  Val MSE: 9016.3379  Val R2: -0.5680\n",
      "Epoch 631/1000  Train Loss: 9295.7988  Val Loss: 9009.1553  Val MSE: 9009.1543  Val R2: -0.5668\n",
      "Epoch 632/1000  Train Loss: 9288.6377  Val Loss: 9001.9775  Val MSE: 9001.9775  Val R2: -0.5655\n",
      "Epoch 633/1000  Train Loss: 9281.4805  Val Loss: 8994.8076  Val MSE: 8994.8076  Val R2: -0.5643\n",
      "Epoch 634/1000  Train Loss: 9274.3320  Val Loss: 8987.6416  Val MSE: 8987.6426  Val R2: -0.5630\n",
      "Epoch 635/1000  Train Loss: 9267.1875  Val Loss: 8980.4844  Val MSE: 8980.4844  Val R2: -0.5618\n",
      "Epoch 636/1000  Train Loss: 9260.0518  Val Loss: 8973.3320  Val MSE: 8973.3320  Val R2: -0.5605\n",
      "Epoch 637/1000  Train Loss: 9252.9199  Val Loss: 8966.1865  Val MSE: 8966.1865  Val R2: -0.5593\n",
      "Epoch 638/1000  Train Loss: 9245.7939  Val Loss: 8959.0449  Val MSE: 8959.0449  Val R2: -0.5581\n",
      "Epoch 639/1000  Train Loss: 9238.6738  Val Loss: 8951.9111  Val MSE: 8951.9111  Val R2: -0.5568\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 640/1000  Train Loss: 9231.5605  Val Loss: 8944.7812  Val MSE: 8944.7812  Val R2: -0.5556\n",
      "Epoch 641/1000  Train Loss: 9224.4521  Val Loss: 8937.6592  Val MSE: 8937.6592  Val R2: -0.5543\n",
      "Epoch 642/1000  Train Loss: 9217.3506  Val Loss: 8930.5420  Val MSE: 8930.5430  Val R2: -0.5531\n",
      "Epoch 643/1000  Train Loss: 9210.2559  Val Loss: 8923.4326  Val MSE: 8923.4316  Val R2: -0.5519\n",
      "Epoch 644/1000  Train Loss: 9203.1670  Val Loss: 8916.3271  Val MSE: 8916.3271  Val R2: -0.5506\n",
      "Epoch 645/1000  Train Loss: 9196.0820  Val Loss: 8909.2275  Val MSE: 8909.2275  Val R2: -0.5494\n",
      "Epoch 646/1000  Train Loss: 9189.0049  Val Loss: 8902.1357  Val MSE: 8902.1357  Val R2: -0.5482\n",
      "Epoch 647/1000  Train Loss: 9181.9316  Val Loss: 8895.0488  Val MSE: 8895.0488  Val R2: -0.5469\n",
      "Epoch 648/1000  Train Loss: 9174.8672  Val Loss: 8887.9678  Val MSE: 8887.9678  Val R2: -0.5457\n",
      "Epoch 649/1000  Train Loss: 9167.8066  Val Loss: 8880.8926  Val MSE: 8880.8926  Val R2: -0.5445\n",
      "Epoch 650/1000  Train Loss: 9160.7539  Val Loss: 8873.8232  Val MSE: 8873.8242  Val R2: -0.5432\n",
      "Epoch 651/1000  Train Loss: 9153.7041  Val Loss: 8866.7588  Val MSE: 8866.7598  Val R2: -0.5420\n",
      "Epoch 652/1000  Train Loss: 9146.6611  Val Loss: 8859.7021  Val MSE: 8859.7031  Val R2: -0.5408\n",
      "Epoch 653/1000  Train Loss: 9139.6260  Val Loss: 8852.6514  Val MSE: 8852.6514  Val R2: -0.5395\n",
      "Epoch 654/1000  Train Loss: 9132.5957  Val Loss: 8845.6055  Val MSE: 8845.6064  Val R2: -0.5383\n",
      "Epoch 655/1000  Train Loss: 9125.5713  Val Loss: 8838.5664  Val MSE: 8838.5664  Val R2: -0.5371\n",
      "Epoch 656/1000  Train Loss: 9118.5527  Val Loss: 8831.5332  Val MSE: 8831.5322  Val R2: -0.5359\n",
      "Epoch 657/1000  Train Loss: 9111.5391  Val Loss: 8824.5049  Val MSE: 8824.5049  Val R2: -0.5347\n",
      "Epoch 658/1000  Train Loss: 9104.5332  Val Loss: 8817.4824  Val MSE: 8817.4824  Val R2: -0.5334\n",
      "Epoch 659/1000  Train Loss: 9097.5312  Val Loss: 8810.4668  Val MSE: 8810.4668  Val R2: -0.5322\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 660/1000  Train Loss: 9090.5361  Val Loss: 8803.4570  Val MSE: 8803.4580  Val R2: -0.5310\n",
      "Epoch 661/1000  Train Loss: 9083.5479  Val Loss: 8796.4521  Val MSE: 8796.4531  Val R2: -0.5298\n",
      "Epoch 662/1000  Train Loss: 9076.5635  Val Loss: 8789.4541  Val MSE: 8789.4541  Val R2: -0.5286\n",
      "Epoch 663/1000  Train Loss: 9069.5859  Val Loss: 8782.4609  Val MSE: 8782.4609  Val R2: -0.5273\n",
      "Epoch 664/1000  Train Loss: 9062.6143  Val Loss: 8775.4756  Val MSE: 8775.4756  Val R2: -0.5261\n",
      "Epoch 665/1000  Train Loss: 9055.6484  Val Loss: 8768.4941  Val MSE: 8768.4941  Val R2: -0.5249\n",
      "Epoch 666/1000  Train Loss: 9048.6885  Val Loss: 8761.5186  Val MSE: 8761.5195  Val R2: -0.5237\n",
      "Epoch 667/1000  Train Loss: 9041.7344  Val Loss: 8754.5498  Val MSE: 8754.5498  Val R2: -0.5225\n",
      "Epoch 668/1000  Train Loss: 9034.7861  Val Loss: 8747.5869  Val MSE: 8747.5869  Val R2: -0.5213\n",
      "Epoch 669/1000  Train Loss: 9027.8438  Val Loss: 8740.6289  Val MSE: 8740.6289  Val R2: -0.5201\n",
      "Epoch 670/1000  Train Loss: 9020.9072  Val Loss: 8733.6768  Val MSE: 8733.6768  Val R2: -0.5189\n",
      "Epoch 671/1000  Train Loss: 9013.9756  Val Loss: 8726.7314  Val MSE: 8726.7314  Val R2: -0.5177\n",
      "Epoch 672/1000  Train Loss: 9007.0508  Val Loss: 8719.7910  Val MSE: 8719.7920  Val R2: -0.5164\n",
      "Epoch 673/1000  Train Loss: 9000.1309  Val Loss: 8712.8564  Val MSE: 8712.8564  Val R2: -0.5152\n",
      "Epoch 674/1000  Train Loss: 8993.2188  Val Loss: 8705.9287  Val MSE: 8705.9287  Val R2: -0.5140\n",
      "Epoch 675/1000  Train Loss: 8986.3105  Val Loss: 8699.0059  Val MSE: 8699.0059  Val R2: -0.5128\n",
      "Epoch 676/1000  Train Loss: 8979.4082  Val Loss: 8692.0879  Val MSE: 8692.0879  Val R2: -0.5116\n",
      "Epoch 677/1000  Train Loss: 8972.5117  Val Loss: 8685.1777  Val MSE: 8685.1777  Val R2: -0.5104\n",
      "Epoch 678/1000  Train Loss: 8965.6221  Val Loss: 8678.2705  Val MSE: 8678.2715  Val R2: -0.5092\n",
      "Epoch 679/1000  Train Loss: 8958.7363  Val Loss: 8671.3721  Val MSE: 8671.3711  Val R2: -0.5080\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 680/1000  Train Loss: 8951.8574  Val Loss: 8664.4795  Val MSE: 8664.4785  Val R2: -0.5068\n",
      "Epoch 681/1000  Train Loss: 8944.9854  Val Loss: 8657.5908  Val MSE: 8657.5898  Val R2: -0.5056\n",
      "Epoch 682/1000  Train Loss: 8938.1182  Val Loss: 8650.7080  Val MSE: 8650.7080  Val R2: -0.5044\n",
      "Epoch 683/1000  Train Loss: 8931.2559  Val Loss: 8643.8311  Val MSE: 8643.8311  Val R2: -0.5032\n",
      "Epoch 684/1000  Train Loss: 8924.4014  Val Loss: 8636.9590  Val MSE: 8636.9600  Val R2: -0.5020\n",
      "Epoch 685/1000  Train Loss: 8917.5498  Val Loss: 8630.0947  Val MSE: 8630.0947  Val R2: -0.5008\n",
      "Epoch 686/1000  Train Loss: 8910.7051  Val Loss: 8623.2354  Val MSE: 8623.2354  Val R2: -0.4997\n",
      "Epoch 687/1000  Train Loss: 8903.8682  Val Loss: 8616.3818  Val MSE: 8616.3818  Val R2: -0.4985\n",
      "Epoch 688/1000  Train Loss: 8897.0342  Val Loss: 8609.5342  Val MSE: 8609.5332  Val R2: -0.4973\n",
      "Epoch 689/1000  Train Loss: 8890.2070  Val Loss: 8602.6914  Val MSE: 8602.6914  Val R2: -0.4961\n",
      "Epoch 690/1000  Train Loss: 8883.3857  Val Loss: 8595.8545  Val MSE: 8595.8545  Val R2: -0.4949\n",
      "Epoch 691/1000  Train Loss: 8876.5703  Val Loss: 8589.0254  Val MSE: 8589.0234  Val R2: -0.4937\n",
      "Epoch 692/1000  Train Loss: 8869.7598  Val Loss: 8582.1992  Val MSE: 8582.1992  Val R2: -0.4925\n",
      "Epoch 693/1000  Train Loss: 8862.9551  Val Loss: 8575.3789  Val MSE: 8575.3789  Val R2: -0.4913\n",
      "Epoch 694/1000  Train Loss: 8856.1572  Val Loss: 8568.5654  Val MSE: 8568.5654  Val R2: -0.4901\n",
      "Epoch 695/1000  Train Loss: 8849.3633  Val Loss: 8561.7568  Val MSE: 8561.7568  Val R2: -0.4890\n",
      "Epoch 696/1000  Train Loss: 8842.5762  Val Loss: 8554.9561  Val MSE: 8554.9541  Val R2: -0.4878\n",
      "Epoch 697/1000  Train Loss: 8835.7949  Val Loss: 8548.1582  Val MSE: 8548.1582  Val R2: -0.4866\n",
      "Epoch 698/1000  Train Loss: 8829.0186  Val Loss: 8541.3672  Val MSE: 8541.3672  Val R2: -0.4854\n",
      "Epoch 699/1000  Train Loss: 8822.2480  Val Loss: 8534.5811  Val MSE: 8534.5820  Val R2: -0.4842\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 700/1000  Train Loss: 8815.4834  Val Loss: 8527.8018  Val MSE: 8527.8018  Val R2: -0.4831\n",
      "Epoch 701/1000  Train Loss: 8808.7256  Val Loss: 8521.0283  Val MSE: 8521.0283  Val R2: -0.4819\n",
      "Epoch 702/1000  Train Loss: 8801.9707  Val Loss: 8514.2607  Val MSE: 8514.2607  Val R2: -0.4807\n",
      "Epoch 703/1000  Train Loss: 8795.2246  Val Loss: 8507.4971  Val MSE: 8507.4971  Val R2: -0.4795\n",
      "Epoch 704/1000  Train Loss: 8788.4814  Val Loss: 8500.7393  Val MSE: 8500.7393  Val R2: -0.4783\n",
      "Epoch 705/1000  Train Loss: 8781.7451  Val Loss: 8493.9893  Val MSE: 8493.9893  Val R2: -0.4772\n",
      "Epoch 706/1000  Train Loss: 8775.0146  Val Loss: 8487.2422  Val MSE: 8487.2432  Val R2: -0.4760\n",
      "Epoch 707/1000  Train Loss: 8768.2891  Val Loss: 8480.5020  Val MSE: 8480.5020  Val R2: -0.4748\n",
      "Epoch 708/1000  Train Loss: 8761.5693  Val Loss: 8473.7676  Val MSE: 8473.7676  Val R2: -0.4737\n",
      "Epoch 709/1000  Train Loss: 8754.8555  Val Loss: 8467.0381  Val MSE: 8467.0381  Val R2: -0.4725\n",
      "Epoch 710/1000  Train Loss: 8748.1475  Val Loss: 8460.3145  Val MSE: 8460.3145  Val R2: -0.4713\n",
      "Epoch 711/1000  Train Loss: 8741.4434  Val Loss: 8453.5967  Val MSE: 8453.5967  Val R2: -0.4701\n",
      "Epoch 712/1000  Train Loss: 8734.7480  Val Loss: 8446.8848  Val MSE: 8446.8857  Val R2: -0.4690\n",
      "Epoch 713/1000  Train Loss: 8728.0566  Val Loss: 8440.1777  Val MSE: 8440.1787  Val R2: -0.4678\n",
      "Epoch 714/1000  Train Loss: 8721.3701  Val Loss: 8433.4775  Val MSE: 8433.4775  Val R2: -0.4667\n",
      "Epoch 715/1000  Train Loss: 8714.6904  Val Loss: 8426.7812  Val MSE: 8426.7822  Val R2: -0.4655\n",
      "Epoch 716/1000  Train Loss: 8708.0146  Val Loss: 8420.0918  Val MSE: 8420.0908  Val R2: -0.4643\n",
      "Epoch 717/1000  Train Loss: 8701.3457  Val Loss: 8413.4072  Val MSE: 8413.4082  Val R2: -0.4632\n",
      "Epoch 718/1000  Train Loss: 8694.6807  Val Loss: 8406.7295  Val MSE: 8406.7295  Val R2: -0.4620\n",
      "Epoch 719/1000  Train Loss: 8688.0244  Val Loss: 8400.0557  Val MSE: 8400.0557  Val R2: -0.4608\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 720/1000  Train Loss: 8681.3711  Val Loss: 8393.3877  Val MSE: 8393.3877  Val R2: -0.4597\n",
      "Epoch 721/1000  Train Loss: 8674.7246  Val Loss: 8386.7266  Val MSE: 8386.7256  Val R2: -0.4585\n",
      "Epoch 722/1000  Train Loss: 8668.0840  Val Loss: 8380.0684  Val MSE: 8380.0693  Val R2: -0.4574\n",
      "Epoch 723/1000  Train Loss: 8661.4473  Val Loss: 8373.4189  Val MSE: 8373.4189  Val R2: -0.4562\n",
      "Epoch 724/1000  Train Loss: 8654.8164  Val Loss: 8366.7734  Val MSE: 8366.7734  Val R2: -0.4551\n",
      "Epoch 725/1000  Train Loss: 8648.1914  Val Loss: 8360.1318  Val MSE: 8360.1328  Val R2: -0.4539\n",
      "Epoch 726/1000  Train Loss: 8641.5723  Val Loss: 8353.4990  Val MSE: 8353.4980  Val R2: -0.4527\n",
      "Epoch 727/1000  Train Loss: 8634.9580  Val Loss: 8346.8711  Val MSE: 8346.8701  Val R2: -0.4516\n",
      "Epoch 728/1000  Train Loss: 8628.3506  Val Loss: 8340.2461  Val MSE: 8340.2451  Val R2: -0.4504\n",
      "Epoch 729/1000  Train Loss: 8621.7471  Val Loss: 8333.6279  Val MSE: 8333.6279  Val R2: -0.4493\n",
      "Epoch 730/1000  Train Loss: 8615.1504  Val Loss: 8327.0156  Val MSE: 8327.0156  Val R2: -0.4481\n",
      "Epoch 731/1000  Train Loss: 8608.5586  Val Loss: 8320.4092  Val MSE: 8320.4092  Val R2: -0.4470\n",
      "Epoch 732/1000  Train Loss: 8601.9717  Val Loss: 8313.8076  Val MSE: 8313.8076  Val R2: -0.4458\n",
      "Epoch 733/1000  Train Loss: 8595.3916  Val Loss: 8307.2129  Val MSE: 8307.2119  Val R2: -0.4447\n",
      "Epoch 734/1000  Train Loss: 8588.8164  Val Loss: 8300.6221  Val MSE: 8300.6211  Val R2: -0.4435\n",
      "Epoch 735/1000  Train Loss: 8582.2461  Val Loss: 8294.0361  Val MSE: 8294.0361  Val R2: -0.4424\n",
      "Epoch 736/1000  Train Loss: 8575.6816  Val Loss: 8287.4580  Val MSE: 8287.4580  Val R2: -0.4413\n",
      "Epoch 737/1000  Train Loss: 8569.1240  Val Loss: 8280.8848  Val MSE: 8280.8838  Val R2: -0.4401\n",
      "Epoch 738/1000  Train Loss: 8562.5713  Val Loss: 8274.3154  Val MSE: 8274.3154  Val R2: -0.4390\n",
      "Epoch 739/1000  Train Loss: 8556.0225  Val Loss: 8267.7529  Val MSE: 8267.7529  Val R2: -0.4378\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 740/1000  Train Loss: 8549.4805  Val Loss: 8261.1943  Val MSE: 8261.1953  Val R2: -0.4367\n",
      "Epoch 741/1000  Train Loss: 8542.9434  Val Loss: 8254.6426  Val MSE: 8254.6426  Val R2: -0.4356\n",
      "Epoch 742/1000  Train Loss: 8536.4111  Val Loss: 8248.0967  Val MSE: 8248.0967  Val R2: -0.4344\n",
      "Epoch 743/1000  Train Loss: 8529.8857  Val Loss: 8241.5557  Val MSE: 8241.5557  Val R2: -0.4333\n",
      "Epoch 744/1000  Train Loss: 8523.3652  Val Loss: 8235.0195  Val MSE: 8235.0195  Val R2: -0.4321\n",
      "Epoch 745/1000  Train Loss: 8516.8506  Val Loss: 8228.4883  Val MSE: 8228.4883  Val R2: -0.4310\n",
      "Epoch 746/1000  Train Loss: 8510.3398  Val Loss: 8221.9639  Val MSE: 8221.9648  Val R2: -0.4299\n",
      "Epoch 747/1000  Train Loss: 8503.8350  Val Loss: 8215.4434  Val MSE: 8215.4443  Val R2: -0.4287\n",
      "Epoch 748/1000  Train Loss: 8497.3369  Val Loss: 8208.9316  Val MSE: 8208.9316  Val R2: -0.4276\n",
      "Epoch 749/1000  Train Loss: 8490.8428  Val Loss: 8202.4219  Val MSE: 8202.4219  Val R2: -0.4265\n",
      "Epoch 750/1000  Train Loss: 8484.3545  Val Loss: 8195.9180  Val MSE: 8195.9180  Val R2: -0.4253\n",
      "Epoch 751/1000  Train Loss: 8477.8721  Val Loss: 8189.4214  Val MSE: 8189.4214  Val R2: -0.4242\n",
      "Epoch 752/1000  Train Loss: 8471.3945  Val Loss: 8182.9292  Val MSE: 8182.9282  Val R2: -0.4231\n",
      "Epoch 753/1000  Train Loss: 8464.9229  Val Loss: 8176.4409  Val MSE: 8176.4419  Val R2: -0.4220\n",
      "Epoch 754/1000  Train Loss: 8458.4561  Val Loss: 8169.9590  Val MSE: 8169.9600  Val R2: -0.4208\n",
      "Epoch 755/1000  Train Loss: 8451.9951  Val Loss: 8163.4839  Val MSE: 8163.4839  Val R2: -0.4197\n",
      "Epoch 756/1000  Train Loss: 8445.5391  Val Loss: 8157.0132  Val MSE: 8157.0132  Val R2: -0.4186\n",
      "Epoch 757/1000  Train Loss: 8439.0879  Val Loss: 8150.5469  Val MSE: 8150.5469  Val R2: -0.4174\n",
      "Epoch 758/1000  Train Loss: 8432.6436  Val Loss: 8144.0874  Val MSE: 8144.0874  Val R2: -0.4163\n",
      "Epoch 759/1000  Train Loss: 8426.2051  Val Loss: 8137.6333  Val MSE: 8137.6333  Val R2: -0.4152\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 760/1000  Train Loss: 8419.7705  Val Loss: 8131.1831  Val MSE: 8131.1831  Val R2: -0.4141\n",
      "Epoch 761/1000  Train Loss: 8413.3418  Val Loss: 8124.7388  Val MSE: 8124.7388  Val R2: -0.4130\n",
      "Epoch 762/1000  Train Loss: 8406.9170  Val Loss: 8118.3003  Val MSE: 8118.3003  Val R2: -0.4118\n",
      "Epoch 763/1000  Train Loss: 8400.5000  Val Loss: 8111.8672  Val MSE: 8111.8677  Val R2: -0.4107\n",
      "Epoch 764/1000  Train Loss: 8394.0869  Val Loss: 8105.4390  Val MSE: 8105.4390  Val R2: -0.4096\n",
      "Epoch 765/1000  Train Loss: 8387.6777  Val Loss: 8099.0166  Val MSE: 8099.0166  Val R2: -0.4085\n",
      "Epoch 766/1000  Train Loss: 8381.2773  Val Loss: 8092.5991  Val MSE: 8092.5991  Val R2: -0.4074\n",
      "Epoch 767/1000  Train Loss: 8374.8799  Val Loss: 8086.1880  Val MSE: 8086.1870  Val R2: -0.4063\n",
      "Epoch 768/1000  Train Loss: 8368.4883  Val Loss: 8079.7803  Val MSE: 8079.7803  Val R2: -0.4051\n",
      "Epoch 769/1000  Train Loss: 8362.1025  Val Loss: 8073.3794  Val MSE: 8073.3794  Val R2: -0.4040\n",
      "Epoch 770/1000  Train Loss: 8355.7207  Val Loss: 8066.9844  Val MSE: 8066.9834  Val R2: -0.4029\n",
      "Epoch 771/1000  Train Loss: 8349.3457  Val Loss: 8060.5928  Val MSE: 8060.5933  Val R2: -0.4018\n",
      "Epoch 772/1000  Train Loss: 8342.9746  Val Loss: 8054.2075  Val MSE: 8054.2075  Val R2: -0.4007\n",
      "Epoch 773/1000  Train Loss: 8336.6113  Val Loss: 8047.8271  Val MSE: 8047.8271  Val R2: -0.3996\n",
      "Epoch 774/1000  Train Loss: 8330.2500  Val Loss: 8041.4531  Val MSE: 8041.4531  Val R2: -0.3985\n",
      "Epoch 775/1000  Train Loss: 8323.8965  Val Loss: 8035.0830  Val MSE: 8035.0830  Val R2: -0.3974\n",
      "Epoch 776/1000  Train Loss: 8317.5469  Val Loss: 8028.7183  Val MSE: 8028.7183  Val R2: -0.3963\n",
      "Epoch 777/1000  Train Loss: 8311.2041  Val Loss: 8022.3589  Val MSE: 8022.3599  Val R2: -0.3952\n",
      "Epoch 778/1000  Train Loss: 8304.8652  Val Loss: 8016.0054  Val MSE: 8016.0063  Val R2: -0.3940\n",
      "Epoch 779/1000  Train Loss: 8298.5312  Val Loss: 8009.6577  Val MSE: 8009.6577  Val R2: -0.3929\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 780/1000  Train Loss: 8292.2041  Val Loss: 8003.3145  Val MSE: 8003.3145  Val R2: -0.3918\n",
      "Epoch 781/1000  Train Loss: 8285.8809  Val Loss: 7996.9766  Val MSE: 7996.9766  Val R2: -0.3907\n",
      "Epoch 782/1000  Train Loss: 8279.5625  Val Loss: 7990.6436  Val MSE: 7990.6436  Val R2: -0.3896\n",
      "Epoch 783/1000  Train Loss: 8273.2510  Val Loss: 7984.3164  Val MSE: 7984.3164  Val R2: -0.3885\n",
      "Epoch 784/1000  Train Loss: 8266.9443  Val Loss: 7977.9946  Val MSE: 7977.9946  Val R2: -0.3874\n",
      "Epoch 785/1000  Train Loss: 8260.6416  Val Loss: 7971.6772  Val MSE: 7971.6772  Val R2: -0.3863\n",
      "Epoch 786/1000  Train Loss: 8254.3447  Val Loss: 7965.3667  Val MSE: 7965.3667  Val R2: -0.3852\n",
      "Epoch 787/1000  Train Loss: 8248.0547  Val Loss: 7959.0596  Val MSE: 7959.0596  Val R2: -0.3841\n",
      "Epoch 788/1000  Train Loss: 8241.7686  Val Loss: 7952.7593  Val MSE: 7952.7593  Val R2: -0.3831\n",
      "Epoch 789/1000  Train Loss: 8235.4873  Val Loss: 7946.4624  Val MSE: 7946.4624  Val R2: -0.3820\n",
      "Epoch 790/1000  Train Loss: 8229.2109  Val Loss: 7940.1719  Val MSE: 7940.1719  Val R2: -0.3809\n",
      "Epoch 791/1000  Train Loss: 8222.9414  Val Loss: 7933.8867  Val MSE: 7933.8867  Val R2: -0.3798\n",
      "Epoch 792/1000  Train Loss: 8216.6768  Val Loss: 7927.6055  Val MSE: 7927.6064  Val R2: -0.3787\n",
      "Epoch 793/1000  Train Loss: 8210.4170  Val Loss: 7921.3320  Val MSE: 7921.3311  Val R2: -0.3776\n",
      "Epoch 794/1000  Train Loss: 8204.1611  Val Loss: 7915.0615  Val MSE: 7915.0615  Val R2: -0.3765\n",
      "Epoch 795/1000  Train Loss: 8197.9121  Val Loss: 7908.7964  Val MSE: 7908.7964  Val R2: -0.3754\n",
      "Epoch 796/1000  Train Loss: 8191.6670  Val Loss: 7902.5376  Val MSE: 7902.5376  Val R2: -0.3743\n",
      "Epoch 797/1000  Train Loss: 8185.4287  Val Loss: 7896.2837  Val MSE: 7896.2827  Val R2: -0.3732\n",
      "Epoch 798/1000  Train Loss: 8179.1943  Val Loss: 7890.0342  Val MSE: 7890.0337  Val R2: -0.3721\n",
      "Epoch 799/1000  Train Loss: 8172.9658  Val Loss: 7883.7905  Val MSE: 7883.7896  Val R2: -0.3711\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 800/1000  Train Loss: 8166.7422  Val Loss: 7877.5518  Val MSE: 7877.5518  Val R2: -0.3700\n",
      "Epoch 801/1000  Train Loss: 8160.5239  Val Loss: 7871.3174  Val MSE: 7871.3174  Val R2: -0.3689\n",
      "Epoch 802/1000  Train Loss: 8154.3096  Val Loss: 7865.0894  Val MSE: 7865.0894  Val R2: -0.3678\n",
      "Epoch 803/1000  Train Loss: 8148.1025  Val Loss: 7858.8672  Val MSE: 7858.8662  Val R2: -0.3667\n",
      "Epoch 804/1000  Train Loss: 8141.8994  Val Loss: 7852.6484  Val MSE: 7852.6484  Val R2: -0.3656\n",
      "Epoch 805/1000  Train Loss: 8135.7021  Val Loss: 7846.4355  Val MSE: 7846.4355  Val R2: -0.3646\n",
      "Epoch 806/1000  Train Loss: 8129.5078  Val Loss: 7840.2271  Val MSE: 7840.2280  Val R2: -0.3635\n",
      "Epoch 807/1000  Train Loss: 8123.3208  Val Loss: 7834.0244  Val MSE: 7834.0249  Val R2: -0.3624\n",
      "Epoch 808/1000  Train Loss: 8117.1387  Val Loss: 7827.8281  Val MSE: 7827.8271  Val R2: -0.3613\n",
      "Epoch 809/1000  Train Loss: 8110.9619  Val Loss: 7821.6353  Val MSE: 7821.6353  Val R2: -0.3602\n",
      "Epoch 810/1000  Train Loss: 8104.7896  Val Loss: 7815.4473  Val MSE: 7815.4473  Val R2: -0.3592\n",
      "Epoch 811/1000  Train Loss: 8098.6216  Val Loss: 7809.2651  Val MSE: 7809.2661  Val R2: -0.3581\n",
      "Epoch 812/1000  Train Loss: 8092.4604  Val Loss: 7803.0884  Val MSE: 7803.0884  Val R2: -0.3570\n",
      "Epoch 813/1000  Train Loss: 8086.3032  Val Loss: 7796.9165  Val MSE: 7796.9170  Val R2: -0.3559\n",
      "Epoch 814/1000  Train Loss: 8080.1519  Val Loss: 7790.7505  Val MSE: 7790.7500  Val R2: -0.3549\n",
      "Epoch 815/1000  Train Loss: 8074.0054  Val Loss: 7784.5889  Val MSE: 7784.5889  Val R2: -0.3538\n",
      "Epoch 816/1000  Train Loss: 8067.8633  Val Loss: 7778.4316  Val MSE: 7778.4316  Val R2: -0.3527\n",
      "Epoch 817/1000  Train Loss: 8061.7275  Val Loss: 7772.2803  Val MSE: 7772.2803  Val R2: -0.3517\n",
      "Epoch 818/1000  Train Loss: 8055.5962  Val Loss: 7766.1343  Val MSE: 7766.1348  Val R2: -0.3506\n",
      "Epoch 819/1000  Train Loss: 8049.4707  Val Loss: 7759.9932  Val MSE: 7759.9927  Val R2: -0.3495\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 820/1000  Train Loss: 8043.3486  Val Loss: 7753.8569  Val MSE: 7753.8569  Val R2: -0.3485\n",
      "Epoch 821/1000  Train Loss: 8037.2334  Val Loss: 7747.7256  Val MSE: 7747.7251  Val R2: -0.3474\n",
      "Epoch 822/1000  Train Loss: 8031.1221  Val Loss: 7741.5996  Val MSE: 7741.5996  Val R2: -0.3463\n",
      "Epoch 823/1000  Train Loss: 8025.0156  Val Loss: 7735.4780  Val MSE: 7735.4785  Val R2: -0.3453\n",
      "Epoch 824/1000  Train Loss: 8018.9155  Val Loss: 7729.3628  Val MSE: 7729.3628  Val R2: -0.3442\n",
      "Epoch 825/1000  Train Loss: 8012.8193  Val Loss: 7723.2520  Val MSE: 7723.2520  Val R2: -0.3431\n",
      "Epoch 826/1000  Train Loss: 8006.7285  Val Loss: 7717.1460  Val MSE: 7717.1460  Val R2: -0.3421\n",
      "Epoch 827/1000  Train Loss: 8000.6426  Val Loss: 7711.0454  Val MSE: 7711.0464  Val R2: -0.3410\n",
      "Epoch 828/1000  Train Loss: 7994.5630  Val Loss: 7704.9502  Val MSE: 7704.9497  Val R2: -0.3400\n",
      "Epoch 829/1000  Train Loss: 7988.4873  Val Loss: 7698.8594  Val MSE: 7698.8594  Val R2: -0.3389\n",
      "Epoch 830/1000  Train Loss: 7982.4165  Val Loss: 7692.7734  Val MSE: 7692.7739  Val R2: -0.3378\n",
      "Epoch 831/1000  Train Loss: 7976.3516  Val Loss: 7686.6929  Val MSE: 7686.6938  Val R2: -0.3368\n",
      "Epoch 832/1000  Train Loss: 7970.2910  Val Loss: 7680.6172  Val MSE: 7680.6177  Val R2: -0.3357\n",
      "Epoch 833/1000  Train Loss: 7964.2354  Val Loss: 7674.5469  Val MSE: 7674.5474  Val R2: -0.3347\n",
      "Epoch 834/1000  Train Loss: 7958.1851  Val Loss: 7668.4819  Val MSE: 7668.4819  Val R2: -0.3336\n",
      "Epoch 835/1000  Train Loss: 7952.1396  Val Loss: 7662.4214  Val MSE: 7662.4209  Val R2: -0.3326\n",
      "Epoch 836/1000  Train Loss: 7946.0986  Val Loss: 7656.3657  Val MSE: 7656.3667  Val R2: -0.3315\n",
      "Epoch 837/1000  Train Loss: 7940.0649  Val Loss: 7650.3154  Val MSE: 7650.3159  Val R2: -0.3305\n",
      "Epoch 838/1000  Train Loss: 7934.0337  Val Loss: 7644.2705  Val MSE: 7644.2705  Val R2: -0.3294\n",
      "Epoch 839/1000  Train Loss: 7928.0093  Val Loss: 7638.2300  Val MSE: 7638.2300  Val R2: -0.3284\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 840/1000  Train Loss: 7921.9888  Val Loss: 7632.1943  Val MSE: 7632.1943  Val R2: -0.3273\n",
      "Epoch 841/1000  Train Loss: 7915.9741  Val Loss: 7626.1641  Val MSE: 7626.1636  Val R2: -0.3263\n",
      "Epoch 842/1000  Train Loss: 7909.9629  Val Loss: 7620.1392  Val MSE: 7620.1392  Val R2: -0.3252\n",
      "Epoch 843/1000  Train Loss: 7903.9580  Val Loss: 7614.1191  Val MSE: 7614.1187  Val R2: -0.3242\n",
      "Epoch 844/1000  Train Loss: 7897.9570  Val Loss: 7608.1030  Val MSE: 7608.1030  Val R2: -0.3231\n",
      "Epoch 845/1000  Train Loss: 7891.9619  Val Loss: 7602.0923  Val MSE: 7602.0933  Val R2: -0.3221\n",
      "Epoch 846/1000  Train Loss: 7885.9712  Val Loss: 7596.0879  Val MSE: 7596.0874  Val R2: -0.3210\n",
      "Epoch 847/1000  Train Loss: 7879.9858  Val Loss: 7590.0874  Val MSE: 7590.0864  Val R2: -0.3200\n",
      "Epoch 848/1000  Train Loss: 7874.0054  Val Loss: 7584.0913  Val MSE: 7584.0913  Val R2: -0.3189\n",
      "Epoch 849/1000  Train Loss: 7868.0308  Val Loss: 7578.1006  Val MSE: 7578.1006  Val R2: -0.3179\n",
      "Epoch 850/1000  Train Loss: 7862.0586  Val Loss: 7572.1143  Val MSE: 7572.1152  Val R2: -0.3169\n",
      "Epoch 851/1000  Train Loss: 7856.0933  Val Loss: 7566.1338  Val MSE: 7566.1338  Val R2: -0.3158\n",
      "Epoch 852/1000  Train Loss: 7850.1328  Val Loss: 7560.1592  Val MSE: 7560.1587  Val R2: -0.3148\n",
      "Epoch 853/1000  Train Loss: 7844.1768  Val Loss: 7554.1870  Val MSE: 7554.1875  Val R2: -0.3137\n",
      "Epoch 854/1000  Train Loss: 7838.2271  Val Loss: 7548.2222  Val MSE: 7548.2222  Val R2: -0.3127\n",
      "Epoch 855/1000  Train Loss: 7832.2798  Val Loss: 7542.2612  Val MSE: 7542.2612  Val R2: -0.3117\n",
      "Epoch 856/1000  Train Loss: 7826.3394  Val Loss: 7536.3052  Val MSE: 7536.3052  Val R2: -0.3106\n",
      "Epoch 857/1000  Train Loss: 7820.4038  Val Loss: 7530.3540  Val MSE: 7530.3545  Val R2: -0.3096\n",
      "Epoch 858/1000  Train Loss: 7814.4727  Val Loss: 7524.4082  Val MSE: 7524.4082  Val R2: -0.3086\n",
      "Epoch 859/1000  Train Loss: 7808.5459  Val Loss: 7518.4668  Val MSE: 7518.4668  Val R2: -0.3075\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 860/1000  Train Loss: 7802.6260  Val Loss: 7512.5308  Val MSE: 7512.5298  Val R2: -0.3065\n",
      "Epoch 861/1000  Train Loss: 7796.7090  Val Loss: 7506.5991  Val MSE: 7506.5991  Val R2: -0.3055\n",
      "Epoch 862/1000  Train Loss: 7790.7979  Val Loss: 7500.6724  Val MSE: 7500.6729  Val R2: -0.3044\n",
      "Epoch 863/1000  Train Loss: 7784.8911  Val Loss: 7494.7505  Val MSE: 7494.7510  Val R2: -0.3034\n",
      "Epoch 864/1000  Train Loss: 7778.9888  Val Loss: 7488.8345  Val MSE: 7488.8350  Val R2: -0.3024\n",
      "Epoch 865/1000  Train Loss: 7773.0933  Val Loss: 7482.9224  Val MSE: 7482.9219  Val R2: -0.3013\n",
      "Epoch 866/1000  Train Loss: 7767.2007  Val Loss: 7477.0156  Val MSE: 7477.0156  Val R2: -0.3003\n",
      "Epoch 867/1000  Train Loss: 7761.3135  Val Loss: 7471.1128  Val MSE: 7471.1138  Val R2: -0.2993\n",
      "Epoch 868/1000  Train Loss: 7755.4316  Val Loss: 7465.2163  Val MSE: 7465.2163  Val R2: -0.2983\n",
      "Epoch 869/1000  Train Loss: 7749.5542  Val Loss: 7459.3242  Val MSE: 7459.3242  Val R2: -0.2972\n",
      "Epoch 870/1000  Train Loss: 7743.6816  Val Loss: 7453.4370  Val MSE: 7453.4365  Val R2: -0.2962\n",
      "Epoch 871/1000  Train Loss: 7737.8145  Val Loss: 7447.5542  Val MSE: 7447.5537  Val R2: -0.2952\n",
      "Epoch 872/1000  Train Loss: 7731.9512  Val Loss: 7441.6758  Val MSE: 7441.6768  Val R2: -0.2942\n",
      "Epoch 873/1000  Train Loss: 7726.0938  Val Loss: 7435.8037  Val MSE: 7435.8037  Val R2: -0.2931\n",
      "Epoch 874/1000  Train Loss: 7720.2412  Val Loss: 7429.9355  Val MSE: 7429.9355  Val R2: -0.2921\n",
      "Epoch 875/1000  Train Loss: 7714.3931  Val Loss: 7424.0732  Val MSE: 7424.0732  Val R2: -0.2911\n",
      "Epoch 876/1000  Train Loss: 7708.5493  Val Loss: 7418.2139  Val MSE: 7418.2134  Val R2: -0.2901\n",
      "Epoch 877/1000  Train Loss: 7702.7109  Val Loss: 7412.3608  Val MSE: 7412.3608  Val R2: -0.2891\n",
      "Epoch 878/1000  Train Loss: 7696.8774  Val Loss: 7406.5122  Val MSE: 7406.5132  Val R2: -0.2881\n",
      "Epoch 879/1000  Train Loss: 7691.0498  Val Loss: 7400.6680  Val MSE: 7400.6685  Val R2: -0.2870\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 880/1000  Train Loss: 7685.2251  Val Loss: 7394.8291  Val MSE: 7394.8291  Val R2: -0.2860\n",
      "Epoch 881/1000  Train Loss: 7679.4062  Val Loss: 7388.9956  Val MSE: 7388.9951  Val R2: -0.2850\n",
      "Epoch 882/1000  Train Loss: 7673.5913  Val Loss: 7383.1655  Val MSE: 7383.1655  Val R2: -0.2840\n",
      "Epoch 883/1000  Train Loss: 7667.7817  Val Loss: 7377.3413  Val MSE: 7377.3413  Val R2: -0.2830\n",
      "Epoch 884/1000  Train Loss: 7661.9771  Val Loss: 7371.5229  Val MSE: 7371.5220  Val R2: -0.2820\n",
      "Epoch 885/1000  Train Loss: 7656.1772  Val Loss: 7365.7065  Val MSE: 7365.7070  Val R2: -0.2810\n",
      "Epoch 886/1000  Train Loss: 7650.3823  Val Loss: 7359.8970  Val MSE: 7359.8970  Val R2: -0.2799\n",
      "Epoch 887/1000  Train Loss: 7644.5928  Val Loss: 7354.0923  Val MSE: 7354.0923  Val R2: -0.2789\n",
      "Epoch 888/1000  Train Loss: 7638.8066  Val Loss: 7348.2915  Val MSE: 7348.2910  Val R2: -0.2779\n",
      "Epoch 889/1000  Train Loss: 7633.0254  Val Loss: 7342.4956  Val MSE: 7342.4956  Val R2: -0.2769\n",
      "Epoch 890/1000  Train Loss: 7627.2500  Val Loss: 7336.7051  Val MSE: 7336.7051  Val R2: -0.2759\n",
      "Epoch 891/1000  Train Loss: 7621.4790  Val Loss: 7330.9175  Val MSE: 7330.9180  Val R2: -0.2749\n",
      "Epoch 892/1000  Train Loss: 7615.7129  Val Loss: 7325.1367  Val MSE: 7325.1372  Val R2: -0.2739\n",
      "Epoch 893/1000  Train Loss: 7609.9517  Val Loss: 7319.3599  Val MSE: 7319.3599  Val R2: -0.2729\n",
      "Epoch 894/1000  Train Loss: 7604.1948  Val Loss: 7313.5884  Val MSE: 7313.5884  Val R2: -0.2719\n",
      "Epoch 895/1000  Train Loss: 7598.4424  Val Loss: 7307.8223  Val MSE: 7307.8218  Val R2: -0.2709\n",
      "Epoch 896/1000  Train Loss: 7592.6943  Val Loss: 7302.0596  Val MSE: 7302.0596  Val R2: -0.2699\n",
      "Epoch 897/1000  Train Loss: 7586.9526  Val Loss: 7296.3018  Val MSE: 7296.3013  Val R2: -0.2689\n",
      "Epoch 898/1000  Train Loss: 7581.2148  Val Loss: 7290.5488  Val MSE: 7290.5488  Val R2: -0.2679\n",
      "Epoch 899/1000  Train Loss: 7575.4819  Val Loss: 7284.8013  Val MSE: 7284.8013  Val R2: -0.2669\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 900/1000  Train Loss: 7569.7539  Val Loss: 7279.0581  Val MSE: 7279.0581  Val R2: -0.2659\n",
      "Epoch 901/1000  Train Loss: 7564.0303  Val Loss: 7273.3188  Val MSE: 7273.3188  Val R2: -0.2649\n",
      "Epoch 902/1000  Train Loss: 7558.3115  Val Loss: 7267.5854  Val MSE: 7267.5859  Val R2: -0.2639\n",
      "Epoch 903/1000  Train Loss: 7552.5967  Val Loss: 7261.8564  Val MSE: 7261.8560  Val R2: -0.2629\n",
      "Epoch 904/1000  Train Loss: 7546.8872  Val Loss: 7256.1323  Val MSE: 7256.1323  Val R2: -0.2619\n",
      "Epoch 905/1000  Train Loss: 7541.1831  Val Loss: 7250.4131  Val MSE: 7250.4131  Val R2: -0.2609\n",
      "Epoch 906/1000  Train Loss: 7535.4839  Val Loss: 7244.6978  Val MSE: 7244.6973  Val R2: -0.2599\n",
      "Epoch 907/1000  Train Loss: 7529.7881  Val Loss: 7238.9868  Val MSE: 7238.9878  Val R2: -0.2589\n",
      "Epoch 908/1000  Train Loss: 7524.0981  Val Loss: 7233.2827  Val MSE: 7233.2817  Val R2: -0.2579\n",
      "Epoch 909/1000  Train Loss: 7518.4126  Val Loss: 7227.5815  Val MSE: 7227.5815  Val R2: -0.2569\n",
      "Epoch 910/1000  Train Loss: 7512.7305  Val Loss: 7221.8857  Val MSE: 7221.8857  Val R2: -0.2559\n",
      "Epoch 911/1000  Train Loss: 7507.0542  Val Loss: 7216.1938  Val MSE: 7216.1934  Val R2: -0.2550\n",
      "Epoch 912/1000  Train Loss: 7501.3823  Val Loss: 7210.5068  Val MSE: 7210.5068  Val R2: -0.2540\n",
      "Epoch 913/1000  Train Loss: 7495.7158  Val Loss: 7204.8252  Val MSE: 7204.8252  Val R2: -0.2530\n",
      "Epoch 914/1000  Train Loss: 7490.0537  Val Loss: 7199.1479  Val MSE: 7199.1479  Val R2: -0.2520\n",
      "Epoch 915/1000  Train Loss: 7484.3965  Val Loss: 7193.4761  Val MSE: 7193.4756  Val R2: -0.2510\n",
      "Epoch 916/1000  Train Loss: 7478.7432  Val Loss: 7187.8076  Val MSE: 7187.8071  Val R2: -0.2500\n",
      "Epoch 917/1000  Train Loss: 7473.0947  Val Loss: 7182.1440  Val MSE: 7182.1440  Val R2: -0.2490\n",
      "Epoch 918/1000  Train Loss: 7467.4507  Val Loss: 7176.4863  Val MSE: 7176.4854  Val R2: -0.2480\n",
      "Epoch 919/1000  Train Loss: 7461.8125  Val Loss: 7170.8320  Val MSE: 7170.8320  Val R2: -0.2471\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 920/1000  Train Loss: 7456.1782  Val Loss: 7165.1831  Val MSE: 7165.1821  Val R2: -0.2461\n",
      "Epoch 921/1000  Train Loss: 7450.5479  Val Loss: 7159.5381  Val MSE: 7159.5386  Val R2: -0.2451\n",
      "Epoch 922/1000  Train Loss: 7444.9238  Val Loss: 7153.8975  Val MSE: 7153.8984  Val R2: -0.2441\n",
      "Epoch 923/1000  Train Loss: 7439.3027  Val Loss: 7148.2632  Val MSE: 7148.2632  Val R2: -0.2431\n",
      "Epoch 924/1000  Train Loss: 7433.6875  Val Loss: 7142.6323  Val MSE: 7142.6323  Val R2: -0.2422\n",
      "Epoch 925/1000  Train Loss: 7428.0762  Val Loss: 7137.0059  Val MSE: 7137.0063  Val R2: -0.2412\n",
      "Epoch 926/1000  Train Loss: 7422.4702  Val Loss: 7131.3853  Val MSE: 7131.3857  Val R2: -0.2402\n",
      "Epoch 927/1000  Train Loss: 7416.8691  Val Loss: 7125.7695  Val MSE: 7125.7690  Val R2: -0.2392\n",
      "Epoch 928/1000  Train Loss: 7411.2715  Val Loss: 7120.1567  Val MSE: 7120.1562  Val R2: -0.2383\n",
      "Epoch 929/1000  Train Loss: 7405.6802  Val Loss: 7114.5488  Val MSE: 7114.5488  Val R2: -0.2373\n",
      "Epoch 930/1000  Train Loss: 7400.0913  Val Loss: 7108.9463  Val MSE: 7108.9463  Val R2: -0.2363\n",
      "Epoch 931/1000  Train Loss: 7394.5083  Val Loss: 7103.3486  Val MSE: 7103.3486  Val R2: -0.2353\n",
      "Epoch 932/1000  Train Loss: 7388.9292  Val Loss: 7097.7549  Val MSE: 7097.7544  Val R2: -0.2344\n",
      "Epoch 933/1000  Train Loss: 7383.3560  Val Loss: 7092.1660  Val MSE: 7092.1655  Val R2: -0.2334\n",
      "Epoch 934/1000  Train Loss: 7377.7856  Val Loss: 7086.5815  Val MSE: 7086.5811  Val R2: -0.2324\n",
      "Epoch 935/1000  Train Loss: 7372.2207  Val Loss: 7081.0015  Val MSE: 7081.0020  Val R2: -0.2314\n",
      "Epoch 936/1000  Train Loss: 7366.6616  Val Loss: 7075.4263  Val MSE: 7075.4263  Val R2: -0.2305\n",
      "Epoch 937/1000  Train Loss: 7361.1050  Val Loss: 7069.8560  Val MSE: 7069.8560  Val R2: -0.2295\n",
      "Epoch 938/1000  Train Loss: 7355.5542  Val Loss: 7064.2896  Val MSE: 7064.2896  Val R2: -0.2285\n",
      "Epoch 939/1000  Train Loss: 7350.0083  Val Loss: 7058.7290  Val MSE: 7058.7290  Val R2: -0.2276\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 940/1000  Train Loss: 7344.4668  Val Loss: 7053.1719  Val MSE: 7053.1729  Val R2: -0.2266\n",
      "Epoch 941/1000  Train Loss: 7338.9292  Val Loss: 7047.6211  Val MSE: 7047.6206  Val R2: -0.2256\n",
      "Epoch 942/1000  Train Loss: 7333.3970  Val Loss: 7042.0728  Val MSE: 7042.0728  Val R2: -0.2247\n",
      "Epoch 943/1000  Train Loss: 7327.8691  Val Loss: 7036.5293  Val MSE: 7036.5303  Val R2: -0.2237\n",
      "Epoch 944/1000  Train Loss: 7322.3457  Val Loss: 7030.9907  Val MSE: 7030.9912  Val R2: -0.2227\n",
      "Epoch 945/1000  Train Loss: 7316.8262  Val Loss: 7025.4570  Val MSE: 7025.4575  Val R2: -0.2218\n",
      "Epoch 946/1000  Train Loss: 7311.3125  Val Loss: 7019.9272  Val MSE: 7019.9282  Val R2: -0.2208\n",
      "Epoch 947/1000  Train Loss: 7305.8022  Val Loss: 7014.4033  Val MSE: 7014.4033  Val R2: -0.2199\n",
      "Epoch 948/1000  Train Loss: 7300.2969  Val Loss: 7008.8828  Val MSE: 7008.8828  Val R2: -0.2189\n",
      "Epoch 949/1000  Train Loss: 7294.7969  Val Loss: 7003.3677  Val MSE: 7003.3677  Val R2: -0.2179\n",
      "Epoch 950/1000  Train Loss: 7289.3003  Val Loss: 6997.8564  Val MSE: 6997.8564  Val R2: -0.2170\n",
      "Epoch 951/1000  Train Loss: 7283.8086  Val Loss: 6992.3491  Val MSE: 6992.3496  Val R2: -0.2160\n",
      "Epoch 952/1000  Train Loss: 7278.3208  Val Loss: 6986.8481  Val MSE: 6986.8481  Val R2: -0.2151\n",
      "Epoch 953/1000  Train Loss: 7272.8389  Val Loss: 6981.3506  Val MSE: 6981.3501  Val R2: -0.2141\n",
      "Epoch 954/1000  Train Loss: 7267.3613  Val Loss: 6975.8574  Val MSE: 6975.8569  Val R2: -0.2132\n",
      "Epoch 955/1000  Train Loss: 7261.8872  Val Loss: 6970.3691  Val MSE: 6970.3691  Val R2: -0.2122\n",
      "Epoch 956/1000  Train Loss: 7256.4180  Val Loss: 6964.8843  Val MSE: 6964.8848  Val R2: -0.2113\n",
      "Epoch 957/1000  Train Loss: 7250.9536  Val Loss: 6959.4058  Val MSE: 6959.4058  Val R2: -0.2103\n",
      "Epoch 958/1000  Train Loss: 7245.4941  Val Loss: 6953.9307  Val MSE: 6953.9307  Val R2: -0.2093\n",
      "Epoch 959/1000  Train Loss: 7240.0386  Val Loss: 6948.4604  Val MSE: 6948.4609  Val R2: -0.2084\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 960/1000  Train Loss: 7234.5879  Val Loss: 6942.9946  Val MSE: 6942.9946  Val R2: -0.2074\n",
      "Epoch 961/1000  Train Loss: 7229.1416  Val Loss: 6937.5332  Val MSE: 6937.5332  Val R2: -0.2065\n",
      "Epoch 962/1000  Train Loss: 7223.6987  Val Loss: 6932.0767  Val MSE: 6932.0762  Val R2: -0.2055\n",
      "Epoch 963/1000  Train Loss: 7218.2612  Val Loss: 6926.6240  Val MSE: 6926.6240  Val R2: -0.2046\n",
      "Epoch 964/1000  Train Loss: 7212.8286  Val Loss: 6921.1763  Val MSE: 6921.1763  Val R2: -0.2036\n",
      "Epoch 965/1000  Train Loss: 7207.4004  Val Loss: 6915.7329  Val MSE: 6915.7324  Val R2: -0.2027\n",
      "Epoch 966/1000  Train Loss: 7201.9756  Val Loss: 6910.2935  Val MSE: 6910.2939  Val R2: -0.2018\n",
      "Epoch 967/1000  Train Loss: 7196.5571  Val Loss: 6904.8599  Val MSE: 6904.8594  Val R2: -0.2008\n",
      "Epoch 968/1000  Train Loss: 7191.1421  Val Loss: 6899.4292  Val MSE: 6899.4297  Val R2: -0.1999\n",
      "Epoch 969/1000  Train Loss: 7185.7310  Val Loss: 6894.0044  Val MSE: 6894.0039  Val R2: -0.1989\n",
      "Epoch 970/1000  Train Loss: 7180.3247  Val Loss: 6888.5830  Val MSE: 6888.5835  Val R2: -0.1980\n",
      "Epoch 971/1000  Train Loss: 7174.9233  Val Loss: 6883.1665  Val MSE: 6883.1670  Val R2: -0.1970\n",
      "Epoch 972/1000  Train Loss: 7169.5264  Val Loss: 6877.7539  Val MSE: 6877.7544  Val R2: -0.1961\n",
      "Epoch 973/1000  Train Loss: 7164.1333  Val Loss: 6872.3467  Val MSE: 6872.3467  Val R2: -0.1952\n",
      "Epoch 974/1000  Train Loss: 7158.7446  Val Loss: 6866.9434  Val MSE: 6866.9438  Val R2: -0.1942\n",
      "Epoch 975/1000  Train Loss: 7153.3618  Val Loss: 6861.5449  Val MSE: 6861.5449  Val R2: -0.1933\n",
      "Epoch 976/1000  Train Loss: 7147.9824  Val Loss: 6856.1504  Val MSE: 6856.1509  Val R2: -0.1923\n",
      "Epoch 977/1000  Train Loss: 7142.6074  Val Loss: 6850.7603  Val MSE: 6850.7603  Val R2: -0.1914\n",
      "Epoch 978/1000  Train Loss: 7137.2368  Val Loss: 6845.3760  Val MSE: 6845.3750  Val R2: -0.1905\n",
      "Epoch 979/1000  Train Loss: 7131.8701  Val Loss: 6839.9951  Val MSE: 6839.9946  Val R2: -0.1895\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 980/1000  Train Loss: 7126.5088  Val Loss: 6834.6182  Val MSE: 6834.6187  Val R2: -0.1886\n",
      "Epoch 981/1000  Train Loss: 7121.1519  Val Loss: 6829.2456  Val MSE: 6829.2461  Val R2: -0.1877\n",
      "Epoch 982/1000  Train Loss: 7115.7988  Val Loss: 6823.8779  Val MSE: 6823.8779  Val R2: -0.1867\n",
      "Epoch 983/1000  Train Loss: 7110.4502  Val Loss: 6818.5151  Val MSE: 6818.5151  Val R2: -0.1858\n",
      "Epoch 984/1000  Train Loss: 7105.1069  Val Loss: 6813.1562  Val MSE: 6813.1567  Val R2: -0.1849\n",
      "Epoch 985/1000  Train Loss: 7099.7676  Val Loss: 6807.8018  Val MSE: 6807.8018  Val R2: -0.1839\n",
      "Epoch 986/1000  Train Loss: 7094.4321  Val Loss: 6802.4521  Val MSE: 6802.4521  Val R2: -0.1830\n",
      "Epoch 987/1000  Train Loss: 7089.1016  Val Loss: 6797.1064  Val MSE: 6797.1064  Val R2: -0.1821\n",
      "Epoch 988/1000  Train Loss: 7083.7749  Val Loss: 6791.7656  Val MSE: 6791.7656  Val R2: -0.1811\n",
      "Epoch 989/1000  Train Loss: 7078.4541  Val Loss: 6786.4282  Val MSE: 6786.4277  Val R2: -0.1802\n",
      "Epoch 990/1000  Train Loss: 7073.1357  Val Loss: 6781.0962  Val MSE: 6781.0957  Val R2: -0.1793\n",
      "Epoch 991/1000  Train Loss: 7067.8223  Val Loss: 6775.7676  Val MSE: 6775.7681  Val R2: -0.1784\n",
      "Epoch 992/1000  Train Loss: 7062.5137  Val Loss: 6770.4448  Val MSE: 6770.4448  Val R2: -0.1774\n",
      "Epoch 993/1000  Train Loss: 7057.2100  Val Loss: 6765.1245  Val MSE: 6765.1250  Val R2: -0.1765\n",
      "Epoch 994/1000  Train Loss: 7051.9087  Val Loss: 6759.8105  Val MSE: 6759.8101  Val R2: -0.1756\n",
      "Epoch 995/1000  Train Loss: 7046.6143  Val Loss: 6754.5000  Val MSE: 6754.5005  Val R2: -0.1747\n",
      "Epoch 996/1000  Train Loss: 7041.3223  Val Loss: 6749.1938  Val MSE: 6749.1938  Val R2: -0.1737\n",
      "Epoch 997/1000  Train Loss: 7036.0356  Val Loss: 6743.8916  Val MSE: 6743.8916  Val R2: -0.1728\n",
      "Epoch 998/1000  Train Loss: 7030.7529  Val Loss: 6738.5942  Val MSE: 6738.5947  Val R2: -0.1719\n",
      "Epoch 999/1000  Train Loss: 7025.4751  Val Loss: 6733.3013  Val MSE: 6733.3013  Val R2: -0.1710\n",
      "  >> Model saved to /home/orhankocak_0233/MLProject_570/models/lstm_trafik_nopca.pt (val_loss improved)\n",
      "Epoch 1000/1000  Train Loss: 7020.2012  Val Loss: 6728.0137  Val MSE: 6728.0132  Val R2: -0.1701\n",
      "Training finished. Best epoch: 1000 with val_loss=6728.0137\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Final Metrics ==\n",
      "mse: 6728.01318359375\n",
      "mae: 54.13914108276367\n",
      "r2: -0.17005670070648193\n"
     ]
    }
   ],
   "source": [
    "# PCA kullanlmyor\n",
    "dataset = TrafficDataset(data_array, X_STEP, Y_STEP)\n",
    "train_len = int(len(dataset) * 0.8)\n",
    "val_len = len(dataset) - train_len\n",
    "train_ds, val_ds = random_split(dataset, [train_len, val_len])\n",
    "train_loader = DataLoader(train_ds, batch_size=10, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=10)\n",
    "predictor = TrafficPredictor('lstm', dataset.sensors, X_STEP, Y_STEP, pca_model=dataset.pca if False else None)\n",
    "predictor.train(train_loader, val_loader, epochs=1000, save_path=config.PROJECT_ROOT.joinpath('models/lstm_trafik_nopca.pt'), save_optimizer=True)\n",
    "predictor.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
